{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression Salary Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6-VhfB7PXqQ",
        "outputId": "a268208a-fb64-42b4-dbc1-9ebe62523fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.6.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as op\n",
        "op.download(\"https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7eTKSR3Po0y",
        "outputId": "0088ea12-a95b-423d-942b-4d5def4d35d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: kaledhoshme\n",
            "Your Kaggle Key: ··········\n",
            "Downloading data-science-job-salaries.zip to ./data-science-job-salaries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.37k/7.37k [00:00<00:00, 1.95MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "uGJNiCwWPxwQ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SalaryPrediction:\n",
        "  def __init__(self, datasetFolder, epochs, test_size, label):\n",
        "    self.datasetFolder = datasetFolder\n",
        "    self.epochs = epochs\n",
        "    self.test_size = test_size\n",
        "    self.label = label\n",
        "  def readDataset(self):\n",
        "    self.dataset = pd.read_csv(os.path.join(self.datasetFolder, \"ds_salaries.csv\"))\n",
        "  def encoding_(self, column):\n",
        "    self.en = preprocessing.LabelEncoder()\n",
        "    self.en.fit(column)\n",
        "    return self.en.transform(column)\n",
        "  def encoding_columns(self, columns):\n",
        "    for i in columns:\n",
        "      self.dataset[i] = self.encoding_(self.dataset[i])\n",
        "  def detect_Features_label(self):\n",
        "    self.features = self.dataset.drop([self.label], axis = 1)\n",
        "    self.target = self.dataset[self.label]\n",
        "  def split_datset(self):\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.features,\n",
        "                                                                            self.target, \n",
        "                                                                            test_size = self.test_size,\n",
        "                                                                            random_state = 400\n",
        "                                                                            )\n",
        "  def normalizeInput(self):\n",
        "    self.norm = tf.keras.layers.Normalization(input_shape = (self.features.shape[1],), axis = -1)\n",
        "    self.norm.adapt(self.features)\n",
        "  def model(self):\n",
        "    m = tf.keras.models.Sequential()\n",
        "    m.add(self.norm)\n",
        "    m.add(tf.keras.layers.Dense(128, activation = \"tanh\"))\n",
        "    m.add(tf.keras.layers.Dense(64, activation = \"relu\"))\n",
        "    m.add(tf.keras.layers.Dense(1,))\n",
        "    self.m = m\n",
        "  def compile(self):\n",
        "    self.m.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "      loss='mean_absolute_percentage_error')\n",
        "  def fit(self):\n",
        "    self.history = self.m.fit(\n",
        "                  self.x_train,\n",
        "                  self.y_train,\n",
        "                  epochs=self.epochs,\n",
        "                  validation_data = (self.x_test, self.y_test),\n",
        "                  callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
        "                                                                mode=\"min\", \n",
        "                                                                restore_best_weights=True, \n",
        "                                                                patience=800)])\n",
        "  def plot_loss(self):\n",
        "    plt.plot(self.history.history['loss'], label='loss')\n",
        "    plt.plot(self.history.history['val_loss'], label='val_loss')\n",
        "    plt.legend()       \n"
      ],
      "metadata": {
        "id": "FtKKWWS8Elm9"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction = SalaryPrediction(\"data-science-job-salaries\", 10000, 0.1, 'salary')"
      ],
      "metadata": {
        "id": "_IzZyIbkSepG"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.readDataset()"
      ],
      "metadata": {
        "id": "gzzQ777CSxvX"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "GXFwFPabS3HX",
        "outputId": "9dc5b3b0-5252-483d-fa6d-a126e1cdeba0"
      },
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  work_year experience_level employment_type  \\\n",
              "0           0       2020               MI              FT   \n",
              "1           1       2020               SE              FT   \n",
              "2           2       2020               SE              FT   \n",
              "3           3       2020               MI              FT   \n",
              "4           4       2020               SE              FT   \n",
              "\n",
              "                    job_title  salary salary_currency  salary_in_usd  \\\n",
              "0              Data Scientist   70000             EUR          79833   \n",
              "1  Machine Learning Scientist  260000             USD         260000   \n",
              "2           Big Data Engineer   85000             GBP         109024   \n",
              "3        Product Data Analyst   20000             USD          20000   \n",
              "4   Machine Learning Engineer  150000             USD         150000   \n",
              "\n",
              "  employee_residence  remote_ratio company_location company_size  \n",
              "0                 DE             0               DE            L  \n",
              "1                 JP             0               JP            S  \n",
              "2                 GB            50               GB            M  \n",
              "3                 HN             0               HN            S  \n",
              "4                 US            50               US            L  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-755027e1-93a3-44ee-b842-c09e8436ebb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>work_year</th>\n",
              "      <th>experience_level</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_title</th>\n",
              "      <th>salary</th>\n",
              "      <th>salary_currency</th>\n",
              "      <th>salary_in_usd</th>\n",
              "      <th>employee_residence</th>\n",
              "      <th>remote_ratio</th>\n",
              "      <th>company_location</th>\n",
              "      <th>company_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>70000</td>\n",
              "      <td>EUR</td>\n",
              "      <td>79833</td>\n",
              "      <td>DE</td>\n",
              "      <td>0</td>\n",
              "      <td>DE</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Machine Learning Scientist</td>\n",
              "      <td>260000</td>\n",
              "      <td>USD</td>\n",
              "      <td>260000</td>\n",
              "      <td>JP</td>\n",
              "      <td>0</td>\n",
              "      <td>JP</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Big Data Engineer</td>\n",
              "      <td>85000</td>\n",
              "      <td>GBP</td>\n",
              "      <td>109024</td>\n",
              "      <td>GB</td>\n",
              "      <td>50</td>\n",
              "      <td>GB</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Product Data Analyst</td>\n",
              "      <td>20000</td>\n",
              "      <td>USD</td>\n",
              "      <td>20000</td>\n",
              "      <td>HN</td>\n",
              "      <td>0</td>\n",
              "      <td>HN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>150000</td>\n",
              "      <td>USD</td>\n",
              "      <td>150000</td>\n",
              "      <td>US</td>\n",
              "      <td>50</td>\n",
              "      <td>US</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-755027e1-93a3-44ee-b842-c09e8436ebb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-755027e1-93a3-44ee-b842-c09e8436ebb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-755027e1-93a3-44ee-b842-c09e8436ebb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UwV4UZGUHif",
        "outputId": "e04d822c-2822-4719-9a11-3dd67985108b"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'work_year', 'experience_level', 'employment_type',\n",
              "       'job_title', 'salary', 'salary_currency', 'salary_in_usd',\n",
              "       'employee_residence', 'remote_ratio', 'company_location',\n",
              "       'company_size'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.dataset.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "okbenV8gW5L-",
        "outputId": "50463fe0-0e78-4e67-951c-80091af0b8dc"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0    work_year        salary  salary_in_usd  remote_ratio\n",
              "count  607.000000   607.000000  6.070000e+02     607.000000     607.00000\n",
              "mean   303.000000  2021.405272  3.240001e+05  112297.869852      70.92257\n",
              "std    175.370085     0.692133  1.544357e+06   70957.259411      40.70913\n",
              "min      0.000000  2020.000000  4.000000e+03    2859.000000       0.00000\n",
              "25%    151.500000  2021.000000  7.000000e+04   62726.000000      50.00000\n",
              "50%    303.000000  2022.000000  1.150000e+05  101570.000000     100.00000\n",
              "75%    454.500000  2022.000000  1.650000e+05  150000.000000     100.00000\n",
              "max    606.000000  2022.000000  3.040000e+07  600000.000000     100.00000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7c447f9-07f8-4030-bf3b-c4b8425cdf6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>work_year</th>\n",
              "      <th>salary</th>\n",
              "      <th>salary_in_usd</th>\n",
              "      <th>remote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>607.000000</td>\n",
              "      <td>607.000000</td>\n",
              "      <td>6.070000e+02</td>\n",
              "      <td>607.000000</td>\n",
              "      <td>607.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>2021.405272</td>\n",
              "      <td>3.240001e+05</td>\n",
              "      <td>112297.869852</td>\n",
              "      <td>70.92257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>175.370085</td>\n",
              "      <td>0.692133</td>\n",
              "      <td>1.544357e+06</td>\n",
              "      <td>70957.259411</td>\n",
              "      <td>40.70913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2020.000000</td>\n",
              "      <td>4.000000e+03</td>\n",
              "      <td>2859.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>151.500000</td>\n",
              "      <td>2021.000000</td>\n",
              "      <td>7.000000e+04</td>\n",
              "      <td>62726.000000</td>\n",
              "      <td>50.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>2022.000000</td>\n",
              "      <td>1.150000e+05</td>\n",
              "      <td>101570.000000</td>\n",
              "      <td>100.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>454.500000</td>\n",
              "      <td>2022.000000</td>\n",
              "      <td>1.650000e+05</td>\n",
              "      <td>150000.000000</td>\n",
              "      <td>100.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>606.000000</td>\n",
              "      <td>2022.000000</td>\n",
              "      <td>3.040000e+07</td>\n",
              "      <td>600000.000000</td>\n",
              "      <td>100.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7c447f9-07f8-4030-bf3b-c4b8425cdf6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7c447f9-07f8-4030-bf3b-c4b8425cdf6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7c447f9-07f8-4030-bf3b-c4b8425cdf6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.dataset.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1AJJkXhXBDN",
        "outputId": "1cdecf39-a3fd-4441-83bc-c1a1d9bd4ff0"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0            0\n",
              "work_year             0\n",
              "experience_level      0\n",
              "employment_type       0\n",
              "job_title             0\n",
              "salary                0\n",
              "salary_currency       0\n",
              "salary_in_usd         0\n",
              "employee_residence    0\n",
              "remote_ratio          0\n",
              "company_location      0\n",
              "company_size          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kItVgN-DXG6u",
        "outputId": "71d8c424-8832-4b87-dd70-038ec931b55d"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 607 entries, 0 to 606\n",
            "Data columns (total 12 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Unnamed: 0          607 non-null    int64 \n",
            " 1   work_year           607 non-null    int64 \n",
            " 2   experience_level    607 non-null    object\n",
            " 3   employment_type     607 non-null    object\n",
            " 4   job_title           607 non-null    object\n",
            " 5   salary              607 non-null    int64 \n",
            " 6   salary_currency     607 non-null    object\n",
            " 7   salary_in_usd       607 non-null    int64 \n",
            " 8   employee_residence  607 non-null    object\n",
            " 9   remote_ratio        607 non-null    int64 \n",
            " 10  company_location    607 non-null    object\n",
            " 11  company_size        607 non-null    object\n",
            "dtypes: int64(5), object(7)\n",
            "memory usage: 57.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = np.array(['experience_level', 'salary_currency', 'job_title', 'company_size', 'company_location', 'employee_residence',\n",
        "           'employment_type'])\n",
        "\n",
        "SalaryPrediction.encoding_columns(columns)"
      ],
      "metadata": {
        "id": "gBgdszwFTAT9"
      },
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.detect_Features_label()"
      ],
      "metadata": {
        "id": "KTfuxVsKV_Fu"
      },
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "n9UbI2d1WDNm",
        "outputId": "5b522c54-897c-4514-b0b8-b09cdad6e97c"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  work_year  experience_level  employment_type  job_title  \\\n",
              "0           0       2020                 2                2         22   \n",
              "1           1       2020                 3                2         41   \n",
              "2           2       2020                 3                2          7   \n",
              "3           3       2020                 2                2         47   \n",
              "4           4       2020                 3                2         38   \n",
              "\n",
              "   salary_currency  salary_in_usd  employee_residence  remote_ratio  \\\n",
              "0                7          79833                  14             0   \n",
              "1               16         260000                  32             0   \n",
              "2                8         109024                  20            50   \n",
              "3               16          20000                  23             0   \n",
              "4               16         150000                  55            50   \n",
              "\n",
              "   company_location  company_size  \n",
              "0                12             0  \n",
              "1                29             2  \n",
              "2                18             1  \n",
              "3                20             2  \n",
              "4                48             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c27c7af-0bf6-487b-b7af-10df8a24b6be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>work_year</th>\n",
              "      <th>experience_level</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_title</th>\n",
              "      <th>salary_currency</th>\n",
              "      <th>salary_in_usd</th>\n",
              "      <th>employee_residence</th>\n",
              "      <th>remote_ratio</th>\n",
              "      <th>company_location</th>\n",
              "      <th>company_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>79833</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>16</td>\n",
              "      <td>260000</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>109024</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>16</td>\n",
              "      <td>20000</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "      <td>150000</td>\n",
              "      <td>55</td>\n",
              "      <td>50</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c27c7af-0bf6-487b-b7af-10df8a24b6be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c27c7af-0bf6-487b-b7af-10df8a24b6be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c27c7af-0bf6-487b-b7af-10df8a24b6be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1AlDSxWIGP",
        "outputId": "5f5ca62b-e393-4568-b3b0-04c02c0e574b"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     70000\n",
              "1    260000\n",
              "2     85000\n",
              "3     20000\n",
              "4    150000\n",
              "Name: salary, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.split_datset()"
      ],
      "metadata": {
        "id": "LYq6nOboWZR1"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.normalizeInput()"
      ],
      "metadata": {
        "id": "NUcVu5CfWkNu"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.model()"
      ],
      "metadata": {
        "id": "5R--nHB4WqVG"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.m.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXRrYpCKWupt",
        "outputId": "98b832fa-ac58-4f0d-9edc-64fe142b07d6"
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_24 (Normaliza  (None, 11)               23        \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,880\n",
            "Trainable params: 9,857\n",
            "Non-trainable params: 23\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.compile()"
      ],
      "metadata": {
        "id": "MBrEkfMAWx0F"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLd6X-cW0HF",
        "outputId": "5f09cf72-c497-4bad-e471-196ae1d64f73"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0166 - val_loss: 8.2445\n",
            "Epoch 1355/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9985 - val_loss: 8.2172\n",
            "Epoch 1356/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0414 - val_loss: 8.2992\n",
            "Epoch 1357/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0862 - val_loss: 8.2726\n",
            "Epoch 1358/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1412 - val_loss: 8.3395\n",
            "Epoch 1359/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0776 - val_loss: 8.2973\n",
            "Epoch 1360/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0435 - val_loss: 8.2897\n",
            "Epoch 1361/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0793 - val_loss: 8.2429\n",
            "Epoch 1362/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1254 - val_loss: 8.2710\n",
            "Epoch 1363/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1357 - val_loss: 8.3452\n",
            "Epoch 1364/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1315 - val_loss: 8.3367\n",
            "Epoch 1365/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1268 - val_loss: 8.3282\n",
            "Epoch 1366/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0447 - val_loss: 8.2588\n",
            "Epoch 1367/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.1631 - val_loss: 8.2393\n",
            "Epoch 1368/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0867 - val_loss: 8.1854\n",
            "Epoch 1369/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0693 - val_loss: 8.2834\n",
            "Epoch 1370/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0098 - val_loss: 8.2470\n",
            "Epoch 1371/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0284 - val_loss: 8.2808\n",
            "Epoch 1372/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0079 - val_loss: 8.2789\n",
            "Epoch 1373/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0030 - val_loss: 8.2472\n",
            "Epoch 1374/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9747 - val_loss: 8.2608\n",
            "Epoch 1375/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9690 - val_loss: 8.2623\n",
            "Epoch 1376/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0117 - val_loss: 8.2444\n",
            "Epoch 1377/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0231 - val_loss: 8.3140\n",
            "Epoch 1378/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0435 - val_loss: 8.2114\n",
            "Epoch 1379/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9842 - val_loss: 8.2722\n",
            "Epoch 1380/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0845 - val_loss: 8.2997\n",
            "Epoch 1381/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1014 - val_loss: 8.2442\n",
            "Epoch 1382/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0294 - val_loss: 8.2291\n",
            "Epoch 1383/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0662 - val_loss: 8.2457\n",
            "Epoch 1384/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0526 - val_loss: 8.2387\n",
            "Epoch 1385/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1240 - val_loss: 8.3129\n",
            "Epoch 1386/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0890 - val_loss: 8.2459\n",
            "Epoch 1387/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0828 - val_loss: 8.2118\n",
            "Epoch 1388/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0167 - val_loss: 8.2496\n",
            "Epoch 1389/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0365 - val_loss: 8.2771\n",
            "Epoch 1390/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0296 - val_loss: 8.2559\n",
            "Epoch 1391/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0312 - val_loss: 8.2677\n",
            "Epoch 1392/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.6813 - val_loss: 8.3413\n",
            "Epoch 1393/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.6068 - val_loss: 8.2647\n",
            "Epoch 1394/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.2626 - val_loss: 8.2689\n",
            "Epoch 1395/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0777 - val_loss: 8.2415\n",
            "Epoch 1396/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0586 - val_loss: 8.2629\n",
            "Epoch 1397/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0570 - val_loss: 8.2144\n",
            "Epoch 1398/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.3932 - val_loss: 8.3656\n",
            "Epoch 1399/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.3570 - val_loss: 8.2661\n",
            "Epoch 1400/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.1483 - val_loss: 8.2954\n",
            "Epoch 1401/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0878 - val_loss: 8.2147\n",
            "Epoch 1402/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0733 - val_loss: 8.2810\n",
            "Epoch 1403/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0141 - val_loss: 8.2457\n",
            "Epoch 1404/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9969 - val_loss: 8.2210\n",
            "Epoch 1405/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0633 - val_loss: 8.2616\n",
            "Epoch 1406/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9797 - val_loss: 8.2254\n",
            "Epoch 1407/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9658 - val_loss: 8.2059\n",
            "Epoch 1408/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0413 - val_loss: 8.2360\n",
            "Epoch 1409/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.2122 - val_loss: 8.2936\n",
            "Epoch 1410/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1152 - val_loss: 8.2555\n",
            "Epoch 1411/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0174 - val_loss: 8.2681\n",
            "Epoch 1412/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0054 - val_loss: 8.3126\n",
            "Epoch 1413/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9754 - val_loss: 8.2728\n",
            "Epoch 1414/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9396 - val_loss: 8.2846\n",
            "Epoch 1415/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9577 - val_loss: 8.2329\n",
            "Epoch 1416/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9679 - val_loss: 8.3081\n",
            "Epoch 1417/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9395 - val_loss: 8.2158\n",
            "Epoch 1418/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9658 - val_loss: 8.2389\n",
            "Epoch 1419/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9806 - val_loss: 8.2058\n",
            "Epoch 1420/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9658 - val_loss: 8.2057\n",
            "Epoch 1421/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9357 - val_loss: 8.2092\n",
            "Epoch 1422/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8940 - val_loss: 8.2112\n",
            "Epoch 1423/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.3424 - val_loss: 8.1902\n",
            "Epoch 1424/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0941 - val_loss: 8.1870\n",
            "Epoch 1425/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.3278 - val_loss: 8.2378\n",
            "Epoch 1426/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0564 - val_loss: 8.3063\n",
            "Epoch 1427/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0222 - val_loss: 8.2681\n",
            "Epoch 1428/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9619 - val_loss: 8.2495\n",
            "Epoch 1429/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0049 - val_loss: 8.2137\n",
            "Epoch 1430/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9356 - val_loss: 8.2300\n",
            "Epoch 1431/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9851 - val_loss: 8.2525\n",
            "Epoch 1432/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9249 - val_loss: 8.2253\n",
            "Epoch 1433/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9137 - val_loss: 8.2091\n",
            "Epoch 1434/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9450 - val_loss: 8.1791\n",
            "Epoch 1435/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9713 - val_loss: 8.1874\n",
            "Epoch 1436/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8858 - val_loss: 8.2265\n",
            "Epoch 1437/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9405 - val_loss: 8.2600\n",
            "Epoch 1438/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9324 - val_loss: 8.2361\n",
            "Epoch 1439/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0095 - val_loss: 8.1942\n",
            "Epoch 1440/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9765 - val_loss: 8.2376\n",
            "Epoch 1441/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9542 - val_loss: 8.2349\n",
            "Epoch 1442/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9558 - val_loss: 8.2962\n",
            "Epoch 1443/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9339 - val_loss: 8.1947\n",
            "Epoch 1444/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9170 - val_loss: 8.2452\n",
            "Epoch 1445/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9489 - val_loss: 8.2259\n",
            "Epoch 1446/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9214 - val_loss: 8.2137\n",
            "Epoch 1447/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9191 - val_loss: 8.2202\n",
            "Epoch 1448/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9084 - val_loss: 8.2167\n",
            "Epoch 1449/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9213 - val_loss: 8.1717\n",
            "Epoch 1450/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8766 - val_loss: 8.2145\n",
            "Epoch 1451/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8994 - val_loss: 8.1899\n",
            "Epoch 1452/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8954 - val_loss: 8.1953\n",
            "Epoch 1453/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8802 - val_loss: 8.2070\n",
            "Epoch 1454/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8743 - val_loss: 8.1818\n",
            "Epoch 1455/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8822 - val_loss: 8.1661\n",
            "Epoch 1456/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9533 - val_loss: 8.1728\n",
            "Epoch 1457/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9286 - val_loss: 8.2526\n",
            "Epoch 1458/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8634 - val_loss: 8.1956\n",
            "Epoch 1459/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9036 - val_loss: 8.2030\n",
            "Epoch 1460/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9242 - val_loss: 8.1865\n",
            "Epoch 1461/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9224 - val_loss: 8.2107\n",
            "Epoch 1462/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9005 - val_loss: 8.2250\n",
            "Epoch 1463/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8801 - val_loss: 8.2627\n",
            "Epoch 1464/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9338 - val_loss: 8.1861\n",
            "Epoch 1465/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8388 - val_loss: 8.1733\n",
            "Epoch 1466/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8498 - val_loss: 8.1637\n",
            "Epoch 1467/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8580 - val_loss: 8.1645\n",
            "Epoch 1468/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8663 - val_loss: 8.1868\n",
            "Epoch 1469/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8629 - val_loss: 8.1706\n",
            "Epoch 1470/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9028 - val_loss: 8.2203\n",
            "Epoch 1471/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8679 - val_loss: 8.2059\n",
            "Epoch 1472/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8291 - val_loss: 8.1516\n",
            "Epoch 1473/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8317 - val_loss: 8.1859\n",
            "Epoch 1474/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9708 - val_loss: 8.1641\n",
            "Epoch 1475/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9562 - val_loss: 8.2249\n",
            "Epoch 1476/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9396 - val_loss: 8.1499\n",
            "Epoch 1477/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9316 - val_loss: 8.1965\n",
            "Epoch 1478/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9625 - val_loss: 8.1392\n",
            "Epoch 1479/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9535 - val_loss: 8.1310\n",
            "Epoch 1480/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9220 - val_loss: 8.2043\n",
            "Epoch 1481/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8706 - val_loss: 8.1866\n",
            "Epoch 1482/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8541 - val_loss: 8.1756\n",
            "Epoch 1483/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8616 - val_loss: 8.1116\n",
            "Epoch 1484/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8691 - val_loss: 8.1614\n",
            "Epoch 1485/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8637 - val_loss: 8.1349\n",
            "Epoch 1486/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8127 - val_loss: 8.1840\n",
            "Epoch 1487/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8614 - val_loss: 8.1868\n",
            "Epoch 1488/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8320 - val_loss: 8.2300\n",
            "Epoch 1489/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8660 - val_loss: 8.1665\n",
            "Epoch 1490/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8604 - val_loss: 8.1554\n",
            "Epoch 1491/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8670 - val_loss: 8.1989\n",
            "Epoch 1492/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8194 - val_loss: 8.1476\n",
            "Epoch 1493/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8211 - val_loss: 8.1645\n",
            "Epoch 1494/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8290 - val_loss: 8.1254\n",
            "Epoch 1495/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8363 - val_loss: 8.1636\n",
            "Epoch 1496/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7895 - val_loss: 8.1458\n",
            "Epoch 1497/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7797 - val_loss: 8.1747\n",
            "Epoch 1498/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8429 - val_loss: 8.2003\n",
            "Epoch 1499/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8020 - val_loss: 8.1381\n",
            "Epoch 1500/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8760 - val_loss: 8.1902\n",
            "Epoch 1501/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8425 - val_loss: 8.1262\n",
            "Epoch 1502/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8220 - val_loss: 8.1455\n",
            "Epoch 1503/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8078 - val_loss: 8.1903\n",
            "Epoch 1504/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0049 - val_loss: 8.1537\n",
            "Epoch 1505/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8497 - val_loss: 8.1142\n",
            "Epoch 1506/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.5179 - val_loss: 8.0718\n",
            "Epoch 1507/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.1513 - val_loss: 8.2307\n",
            "Epoch 1508/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9768 - val_loss: 8.2009\n",
            "Epoch 1509/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9259 - val_loss: 8.1260\n",
            "Epoch 1510/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8757 - val_loss: 8.1234\n",
            "Epoch 1511/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8620 - val_loss: 8.1513\n",
            "Epoch 1512/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8613 - val_loss: 8.0959\n",
            "Epoch 1513/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8546 - val_loss: 8.1323\n",
            "Epoch 1514/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8148 - val_loss: 8.1466\n",
            "Epoch 1515/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.3953 - val_loss: 8.2054\n",
            "Epoch 1516/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0258 - val_loss: 8.1342\n",
            "Epoch 1517/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9301 - val_loss: 8.1958\n",
            "Epoch 1518/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8786 - val_loss: 8.1469\n",
            "Epoch 1519/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8352 - val_loss: 8.1485\n",
            "Epoch 1520/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7854 - val_loss: 8.1185\n",
            "Epoch 1521/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7746 - val_loss: 8.1510\n",
            "Epoch 1522/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7456 - val_loss: 8.1048\n",
            "Epoch 1523/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7826 - val_loss: 8.1418\n",
            "Epoch 1524/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8071 - val_loss: 8.1206\n",
            "Epoch 1525/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8436 - val_loss: 8.1080\n",
            "Epoch 1526/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8056 - val_loss: 8.1517\n",
            "Epoch 1527/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7721 - val_loss: 8.1717\n",
            "Epoch 1528/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0180 - val_loss: 8.1717\n",
            "Epoch 1529/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9253 - val_loss: 8.0817\n",
            "Epoch 1530/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8241 - val_loss: 8.1831\n",
            "Epoch 1531/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7817 - val_loss: 8.1502\n",
            "Epoch 1532/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.5777 - val_loss: 8.2190\n",
            "Epoch 1533/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.3117 - val_loss: 8.1204\n",
            "Epoch 1534/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.3977 - val_loss: 8.1798\n",
            "Epoch 1535/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.2425 - val_loss: 8.0979\n",
            "Epoch 1536/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0170 - val_loss: 8.1550\n",
            "Epoch 1537/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.9416 - val_loss: 8.1666\n",
            "Epoch 1538/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.9497 - val_loss: 8.1206\n",
            "Epoch 1539/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8441 - val_loss: 8.1249\n",
            "Epoch 1540/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7679 - val_loss: 8.1200\n",
            "Epoch 1541/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.8055 - val_loss: 8.1234\n",
            "Epoch 1542/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8101 - val_loss: 8.1042\n",
            "Epoch 1543/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7796 - val_loss: 8.0926\n",
            "Epoch 1544/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8428 - val_loss: 8.0669\n",
            "Epoch 1545/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7589 - val_loss: 8.1357\n",
            "Epoch 1546/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.7475 - val_loss: 8.1422\n",
            "Epoch 1547/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7609 - val_loss: 8.0631\n",
            "Epoch 1548/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7574 - val_loss: 8.0893\n",
            "Epoch 1549/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7500 - val_loss: 8.0672\n",
            "Epoch 1550/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8289 - val_loss: 8.0909\n",
            "Epoch 1551/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8276 - val_loss: 8.1242\n",
            "Epoch 1552/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7842 - val_loss: 8.1370\n",
            "Epoch 1553/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8060 - val_loss: 8.1320\n",
            "Epoch 1554/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7602 - val_loss: 8.1366\n",
            "Epoch 1555/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7676 - val_loss: 8.0396\n",
            "Epoch 1556/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7981 - val_loss: 8.1375\n",
            "Epoch 1557/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8155 - val_loss: 8.0861\n",
            "Epoch 1558/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7495 - val_loss: 8.1019\n",
            "Epoch 1559/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7725 - val_loss: 8.1890\n",
            "Epoch 1560/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7991 - val_loss: 8.1207\n",
            "Epoch 1561/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7946 - val_loss: 8.1131\n",
            "Epoch 1562/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7992 - val_loss: 8.0517\n",
            "Epoch 1563/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7250 - val_loss: 8.1292\n",
            "Epoch 1564/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7424 - val_loss: 8.1187\n",
            "Epoch 1565/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7485 - val_loss: 8.1209\n",
            "Epoch 1566/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7700 - val_loss: 8.1035\n",
            "Epoch 1567/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7229 - val_loss: 8.0473\n",
            "Epoch 1568/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8253 - val_loss: 8.1024\n",
            "Epoch 1569/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7601 - val_loss: 8.0560\n",
            "Epoch 1570/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7406 - val_loss: 8.1074\n",
            "Epoch 1571/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7136 - val_loss: 8.0636\n",
            "Epoch 1572/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7466 - val_loss: 8.0958\n",
            "Epoch 1573/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7249 - val_loss: 8.0296\n",
            "Epoch 1574/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7167 - val_loss: 8.1262\n",
            "Epoch 1575/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7306 - val_loss: 8.0713\n",
            "Epoch 1576/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7095 - val_loss: 8.0694\n",
            "Epoch 1577/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6701 - val_loss: 8.0817\n",
            "Epoch 1578/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7030 - val_loss: 8.1073\n",
            "Epoch 1579/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7284 - val_loss: 8.1028\n",
            "Epoch 1580/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7288 - val_loss: 8.0711\n",
            "Epoch 1581/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8138 - val_loss: 8.1286\n",
            "Epoch 1582/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7165 - val_loss: 8.0443\n",
            "Epoch 1583/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7365 - val_loss: 8.0678\n",
            "Epoch 1584/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6937 - val_loss: 8.0847\n",
            "Epoch 1585/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6885 - val_loss: 8.0753\n",
            "Epoch 1586/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7087 - val_loss: 8.0664\n",
            "Epoch 1587/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7305 - val_loss: 7.9892\n",
            "Epoch 1588/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7758 - val_loss: 8.0131\n",
            "Epoch 1589/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6810 - val_loss: 8.0326\n",
            "Epoch 1590/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6835 - val_loss: 8.0387\n",
            "Epoch 1591/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6629 - val_loss: 8.0409\n",
            "Epoch 1592/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9568 - val_loss: 8.0549\n",
            "Epoch 1593/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8728 - val_loss: 8.0762\n",
            "Epoch 1594/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8347 - val_loss: 8.0143\n",
            "Epoch 1595/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7405 - val_loss: 8.0480\n",
            "Epoch 1596/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.7141 - val_loss: 8.0497\n",
            "Epoch 1597/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7859 - val_loss: 8.0857\n",
            "Epoch 1598/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7456 - val_loss: 8.0597\n",
            "Epoch 1599/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8502 - val_loss: 7.9353\n",
            "Epoch 1600/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7694 - val_loss: 8.0221\n",
            "Epoch 1601/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7610 - val_loss: 8.0232\n",
            "Epoch 1602/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.6723 - val_loss: 8.0154\n",
            "Epoch 1603/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7322 - val_loss: 8.0562\n",
            "Epoch 1604/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8822 - val_loss: 8.1442\n",
            "Epoch 1605/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7659 - val_loss: 8.0607\n",
            "Epoch 1606/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7507 - val_loss: 8.0972\n",
            "Epoch 1607/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6610 - val_loss: 8.0937\n",
            "Epoch 1608/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6938 - val_loss: 8.0486\n",
            "Epoch 1609/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7075 - val_loss: 8.0187\n",
            "Epoch 1610/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7055 - val_loss: 8.0316\n",
            "Epoch 1611/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7182 - val_loss: 8.0193\n",
            "Epoch 1612/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7044 - val_loss: 8.0275\n",
            "Epoch 1613/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6915 - val_loss: 8.0506\n",
            "Epoch 1614/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7668 - val_loss: 8.0524\n",
            "Epoch 1615/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7134 - val_loss: 8.0116\n",
            "Epoch 1616/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6818 - val_loss: 8.0482\n",
            "Epoch 1617/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6953 - val_loss: 8.0281\n",
            "Epoch 1618/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6663 - val_loss: 8.0577\n",
            "Epoch 1619/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6514 - val_loss: 7.9939\n",
            "Epoch 1620/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6726 - val_loss: 8.0704\n",
            "Epoch 1621/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6954 - val_loss: 8.0402\n",
            "Epoch 1622/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6717 - val_loss: 8.0058\n",
            "Epoch 1623/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6487 - val_loss: 7.9683\n",
            "Epoch 1624/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6911 - val_loss: 8.0591\n",
            "Epoch 1625/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6940 - val_loss: 8.0111\n",
            "Epoch 1626/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8143 - val_loss: 7.9048\n",
            "Epoch 1627/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6634 - val_loss: 8.0104\n",
            "Epoch 1628/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6827 - val_loss: 8.0088\n",
            "Epoch 1629/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7199 - val_loss: 8.0246\n",
            "Epoch 1630/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6871 - val_loss: 8.0612\n",
            "Epoch 1631/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6619 - val_loss: 7.9405\n",
            "Epoch 1632/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7371 - val_loss: 8.0077\n",
            "Epoch 1633/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6587 - val_loss: 8.1142\n",
            "Epoch 1634/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.4325 - val_loss: 8.1009\n",
            "Epoch 1635/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.2399 - val_loss: 8.0750\n",
            "Epoch 1636/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9331 - val_loss: 8.0178\n",
            "Epoch 1637/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7237 - val_loss: 8.0130\n",
            "Epoch 1638/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7141 - val_loss: 8.0315\n",
            "Epoch 1639/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6990 - val_loss: 8.0019\n",
            "Epoch 1640/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6408 - val_loss: 8.0107\n",
            "Epoch 1641/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7429 - val_loss: 8.0260\n",
            "Epoch 1642/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6951 - val_loss: 8.0241\n",
            "Epoch 1643/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6574 - val_loss: 8.0143\n",
            "Epoch 1644/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6306 - val_loss: 8.0263\n",
            "Epoch 1645/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.2753 - val_loss: 8.0565\n",
            "Epoch 1646/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0732 - val_loss: 8.1016\n",
            "Epoch 1647/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8864 - val_loss: 8.0725\n",
            "Epoch 1648/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7612 - val_loss: 8.0911\n",
            "Epoch 1649/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7210 - val_loss: 8.0359\n",
            "Epoch 1650/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6941 - val_loss: 8.0352\n",
            "Epoch 1651/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7167 - val_loss: 7.9965\n",
            "Epoch 1652/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6730 - val_loss: 8.0294\n",
            "Epoch 1653/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6288 - val_loss: 7.9715\n",
            "Epoch 1654/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6546 - val_loss: 8.0370\n",
            "Epoch 1655/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5863 - val_loss: 8.0084\n",
            "Epoch 1656/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6133 - val_loss: 8.0234\n",
            "Epoch 1657/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6415 - val_loss: 7.9940\n",
            "Epoch 1658/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6031 - val_loss: 8.0317\n",
            "Epoch 1659/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5995 - val_loss: 7.9928\n",
            "Epoch 1660/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7216 - val_loss: 8.0684\n",
            "Epoch 1661/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6808 - val_loss: 8.0205\n",
            "Epoch 1662/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6515 - val_loss: 7.9570\n",
            "Epoch 1663/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6046 - val_loss: 7.9671\n",
            "Epoch 1664/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5920 - val_loss: 8.0018\n",
            "Epoch 1665/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5856 - val_loss: 8.0257\n",
            "Epoch 1666/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5989 - val_loss: 8.0293\n",
            "Epoch 1667/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7037 - val_loss: 7.9947\n",
            "Epoch 1668/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6366 - val_loss: 8.0435\n",
            "Epoch 1669/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6445 - val_loss: 8.0718\n",
            "Epoch 1670/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6198 - val_loss: 8.0035\n",
            "Epoch 1671/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5823 - val_loss: 8.0212\n",
            "Epoch 1672/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5895 - val_loss: 8.0045\n",
            "Epoch 1673/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5557 - val_loss: 7.9933\n",
            "Epoch 1674/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5884 - val_loss: 7.9726\n",
            "Epoch 1675/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5532 - val_loss: 8.0056\n",
            "Epoch 1676/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5450 - val_loss: 8.0164\n",
            "Epoch 1677/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5998 - val_loss: 8.0673\n",
            "Epoch 1678/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5726 - val_loss: 7.9923\n",
            "Epoch 1679/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5661 - val_loss: 7.9750\n",
            "Epoch 1680/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5755 - val_loss: 7.9571\n",
            "Epoch 1681/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5569 - val_loss: 7.9623\n",
            "Epoch 1682/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5440 - val_loss: 8.0077\n",
            "Epoch 1683/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6081 - val_loss: 8.0092\n",
            "Epoch 1684/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5602 - val_loss: 7.9660\n",
            "Epoch 1685/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5359 - val_loss: 7.9880\n",
            "Epoch 1686/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5826 - val_loss: 7.9736\n",
            "Epoch 1687/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5609 - val_loss: 8.0374\n",
            "Epoch 1688/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6194 - val_loss: 7.9178\n",
            "Epoch 1689/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5732 - val_loss: 8.0069\n",
            "Epoch 1690/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6561 - val_loss: 7.9395\n",
            "Epoch 1691/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8814 - val_loss: 7.9604\n",
            "Epoch 1692/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7491 - val_loss: 8.0834\n",
            "Epoch 1693/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6192 - val_loss: 8.0180\n",
            "Epoch 1694/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6179 - val_loss: 8.0031\n",
            "Epoch 1695/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6081 - val_loss: 7.9607\n",
            "Epoch 1696/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6065 - val_loss: 7.9417\n",
            "Epoch 1697/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5873 - val_loss: 8.0020\n",
            "Epoch 1698/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5859 - val_loss: 7.9762\n",
            "Epoch 1699/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5107 - val_loss: 7.9902\n",
            "Epoch 1700/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5520 - val_loss: 7.9237\n",
            "Epoch 1701/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5359 - val_loss: 7.9101\n",
            "Epoch 1702/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5894 - val_loss: 7.9918\n",
            "Epoch 1703/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5962 - val_loss: 8.0525\n",
            "Epoch 1704/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6142 - val_loss: 7.9484\n",
            "Epoch 1705/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5934 - val_loss: 8.0038\n",
            "Epoch 1706/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5632 - val_loss: 7.9566\n",
            "Epoch 1707/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6121 - val_loss: 7.9163\n",
            "Epoch 1708/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5832 - val_loss: 7.9963\n",
            "Epoch 1709/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5247 - val_loss: 7.9376\n",
            "Epoch 1710/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5438 - val_loss: 8.0362\n",
            "Epoch 1711/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5707 - val_loss: 7.9740\n",
            "Epoch 1712/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5697 - val_loss: 7.9873\n",
            "Epoch 1713/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5780 - val_loss: 7.9213\n",
            "Epoch 1714/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5489 - val_loss: 7.9931\n",
            "Epoch 1715/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5987 - val_loss: 7.9901\n",
            "Epoch 1716/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5849 - val_loss: 8.0282\n",
            "Epoch 1717/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5526 - val_loss: 7.9922\n",
            "Epoch 1718/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5476 - val_loss: 7.9457\n",
            "Epoch 1719/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5170 - val_loss: 7.9716\n",
            "Epoch 1720/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7673 - val_loss: 8.0570\n",
            "Epoch 1721/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6450 - val_loss: 7.9438\n",
            "Epoch 1722/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5948 - val_loss: 7.9800\n",
            "Epoch 1723/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5728 - val_loss: 7.9496\n",
            "Epoch 1724/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5751 - val_loss: 7.9261\n",
            "Epoch 1725/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5754 - val_loss: 7.9724\n",
            "Epoch 1726/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5638 - val_loss: 7.9619\n",
            "Epoch 1727/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5333 - val_loss: 7.9672\n",
            "Epoch 1728/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7624 - val_loss: 7.9398\n",
            "Epoch 1729/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7069 - val_loss: 8.0092\n",
            "Epoch 1730/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6396 - val_loss: 8.0247\n",
            "Epoch 1731/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5663 - val_loss: 7.9611\n",
            "Epoch 1732/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5681 - val_loss: 7.9357\n",
            "Epoch 1733/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5226 - val_loss: 7.9696\n",
            "Epoch 1734/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5220 - val_loss: 7.9395\n",
            "Epoch 1735/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5085 - val_loss: 7.9870\n",
            "Epoch 1736/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5855 - val_loss: 7.9267\n",
            "Epoch 1737/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8726 - val_loss: 8.0056\n",
            "Epoch 1738/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8936 - val_loss: 7.9766\n",
            "Epoch 1739/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7160 - val_loss: 8.0749\n",
            "Epoch 1740/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6719 - val_loss: 7.9778\n",
            "Epoch 1741/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5409 - val_loss: 7.9529\n",
            "Epoch 1742/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6193 - val_loss: 8.0706\n",
            "Epoch 1743/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5589 - val_loss: 7.9788\n",
            "Epoch 1744/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5268 - val_loss: 7.9614\n",
            "Epoch 1745/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5638 - val_loss: 8.0842\n",
            "Epoch 1746/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0046 - val_loss: 7.9213\n",
            "Epoch 1747/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8503 - val_loss: 8.0544\n",
            "Epoch 1748/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6694 - val_loss: 7.9560\n",
            "Epoch 1749/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5940 - val_loss: 7.9625\n",
            "Epoch 1750/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5325 - val_loss: 7.9744\n",
            "Epoch 1751/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4856 - val_loss: 7.9962\n",
            "Epoch 1752/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5393 - val_loss: 7.9536\n",
            "Epoch 1753/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5710 - val_loss: 7.8906\n",
            "Epoch 1754/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5466 - val_loss: 7.9825\n",
            "Epoch 1755/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6210 - val_loss: 7.9420\n",
            "Epoch 1756/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5286 - val_loss: 7.9723\n",
            "Epoch 1757/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6382 - val_loss: 7.9572\n",
            "Epoch 1758/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5581 - val_loss: 8.0114\n",
            "Epoch 1759/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6145 - val_loss: 7.9945\n",
            "Epoch 1760/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4932 - val_loss: 7.9193\n",
            "Epoch 1761/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5100 - val_loss: 7.9797\n",
            "Epoch 1762/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5382 - val_loss: 7.9306\n",
            "Epoch 1763/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4881 - val_loss: 7.9285\n",
            "Epoch 1764/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5077 - val_loss: 7.9300\n",
            "Epoch 1765/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4805 - val_loss: 7.9389\n",
            "Epoch 1766/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5092 - val_loss: 7.8773\n",
            "Epoch 1767/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4836 - val_loss: 7.9441\n",
            "Epoch 1768/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4420 - val_loss: 7.9502\n",
            "Epoch 1769/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4457 - val_loss: 7.9159\n",
            "Epoch 1770/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4220 - val_loss: 7.9341\n",
            "Epoch 1771/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4579 - val_loss: 7.9265\n",
            "Epoch 1772/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4608 - val_loss: 7.9573\n",
            "Epoch 1773/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4471 - val_loss: 7.9226\n",
            "Epoch 1774/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4376 - val_loss: 7.9465\n",
            "Epoch 1775/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4884 - val_loss: 8.0259\n",
            "Epoch 1776/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5314 - val_loss: 7.9663\n",
            "Epoch 1777/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5774 - val_loss: 7.9292\n",
            "Epoch 1778/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5459 - val_loss: 7.9597\n",
            "Epoch 1779/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5269 - val_loss: 7.9773\n",
            "Epoch 1780/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4295 - val_loss: 7.9849\n",
            "Epoch 1781/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4894 - val_loss: 7.9639\n",
            "Epoch 1782/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4956 - val_loss: 7.9065\n",
            "Epoch 1783/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4406 - val_loss: 7.9587\n",
            "Epoch 1784/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4504 - val_loss: 7.9353\n",
            "Epoch 1785/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4609 - val_loss: 7.9337\n",
            "Epoch 1786/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4834 - val_loss: 7.9301\n",
            "Epoch 1787/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5236 - val_loss: 7.9385\n",
            "Epoch 1788/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8251 - val_loss: 7.9294\n",
            "Epoch 1789/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6793 - val_loss: 7.9266\n",
            "Epoch 1790/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5623 - val_loss: 7.9744\n",
            "Epoch 1791/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5627 - val_loss: 7.9458\n",
            "Epoch 1792/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4722 - val_loss: 7.9388\n",
            "Epoch 1793/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4794 - val_loss: 7.9577\n",
            "Epoch 1794/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5249 - val_loss: 7.9004\n",
            "Epoch 1795/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5066 - val_loss: 7.9370\n",
            "Epoch 1796/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4631 - val_loss: 7.9356\n",
            "Epoch 1797/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4421 - val_loss: 7.9263\n",
            "Epoch 1798/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4663 - val_loss: 7.9791\n",
            "Epoch 1799/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4898 - val_loss: 7.9108\n",
            "Epoch 1800/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4798 - val_loss: 7.9213\n",
            "Epoch 1801/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4404 - val_loss: 7.9560\n",
            "Epoch 1802/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4049 - val_loss: 7.8887\n",
            "Epoch 1803/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4217 - val_loss: 7.9437\n",
            "Epoch 1804/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4541 - val_loss: 7.9506\n",
            "Epoch 1805/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4405 - val_loss: 7.9162\n",
            "Epoch 1806/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4364 - val_loss: 7.9120\n",
            "Epoch 1807/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7981 - val_loss: 8.1787\n",
            "Epoch 1808/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6044 - val_loss: 8.0136\n",
            "Epoch 1809/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6427 - val_loss: 7.8506\n",
            "Epoch 1810/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5015 - val_loss: 7.9492\n",
            "Epoch 1811/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4410 - val_loss: 7.8839\n",
            "Epoch 1812/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4731 - val_loss: 7.9126\n",
            "Epoch 1813/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5128 - val_loss: 7.9675\n",
            "Epoch 1814/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7827 - val_loss: 7.8028\n",
            "Epoch 1815/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6099 - val_loss: 7.8894\n",
            "Epoch 1816/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5206 - val_loss: 7.8738\n",
            "Epoch 1817/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4440 - val_loss: 7.8634\n",
            "Epoch 1818/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4477 - val_loss: 7.8973\n",
            "Epoch 1819/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4252 - val_loss: 7.9051\n",
            "Epoch 1820/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4292 - val_loss: 7.9908\n",
            "Epoch 1821/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4631 - val_loss: 7.9015\n",
            "Epoch 1822/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4164 - val_loss: 7.9615\n",
            "Epoch 1823/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4677 - val_loss: 7.8757\n",
            "Epoch 1824/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4239 - val_loss: 7.9055\n",
            "Epoch 1825/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4186 - val_loss: 7.9186\n",
            "Epoch 1826/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3985 - val_loss: 7.9281\n",
            "Epoch 1827/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4076 - val_loss: 7.9691\n",
            "Epoch 1828/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5049 - val_loss: 7.9818\n",
            "Epoch 1829/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4491 - val_loss: 7.8953\n",
            "Epoch 1830/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5018 - val_loss: 7.9630\n",
            "Epoch 1831/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4369 - val_loss: 7.8903\n",
            "Epoch 1832/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4149 - val_loss: 7.9222\n",
            "Epoch 1833/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4538 - val_loss: 7.9134\n",
            "Epoch 1834/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4179 - val_loss: 7.9006\n",
            "Epoch 1835/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4270 - val_loss: 7.9188\n",
            "Epoch 1836/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4083 - val_loss: 7.9475\n",
            "Epoch 1837/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4076 - val_loss: 7.9066\n",
            "Epoch 1838/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4363 - val_loss: 7.9211\n",
            "Epoch 1839/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4198 - val_loss: 7.8426\n",
            "Epoch 1840/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4114 - val_loss: 7.9391\n",
            "Epoch 1841/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4271 - val_loss: 7.9306\n",
            "Epoch 1842/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6820 - val_loss: 7.8687\n",
            "Epoch 1843/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5412 - val_loss: 7.9054\n",
            "Epoch 1844/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4692 - val_loss: 7.9651\n",
            "Epoch 1845/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4751 - val_loss: 7.9263\n",
            "Epoch 1846/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4044 - val_loss: 7.9306\n",
            "Epoch 1847/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3772 - val_loss: 7.9174\n",
            "Epoch 1848/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3670 - val_loss: 7.8986\n",
            "Epoch 1849/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4388 - val_loss: 7.8866\n",
            "Epoch 1850/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4066 - val_loss: 7.9300\n",
            "Epoch 1851/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4292 - val_loss: 7.8214\n",
            "Epoch 1852/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4429 - val_loss: 7.9231\n",
            "Epoch 1853/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4702 - val_loss: 7.9733\n",
            "Epoch 1854/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4669 - val_loss: 7.8884\n",
            "Epoch 1855/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3792 - val_loss: 7.9049\n",
            "Epoch 1856/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8351 - val_loss: 7.9792\n",
            "Epoch 1857/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5667 - val_loss: 8.0139\n",
            "Epoch 1858/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5181 - val_loss: 7.9135\n",
            "Epoch 1859/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4311 - val_loss: 7.9244\n",
            "Epoch 1860/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4137 - val_loss: 7.9262\n",
            "Epoch 1861/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3760 - val_loss: 7.9182\n",
            "Epoch 1862/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4367 - val_loss: 7.9028\n",
            "Epoch 1863/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3870 - val_loss: 7.8925\n",
            "Epoch 1864/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4330 - val_loss: 7.8240\n",
            "Epoch 1865/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3856 - val_loss: 7.9506\n",
            "Epoch 1866/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3883 - val_loss: 7.8805\n",
            "Epoch 1867/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3900 - val_loss: 7.9695\n",
            "Epoch 1868/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3949 - val_loss: 7.9211\n",
            "Epoch 1869/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3828 - val_loss: 7.9869\n",
            "Epoch 1870/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4225 - val_loss: 7.9090\n",
            "Epoch 1871/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3441 - val_loss: 7.8628\n",
            "Epoch 1872/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4968 - val_loss: 7.9574\n",
            "Epoch 1873/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5063 - val_loss: 7.9377\n",
            "Epoch 1874/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4463 - val_loss: 7.9495\n",
            "Epoch 1875/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7766 - val_loss: 7.9770\n",
            "Epoch 1876/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5693 - val_loss: 7.8811\n",
            "Epoch 1877/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5073 - val_loss: 7.9405\n",
            "Epoch 1878/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4402 - val_loss: 7.9505\n",
            "Epoch 1879/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4617 - val_loss: 7.9358\n",
            "Epoch 1880/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3771 - val_loss: 7.9273\n",
            "Epoch 1881/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 10.0512 - val_loss: 7.9708\n",
            "Epoch 1882/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8387 - val_loss: 7.9797\n",
            "Epoch 1883/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9891 - val_loss: 8.0061\n",
            "Epoch 1884/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7118 - val_loss: 7.9515\n",
            "Epoch 1885/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5299 - val_loss: 7.8652\n",
            "Epoch 1886/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3986 - val_loss: 7.9071\n",
            "Epoch 1887/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3506 - val_loss: 7.9472\n",
            "Epoch 1888/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3799 - val_loss: 7.9367\n",
            "Epoch 1889/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3684 - val_loss: 7.8751\n",
            "Epoch 1890/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3244 - val_loss: 7.8976\n",
            "Epoch 1891/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3579 - val_loss: 7.8940\n",
            "Epoch 1892/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3678 - val_loss: 7.9309\n",
            "Epoch 1893/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3881 - val_loss: 7.9108\n",
            "Epoch 1894/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3343 - val_loss: 7.8571\n",
            "Epoch 1895/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3856 - val_loss: 7.8705\n",
            "Epoch 1896/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5087 - val_loss: 7.9242\n",
            "Epoch 1897/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4711 - val_loss: 7.8592\n",
            "Epoch 1898/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3987 - val_loss: 7.8712\n",
            "Epoch 1899/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3178 - val_loss: 7.8540\n",
            "Epoch 1900/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3776 - val_loss: 7.8930\n",
            "Epoch 1901/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3992 - val_loss: 7.8441\n",
            "Epoch 1902/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3490 - val_loss: 7.8387\n",
            "Epoch 1903/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3399 - val_loss: 7.8965\n",
            "Epoch 1904/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3330 - val_loss: 7.8908\n",
            "Epoch 1905/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3444 - val_loss: 7.8330\n",
            "Epoch 1906/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6611 - val_loss: 7.9486\n",
            "Epoch 1907/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5150 - val_loss: 7.8647\n",
            "Epoch 1908/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4413 - val_loss: 7.8415\n",
            "Epoch 1909/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4082 - val_loss: 7.9013\n",
            "Epoch 1910/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3620 - val_loss: 7.8894\n",
            "Epoch 1911/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3459 - val_loss: 7.8680\n",
            "Epoch 1912/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3472 - val_loss: 7.9449\n",
            "Epoch 1913/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4221 - val_loss: 7.8522\n",
            "Epoch 1914/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4238 - val_loss: 7.9103\n",
            "Epoch 1915/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3905 - val_loss: 7.8823\n",
            "Epoch 1916/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3376 - val_loss: 7.9169\n",
            "Epoch 1917/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3892 - val_loss: 7.8893\n",
            "Epoch 1918/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.3541 - val_loss: 7.8692\n",
            "Epoch 1919/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3802 - val_loss: 7.8905\n",
            "Epoch 1920/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3502 - val_loss: 7.8586\n",
            "Epoch 1921/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3230 - val_loss: 7.8781\n",
            "Epoch 1922/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3848 - val_loss: 7.9311\n",
            "Epoch 1923/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4240 - val_loss: 7.9225\n",
            "Epoch 1924/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3142 - val_loss: 7.8595\n",
            "Epoch 1925/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4181 - val_loss: 7.8080\n",
            "Epoch 1926/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3347 - val_loss: 7.9257\n",
            "Epoch 1927/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3601 - val_loss: 7.9877\n",
            "Epoch 1928/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3911 - val_loss: 7.9307\n",
            "Epoch 1929/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3665 - val_loss: 7.8910\n",
            "Epoch 1930/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2829 - val_loss: 7.9401\n",
            "Epoch 1931/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6515 - val_loss: 7.9341\n",
            "Epoch 1932/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4337 - val_loss: 7.9466\n",
            "Epoch 1933/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3649 - val_loss: 7.9345\n",
            "Epoch 1934/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3805 - val_loss: 7.8945\n",
            "Epoch 1935/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3401 - val_loss: 7.8857\n",
            "Epoch 1936/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3185 - val_loss: 7.8559\n",
            "Epoch 1937/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2920 - val_loss: 7.8436\n",
            "Epoch 1938/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3929 - val_loss: 7.8735\n",
            "Epoch 1939/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3617 - val_loss: 7.9311\n",
            "Epoch 1940/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3572 - val_loss: 7.8435\n",
            "Epoch 1941/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3652 - val_loss: 7.9054\n",
            "Epoch 1942/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3516 - val_loss: 7.8975\n",
            "Epoch 1943/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3482 - val_loss: 7.8318\n",
            "Epoch 1944/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9199 - val_loss: 7.9099\n",
            "Epoch 1945/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.7146 - val_loss: 7.8210\n",
            "Epoch 1946/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5101 - val_loss: 7.9391\n",
            "Epoch 1947/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4660 - val_loss: 7.8623\n",
            "Epoch 1948/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3885 - val_loss: 7.8252\n",
            "Epoch 1949/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3423 - val_loss: 7.9357\n",
            "Epoch 1950/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2927 - val_loss: 7.8929\n",
            "Epoch 1951/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.4154 - val_loss: 7.8132\n",
            "Epoch 1952/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3308 - val_loss: 7.9150\n",
            "Epoch 1953/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2832 - val_loss: 7.9403\n",
            "Epoch 1954/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3094 - val_loss: 7.8565\n",
            "Epoch 1955/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4506 - val_loss: 7.9192\n",
            "Epoch 1956/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3368 - val_loss: 7.9000\n",
            "Epoch 1957/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3393 - val_loss: 7.8545\n",
            "Epoch 1958/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3462 - val_loss: 7.8893\n",
            "Epoch 1959/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3121 - val_loss: 7.9696\n",
            "Epoch 1960/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3032 - val_loss: 7.8984\n",
            "Epoch 1961/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3012 - val_loss: 7.8945\n",
            "Epoch 1962/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3159 - val_loss: 7.9239\n",
            "Epoch 1963/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2555 - val_loss: 7.9085\n",
            "Epoch 1964/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2975 - val_loss: 7.9067\n",
            "Epoch 1965/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3239 - val_loss: 7.9509\n",
            "Epoch 1966/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3001 - val_loss: 7.9307\n",
            "Epoch 1967/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2831 - val_loss: 7.9051\n",
            "Epoch 1968/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2694 - val_loss: 7.9063\n",
            "Epoch 1969/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2462 - val_loss: 7.9333\n",
            "Epoch 1970/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3453 - val_loss: 7.8829\n",
            "Epoch 1971/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3193 - val_loss: 7.8744\n",
            "Epoch 1972/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2520 - val_loss: 7.9002\n",
            "Epoch 1973/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3044 - val_loss: 7.9623\n",
            "Epoch 1974/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6676 - val_loss: 8.1400\n",
            "Epoch 1975/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4899 - val_loss: 8.0357\n",
            "Epoch 1976/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3692 - val_loss: 7.8896\n",
            "Epoch 1977/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3763 - val_loss: 7.9014\n",
            "Epoch 1978/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3009 - val_loss: 7.9061\n",
            "Epoch 1979/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3285 - val_loss: 7.8493\n",
            "Epoch 1980/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3298 - val_loss: 7.8711\n",
            "Epoch 1981/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3215 - val_loss: 7.8805\n",
            "Epoch 1982/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2820 - val_loss: 7.9057\n",
            "Epoch 1983/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2958 - val_loss: 7.9220\n",
            "Epoch 1984/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2686 - val_loss: 7.9415\n",
            "Epoch 1985/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2941 - val_loss: 7.8828\n",
            "Epoch 1986/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2548 - val_loss: 7.9553\n",
            "Epoch 1987/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2822 - val_loss: 7.9130\n",
            "Epoch 1988/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2381 - val_loss: 7.9405\n",
            "Epoch 1989/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2845 - val_loss: 7.9206\n",
            "Epoch 1990/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2732 - val_loss: 7.9361\n",
            "Epoch 1991/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2670 - val_loss: 7.8793\n",
            "Epoch 1992/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6724 - val_loss: 7.9028\n",
            "Epoch 1993/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4818 - val_loss: 7.9330\n",
            "Epoch 1994/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4007 - val_loss: 7.9094\n",
            "Epoch 1995/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3708 - val_loss: 7.9389\n",
            "Epoch 1996/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3985 - val_loss: 7.9140\n",
            "Epoch 1997/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3336 - val_loss: 8.0405\n",
            "Epoch 1998/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3694 - val_loss: 7.9214\n",
            "Epoch 1999/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2781 - val_loss: 7.9369\n",
            "Epoch 2000/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3015 - val_loss: 8.0027\n",
            "Epoch 2001/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3132 - val_loss: 7.9000\n",
            "Epoch 2002/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2830 - val_loss: 7.9170\n",
            "Epoch 2003/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2820 - val_loss: 7.9556\n",
            "Epoch 2004/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2842 - val_loss: 7.8898\n",
            "Epoch 2005/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2744 - val_loss: 7.9683\n",
            "Epoch 2006/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2765 - val_loss: 7.9095\n",
            "Epoch 2007/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3027 - val_loss: 7.9113\n",
            "Epoch 2008/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2583 - val_loss: 7.9596\n",
            "Epoch 2009/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3565 - val_loss: 7.9386\n",
            "Epoch 2010/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2860 - val_loss: 7.9101\n",
            "Epoch 2011/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3010 - val_loss: 7.8793\n",
            "Epoch 2012/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2796 - val_loss: 7.8970\n",
            "Epoch 2013/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2458 - val_loss: 7.9115\n",
            "Epoch 2014/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2871 - val_loss: 7.8819\n",
            "Epoch 2015/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2715 - val_loss: 7.9066\n",
            "Epoch 2016/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2259 - val_loss: 7.8795\n",
            "Epoch 2017/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4477 - val_loss: 7.8289\n",
            "Epoch 2018/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4453 - val_loss: 7.8384\n",
            "Epoch 2019/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3108 - val_loss: 7.8709\n",
            "Epoch 2020/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3004 - val_loss: 7.8316\n",
            "Epoch 2021/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2740 - val_loss: 7.8422\n",
            "Epoch 2022/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2450 - val_loss: 7.8521\n",
            "Epoch 2023/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2502 - val_loss: 7.8950\n",
            "Epoch 2024/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2150 - val_loss: 7.8488\n",
            "Epoch 2025/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.2874 - val_loss: 7.8203\n",
            "Epoch 2026/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2975 - val_loss: 7.8390\n",
            "Epoch 2027/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3069 - val_loss: 7.8465\n",
            "Epoch 2028/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2735 - val_loss: 7.8843\n",
            "Epoch 2029/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2406 - val_loss: 7.8544\n",
            "Epoch 2030/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2367 - val_loss: 7.8918\n",
            "Epoch 2031/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2663 - val_loss: 7.7980\n",
            "Epoch 2032/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2941 - val_loss: 7.8779\n",
            "Epoch 2033/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3913 - val_loss: 7.8603\n",
            "Epoch 2034/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3416 - val_loss: 7.8485\n",
            "Epoch 2035/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3655 - val_loss: 7.8834\n",
            "Epoch 2036/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2958 - val_loss: 7.8907\n",
            "Epoch 2037/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2277 - val_loss: 7.8185\n",
            "Epoch 2038/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2435 - val_loss: 7.8820\n",
            "Epoch 2039/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2466 - val_loss: 7.9461\n",
            "Epoch 2040/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4397 - val_loss: 7.8744\n",
            "Epoch 2041/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3770 - val_loss: 7.9493\n",
            "Epoch 2042/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2960 - val_loss: 7.9884\n",
            "Epoch 2043/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2647 - val_loss: 7.9726\n",
            "Epoch 2044/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2170 - val_loss: 7.9504\n",
            "Epoch 2045/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2206 - val_loss: 7.9504\n",
            "Epoch 2046/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3320 - val_loss: 8.0468\n",
            "Epoch 2047/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2569 - val_loss: 7.9135\n",
            "Epoch 2048/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2156 - val_loss: 7.8807\n",
            "Epoch 2049/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2256 - val_loss: 7.8898\n",
            "Epoch 2050/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2640 - val_loss: 7.8807\n",
            "Epoch 2051/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2423 - val_loss: 7.9563\n",
            "Epoch 2052/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2486 - val_loss: 7.9386\n",
            "Epoch 2053/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2045 - val_loss: 7.9058\n",
            "Epoch 2054/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2274 - val_loss: 7.9250\n",
            "Epoch 2055/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2001 - val_loss: 7.8952\n",
            "Epoch 2056/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2205 - val_loss: 7.8989\n",
            "Epoch 2057/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1885 - val_loss: 7.8599\n",
            "Epoch 2058/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2678 - val_loss: 7.9402\n",
            "Epoch 2059/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2688 - val_loss: 7.8962\n",
            "Epoch 2060/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1966 - val_loss: 7.8822\n",
            "Epoch 2061/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2062 - val_loss: 7.8665\n",
            "Epoch 2062/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1845 - val_loss: 7.8829\n",
            "Epoch 2063/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2079 - val_loss: 7.9024\n",
            "Epoch 2064/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2340 - val_loss: 7.8819\n",
            "Epoch 2065/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2829 - val_loss: 7.8999\n",
            "Epoch 2066/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3573 - val_loss: 7.8770\n",
            "Epoch 2067/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3000 - val_loss: 7.8819\n",
            "Epoch 2068/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3295 - val_loss: 7.9005\n",
            "Epoch 2069/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3575 - val_loss: 7.9137\n",
            "Epoch 2070/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2816 - val_loss: 7.9045\n",
            "Epoch 2071/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2245 - val_loss: 7.9374\n",
            "Epoch 2072/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2790 - val_loss: 7.9336\n",
            "Epoch 2073/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3476 - val_loss: 7.9420\n",
            "Epoch 2074/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2590 - val_loss: 7.9742\n",
            "Epoch 2075/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2438 - val_loss: 7.9450\n",
            "Epoch 2076/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2379 - val_loss: 7.9241\n",
            "Epoch 2077/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2255 - val_loss: 7.8619\n",
            "Epoch 2078/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2611 - val_loss: 7.9531\n",
            "Epoch 2079/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2076 - val_loss: 7.9065\n",
            "Epoch 2080/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2025 - val_loss: 7.9237\n",
            "Epoch 2081/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2123 - val_loss: 7.8885\n",
            "Epoch 2082/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2376 - val_loss: 7.8898\n",
            "Epoch 2083/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2370 - val_loss: 7.9286\n",
            "Epoch 2084/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.1921 - val_loss: 7.9343\n",
            "Epoch 2085/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5450 - val_loss: 8.1691\n",
            "Epoch 2086/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4177 - val_loss: 7.9559\n",
            "Epoch 2087/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2965 - val_loss: 7.9484\n",
            "Epoch 2088/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2154 - val_loss: 7.8993\n",
            "Epoch 2089/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2160 - val_loss: 7.8776\n",
            "Epoch 2090/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2175 - val_loss: 7.9534\n",
            "Epoch 2091/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2159 - val_loss: 7.9481\n",
            "Epoch 2092/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8131 - val_loss: 7.8935\n",
            "Epoch 2093/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.4378 - val_loss: 7.9855\n",
            "Epoch 2094/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3591 - val_loss: 7.9131\n",
            "Epoch 2095/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2468 - val_loss: 7.9047\n",
            "Epoch 2096/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2831 - val_loss: 7.8636\n",
            "Epoch 2097/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2564 - val_loss: 7.9048\n",
            "Epoch 2098/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2161 - val_loss: 7.9864\n",
            "Epoch 2099/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2748 - val_loss: 7.9337\n",
            "Epoch 2100/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2643 - val_loss: 7.8131\n",
            "Epoch 2101/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2024 - val_loss: 7.9367\n",
            "Epoch 2102/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2368 - val_loss: 7.8785\n",
            "Epoch 2103/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1778 - val_loss: 7.8979\n",
            "Epoch 2104/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1675 - val_loss: 7.8849\n",
            "Epoch 2105/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1677 - val_loss: 7.8993\n",
            "Epoch 2106/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1412 - val_loss: 7.8845\n",
            "Epoch 2107/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1994 - val_loss: 7.8857\n",
            "Epoch 2108/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1595 - val_loss: 7.9104\n",
            "Epoch 2109/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1582 - val_loss: 7.8683\n",
            "Epoch 2110/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1844 - val_loss: 7.8883\n",
            "Epoch 2111/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1763 - val_loss: 7.8893\n",
            "Epoch 2112/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1680 - val_loss: 7.8539\n",
            "Epoch 2113/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1719 - val_loss: 7.9201\n",
            "Epoch 2114/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2462 - val_loss: 7.8716\n",
            "Epoch 2115/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2135 - val_loss: 7.9213\n",
            "Epoch 2116/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2134 - val_loss: 7.8669\n",
            "Epoch 2117/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2359 - val_loss: 7.8963\n",
            "Epoch 2118/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2087 - val_loss: 7.8325\n",
            "Epoch 2119/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1780 - val_loss: 7.8654\n",
            "Epoch 2120/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2140 - val_loss: 7.8404\n",
            "Epoch 2121/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2785 - val_loss: 8.0295\n",
            "Epoch 2122/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3235 - val_loss: 7.8932\n",
            "Epoch 2123/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1926 - val_loss: 7.8839\n",
            "Epoch 2124/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1892 - val_loss: 7.9126\n",
            "Epoch 2125/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1565 - val_loss: 7.8803\n",
            "Epoch 2126/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1958 - val_loss: 7.8668\n",
            "Epoch 2127/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1716 - val_loss: 7.8639\n",
            "Epoch 2128/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1760 - val_loss: 7.8961\n",
            "Epoch 2129/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2024 - val_loss: 7.9114\n",
            "Epoch 2130/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2530 - val_loss: 7.8613\n",
            "Epoch 2131/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2468 - val_loss: 7.9261\n",
            "Epoch 2132/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1879 - val_loss: 7.8960\n",
            "Epoch 2133/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1888 - val_loss: 7.8687\n",
            "Epoch 2134/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1791 - val_loss: 7.9546\n",
            "Epoch 2135/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1532 - val_loss: 7.8633\n",
            "Epoch 2136/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2130 - val_loss: 7.8104\n",
            "Epoch 2137/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2573 - val_loss: 7.8789\n",
            "Epoch 2138/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1834 - val_loss: 7.9265\n",
            "Epoch 2139/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1842 - val_loss: 7.8374\n",
            "Epoch 2140/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2203 - val_loss: 7.8448\n",
            "Epoch 2141/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2141 - val_loss: 7.8961\n",
            "Epoch 2142/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1499 - val_loss: 7.8815\n",
            "Epoch 2143/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1606 - val_loss: 7.9150\n",
            "Epoch 2144/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2188 - val_loss: 7.8952\n",
            "Epoch 2145/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1710 - val_loss: 7.8384\n",
            "Epoch 2146/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1906 - val_loss: 7.8708\n",
            "Epoch 2147/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6300 - val_loss: 7.8778\n",
            "Epoch 2148/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4702 - val_loss: 7.9077\n",
            "Epoch 2149/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3081 - val_loss: 7.8351\n",
            "Epoch 2150/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2311 - val_loss: 7.8169\n",
            "Epoch 2151/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1821 - val_loss: 7.9200\n",
            "Epoch 2152/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1577 - val_loss: 7.8823\n",
            "Epoch 2153/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1846 - val_loss: 7.9273\n",
            "Epoch 2154/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1673 - val_loss: 7.8478\n",
            "Epoch 2155/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2712 - val_loss: 7.8604\n",
            "Epoch 2156/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2118 - val_loss: 7.8909\n",
            "Epoch 2157/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2434 - val_loss: 7.8540\n",
            "Epoch 2158/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2243 - val_loss: 7.8806\n",
            "Epoch 2159/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2122 - val_loss: 7.8975\n",
            "Epoch 2160/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2001 - val_loss: 7.8391\n",
            "Epoch 2161/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2118 - val_loss: 7.8437\n",
            "Epoch 2162/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.5054 - val_loss: 7.9246\n",
            "Epoch 2163/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4963 - val_loss: 7.8553\n",
            "Epoch 2164/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3469 - val_loss: 7.9384\n",
            "Epoch 2165/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2795 - val_loss: 7.9130\n",
            "Epoch 2166/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2021 - val_loss: 7.9351\n",
            "Epoch 2167/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1976 - val_loss: 7.9266\n",
            "Epoch 2168/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1335 - val_loss: 7.8993\n",
            "Epoch 2169/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1506 - val_loss: 7.9029\n",
            "Epoch 2170/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2518 - val_loss: 7.9284\n",
            "Epoch 2171/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2418 - val_loss: 7.8578\n",
            "Epoch 2172/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1965 - val_loss: 7.8862\n",
            "Epoch 2173/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2008 - val_loss: 7.9353\n",
            "Epoch 2174/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1519 - val_loss: 7.9040\n",
            "Epoch 2175/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1366 - val_loss: 7.8579\n",
            "Epoch 2176/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1643 - val_loss: 7.9264\n",
            "Epoch 2177/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1418 - val_loss: 7.8721\n",
            "Epoch 2178/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1159 - val_loss: 7.8809\n",
            "Epoch 2179/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1064 - val_loss: 7.8967\n",
            "Epoch 2180/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2012 - val_loss: 7.9008\n",
            "Epoch 2181/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1564 - val_loss: 7.8851\n",
            "Epoch 2182/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1101 - val_loss: 7.8343\n",
            "Epoch 2183/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5116 - val_loss: 7.7675\n",
            "Epoch 2184/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0071 - val_loss: 7.8716\n",
            "Epoch 2185/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6236 - val_loss: 7.8997\n",
            "Epoch 2186/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3245 - val_loss: 7.9397\n",
            "Epoch 2187/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3086 - val_loss: 7.8611\n",
            "Epoch 2188/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2586 - val_loss: 7.9244\n",
            "Epoch 2189/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1810 - val_loss: 7.8936\n",
            "Epoch 2190/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1253 - val_loss: 7.8816\n",
            "Epoch 2191/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1659 - val_loss: 7.8990\n",
            "Epoch 2192/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1128 - val_loss: 7.8761\n",
            "Epoch 2193/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2906 - val_loss: 7.9229\n",
            "Epoch 2194/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2232 - val_loss: 7.8359\n",
            "Epoch 2195/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1692 - val_loss: 7.8580\n",
            "Epoch 2196/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1078 - val_loss: 7.9457\n",
            "Epoch 2197/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1554 - val_loss: 7.8674\n",
            "Epoch 2198/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1196 - val_loss: 7.8850\n",
            "Epoch 2199/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1079 - val_loss: 7.8761\n",
            "Epoch 2200/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1980 - val_loss: 7.8210\n",
            "Epoch 2201/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1294 - val_loss: 7.9225\n",
            "Epoch 2202/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1552 - val_loss: 7.8264\n",
            "Epoch 2203/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1318 - val_loss: 7.9111\n",
            "Epoch 2204/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1290 - val_loss: 7.8629\n",
            "Epoch 2205/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1256 - val_loss: 7.8347\n",
            "Epoch 2206/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3222 - val_loss: 7.8677\n",
            "Epoch 2207/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2815 - val_loss: 7.8267\n",
            "Epoch 2208/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2013 - val_loss: 7.8519\n",
            "Epoch 2209/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2319 - val_loss: 7.8979\n",
            "Epoch 2210/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1681 - val_loss: 7.8465\n",
            "Epoch 2211/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1262 - val_loss: 7.8569\n",
            "Epoch 2212/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1212 - val_loss: 7.8743\n",
            "Epoch 2213/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0835 - val_loss: 7.8018\n",
            "Epoch 2214/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2008 - val_loss: 7.9417\n",
            "Epoch 2215/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1815 - val_loss: 7.9074\n",
            "Epoch 2216/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1662 - val_loss: 7.9097\n",
            "Epoch 2217/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0947 - val_loss: 7.8662\n",
            "Epoch 2218/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0829 - val_loss: 7.8997\n",
            "Epoch 2219/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2473 - val_loss: 7.8182\n",
            "Epoch 2220/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1996 - val_loss: 7.8978\n",
            "Epoch 2221/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1449 - val_loss: 7.8146\n",
            "Epoch 2222/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1671 - val_loss: 7.8754\n",
            "Epoch 2223/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3553 - val_loss: 7.9307\n",
            "Epoch 2224/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8424 - val_loss: 7.9985\n",
            "Epoch 2225/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5789 - val_loss: 7.9581\n",
            "Epoch 2226/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3281 - val_loss: 7.8907\n",
            "Epoch 2227/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2171 - val_loss: 7.8354\n",
            "Epoch 2228/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1921 - val_loss: 7.8566\n",
            "Epoch 2229/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1092 - val_loss: 7.8689\n",
            "Epoch 2230/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1102 - val_loss: 7.8903\n",
            "Epoch 2231/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1110 - val_loss: 7.9139\n",
            "Epoch 2232/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9281 - val_loss: 8.1807\n",
            "Epoch 2233/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9141 - val_loss: 8.0898\n",
            "Epoch 2234/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5467 - val_loss: 7.9506\n",
            "Epoch 2235/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4144 - val_loss: 7.9747\n",
            "Epoch 2236/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3044 - val_loss: 7.9818\n",
            "Epoch 2237/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2696 - val_loss: 7.8747\n",
            "Epoch 2238/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2500 - val_loss: 7.9298\n",
            "Epoch 2239/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2043 - val_loss: 7.9353\n",
            "Epoch 2240/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1708 - val_loss: 7.8590\n",
            "Epoch 2241/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1500 - val_loss: 7.8829\n",
            "Epoch 2242/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1457 - val_loss: 7.8709\n",
            "Epoch 2243/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1215 - val_loss: 7.8491\n",
            "Epoch 2244/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1101 - val_loss: 7.8939\n",
            "Epoch 2245/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1099 - val_loss: 7.8342\n",
            "Epoch 2246/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1303 - val_loss: 7.8566\n",
            "Epoch 2247/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1303 - val_loss: 7.8477\n",
            "Epoch 2248/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0921 - val_loss: 7.8127\n",
            "Epoch 2249/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0711 - val_loss: 7.8958\n",
            "Epoch 2250/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0880 - val_loss: 7.8523\n",
            "Epoch 2251/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0881 - val_loss: 7.8618\n",
            "Epoch 2252/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1125 - val_loss: 7.8582\n",
            "Epoch 2253/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0747 - val_loss: 7.8771\n",
            "Epoch 2254/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0577 - val_loss: 7.8938\n",
            "Epoch 2255/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0341 - val_loss: 7.8181\n",
            "Epoch 2256/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0881 - val_loss: 7.8711\n",
            "Epoch 2257/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0690 - val_loss: 7.8844\n",
            "Epoch 2258/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0732 - val_loss: 7.8648\n",
            "Epoch 2259/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0530 - val_loss: 7.8056\n",
            "Epoch 2260/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0358 - val_loss: 7.8821\n",
            "Epoch 2261/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0609 - val_loss: 7.8694\n",
            "Epoch 2262/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0463 - val_loss: 7.8943\n",
            "Epoch 2263/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0748 - val_loss: 7.8402\n",
            "Epoch 2264/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0554 - val_loss: 7.8420\n",
            "Epoch 2265/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0540 - val_loss: 7.8106\n",
            "Epoch 2266/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0604 - val_loss: 7.9022\n",
            "Epoch 2267/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0975 - val_loss: 7.8514\n",
            "Epoch 2268/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1814 - val_loss: 7.8070\n",
            "Epoch 2269/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0807 - val_loss: 7.8736\n",
            "Epoch 2270/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0581 - val_loss: 7.8955\n",
            "Epoch 2271/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1084 - val_loss: 7.8635\n",
            "Epoch 2272/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0462 - val_loss: 7.8685\n",
            "Epoch 2273/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0726 - val_loss: 7.8960\n",
            "Epoch 2274/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0703 - val_loss: 7.8262\n",
            "Epoch 2275/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0822 - val_loss: 7.8589\n",
            "Epoch 2276/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1997 - val_loss: 7.8970\n",
            "Epoch 2277/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0964 - val_loss: 7.9290\n",
            "Epoch 2278/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1192 - val_loss: 7.9195\n",
            "Epoch 2279/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0701 - val_loss: 7.8916\n",
            "Epoch 2280/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0788 - val_loss: 7.8481\n",
            "Epoch 2281/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0893 - val_loss: 7.9000\n",
            "Epoch 2282/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0695 - val_loss: 7.8707\n",
            "Epoch 2283/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0689 - val_loss: 7.8772\n",
            "Epoch 2284/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0566 - val_loss: 7.9094\n",
            "Epoch 2285/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0684 - val_loss: 7.8660\n",
            "Epoch 2286/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1029 - val_loss: 7.8590\n",
            "Epoch 2287/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0774 - val_loss: 7.8933\n",
            "Epoch 2288/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0567 - val_loss: 7.8798\n",
            "Epoch 2289/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0492 - val_loss: 7.9241\n",
            "Epoch 2290/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0408 - val_loss: 7.9178\n",
            "Epoch 2291/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0517 - val_loss: 7.8826\n",
            "Epoch 2292/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0363 - val_loss: 7.9463\n",
            "Epoch 2293/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.9805 - val_loss: 8.2562\n",
            "Epoch 2294/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.9793 - val_loss: 8.0887\n",
            "Epoch 2295/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5779 - val_loss: 7.9939\n",
            "Epoch 2296/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3813 - val_loss: 7.9694\n",
            "Epoch 2297/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2953 - val_loss: 7.8729\n",
            "Epoch 2298/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2940 - val_loss: 7.9065\n",
            "Epoch 2299/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1510 - val_loss: 7.9087\n",
            "Epoch 2300/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1336 - val_loss: 7.8874\n",
            "Epoch 2301/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1391 - val_loss: 7.8641\n",
            "Epoch 2302/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1170 - val_loss: 7.9174\n",
            "Epoch 2303/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1188 - val_loss: 7.8674\n",
            "Epoch 2304/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1378 - val_loss: 7.8284\n",
            "Epoch 2305/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1474 - val_loss: 7.8630\n",
            "Epoch 2306/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0573 - val_loss: 7.8593\n",
            "Epoch 2307/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0541 - val_loss: 7.8643\n",
            "Epoch 2308/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0667 - val_loss: 7.8944\n",
            "Epoch 2309/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0605 - val_loss: 7.8451\n",
            "Epoch 2310/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0572 - val_loss: 7.8541\n",
            "Epoch 2311/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0563 - val_loss: 7.8635\n",
            "Epoch 2312/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0960 - val_loss: 7.8398\n",
            "Epoch 2313/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0425 - val_loss: 7.9170\n",
            "Epoch 2314/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0567 - val_loss: 7.8577\n",
            "Epoch 2315/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0530 - val_loss: 7.8358\n",
            "Epoch 2316/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0398 - val_loss: 7.8591\n",
            "Epoch 2317/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0186 - val_loss: 7.9030\n",
            "Epoch 2318/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0609 - val_loss: 7.8762\n",
            "Epoch 2319/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0739 - val_loss: 7.9034\n",
            "Epoch 2320/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0258 - val_loss: 7.8692\n",
            "Epoch 2321/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0121 - val_loss: 7.8389\n",
            "Epoch 2322/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0123 - val_loss: 7.8466\n",
            "Epoch 2323/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0540 - val_loss: 7.8497\n",
            "Epoch 2324/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0447 - val_loss: 7.8633\n",
            "Epoch 2325/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0285 - val_loss: 7.8380\n",
            "Epoch 2326/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0289 - val_loss: 7.8690\n",
            "Epoch 2327/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0224 - val_loss: 7.8453\n",
            "Epoch 2328/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0608 - val_loss: 7.8824\n",
            "Epoch 2329/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0539 - val_loss: 7.8551\n",
            "Epoch 2330/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1332 - val_loss: 7.8814\n",
            "Epoch 2331/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1441 - val_loss: 7.9105\n",
            "Epoch 2332/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0730 - val_loss: 7.9623\n",
            "Epoch 2333/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0881 - val_loss: 7.8797\n",
            "Epoch 2334/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0211 - val_loss: 7.9027\n",
            "Epoch 2335/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1687 - val_loss: 7.9180\n",
            "Epoch 2336/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1108 - val_loss: 7.8776\n",
            "Epoch 2337/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1008 - val_loss: 7.8923\n",
            "Epoch 2338/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0856 - val_loss: 7.8705\n",
            "Epoch 2339/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0480 - val_loss: 7.8445\n",
            "Epoch 2340/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0552 - val_loss: 7.8870\n",
            "Epoch 2341/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0554 - val_loss: 7.8595\n",
            "Epoch 2342/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0424 - val_loss: 7.8573\n",
            "Epoch 2343/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0869 - val_loss: 7.8845\n",
            "Epoch 2344/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0510 - val_loss: 7.8381\n",
            "Epoch 2345/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3091 - val_loss: 8.0754\n",
            "Epoch 2346/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2345 - val_loss: 8.0090\n",
            "Epoch 2347/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0889 - val_loss: 7.8744\n",
            "Epoch 2348/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0995 - val_loss: 7.8379\n",
            "Epoch 2349/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0457 - val_loss: 7.9107\n",
            "Epoch 2350/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1123 - val_loss: 7.8821\n",
            "Epoch 2351/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1800 - val_loss: 7.8606\n",
            "Epoch 2352/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1116 - val_loss: 7.9025\n",
            "Epoch 2353/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0489 - val_loss: 7.8994\n",
            "Epoch 2354/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0244 - val_loss: 7.8254\n",
            "Epoch 2355/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0001 - val_loss: 7.8355\n",
            "Epoch 2356/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0128 - val_loss: 7.7664\n",
            "Epoch 2357/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0369 - val_loss: 7.8146\n",
            "Epoch 2358/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0489 - val_loss: 7.8074\n",
            "Epoch 2359/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0081 - val_loss: 7.8679\n",
            "Epoch 2360/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0341 - val_loss: 7.8682\n",
            "Epoch 2361/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0567 - val_loss: 7.8362\n",
            "Epoch 2362/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0694 - val_loss: 7.8550\n",
            "Epoch 2363/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9879 - val_loss: 7.7986\n",
            "Epoch 2364/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0223 - val_loss: 7.8148\n",
            "Epoch 2365/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0691 - val_loss: 7.8709\n",
            "Epoch 2366/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0960 - val_loss: 7.8069\n",
            "Epoch 2367/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0941 - val_loss: 7.8960\n",
            "Epoch 2368/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0776 - val_loss: 7.8373\n",
            "Epoch 2369/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0370 - val_loss: 7.8574\n",
            "Epoch 2370/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0161 - val_loss: 7.8034\n",
            "Epoch 2371/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9991 - val_loss: 7.8134\n",
            "Epoch 2372/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0198 - val_loss: 7.8754\n",
            "Epoch 2373/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0206 - val_loss: 7.8119\n",
            "Epoch 2374/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9755 - val_loss: 7.8581\n",
            "Epoch 2375/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0077 - val_loss: 7.8228\n",
            "Epoch 2376/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0136 - val_loss: 7.8798\n",
            "Epoch 2377/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1123 - val_loss: 7.7903\n",
            "Epoch 2378/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0274 - val_loss: 7.7799\n",
            "Epoch 2379/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0927 - val_loss: 7.8441\n",
            "Epoch 2380/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9970 - val_loss: 7.8891\n",
            "Epoch 2381/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0213 - val_loss: 7.8269\n",
            "Epoch 2382/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0244 - val_loss: 7.8535\n",
            "Epoch 2383/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0039 - val_loss: 7.8115\n",
            "Epoch 2384/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0302 - val_loss: 7.8136\n",
            "Epoch 2385/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9983 - val_loss: 7.7666\n",
            "Epoch 2386/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9818 - val_loss: 7.8473\n",
            "Epoch 2387/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9903 - val_loss: 7.8045\n",
            "Epoch 2388/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0298 - val_loss: 7.8187\n",
            "Epoch 2389/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0350 - val_loss: 7.7714\n",
            "Epoch 2390/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0189 - val_loss: 7.8521\n",
            "Epoch 2391/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0913 - val_loss: 7.8042\n",
            "Epoch 2392/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0353 - val_loss: 7.8515\n",
            "Epoch 2393/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3080 - val_loss: 7.8671\n",
            "Epoch 2394/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1459 - val_loss: 7.8908\n",
            "Epoch 2395/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1069 - val_loss: 7.8188\n",
            "Epoch 2396/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.0153 - val_loss: 7.8045\n",
            "Epoch 2397/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.8342 - val_loss: 7.7344\n",
            "Epoch 2398/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5445 - val_loss: 7.8105\n",
            "Epoch 2399/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3666 - val_loss: 7.8337\n",
            "Epoch 2400/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1920 - val_loss: 7.8153\n",
            "Epoch 2401/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1226 - val_loss: 7.8068\n",
            "Epoch 2402/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1717 - val_loss: 7.8215\n",
            "Epoch 2403/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1816 - val_loss: 7.8572\n",
            "Epoch 2404/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1089 - val_loss: 7.8863\n",
            "Epoch 2405/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0623 - val_loss: 7.8284\n",
            "Epoch 2406/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0286 - val_loss: 7.8802\n",
            "Epoch 2407/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0500 - val_loss: 7.9065\n",
            "Epoch 2408/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0264 - val_loss: 7.8269\n",
            "Epoch 2409/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9833 - val_loss: 7.8377\n",
            "Epoch 2410/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0154 - val_loss: 7.8313\n",
            "Epoch 2411/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0213 - val_loss: 7.8657\n",
            "Epoch 2412/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0372 - val_loss: 7.8122\n",
            "Epoch 2413/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9787 - val_loss: 7.8426\n",
            "Epoch 2414/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9941 - val_loss: 7.8114\n",
            "Epoch 2415/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9603 - val_loss: 7.7950\n",
            "Epoch 2416/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0059 - val_loss: 7.8369\n",
            "Epoch 2417/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9974 - val_loss: 7.8483\n",
            "Epoch 2418/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0219 - val_loss: 7.7902\n",
            "Epoch 2419/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9904 - val_loss: 7.8681\n",
            "Epoch 2420/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9928 - val_loss: 7.7876\n",
            "Epoch 2421/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9627 - val_loss: 7.7936\n",
            "Epoch 2422/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9775 - val_loss: 7.8014\n",
            "Epoch 2423/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9777 - val_loss: 7.8190\n",
            "Epoch 2424/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9608 - val_loss: 7.8516\n",
            "Epoch 2425/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9832 - val_loss: 7.7622\n",
            "Epoch 2426/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9699 - val_loss: 7.8346\n",
            "Epoch 2427/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9964 - val_loss: 7.7597\n",
            "Epoch 2428/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9745 - val_loss: 7.8237\n",
            "Epoch 2429/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9810 - val_loss: 7.8105\n",
            "Epoch 2430/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0565 - val_loss: 7.7764\n",
            "Epoch 2431/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0947 - val_loss: 7.8440\n",
            "Epoch 2432/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0185 - val_loss: 7.8992\n",
            "Epoch 2433/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9984 - val_loss: 7.8683\n",
            "Epoch 2434/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9632 - val_loss: 7.8245\n",
            "Epoch 2435/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9769 - val_loss: 7.8452\n",
            "Epoch 2436/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9301 - val_loss: 7.8144\n",
            "Epoch 2437/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9712 - val_loss: 7.8174\n",
            "Epoch 2438/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9977 - val_loss: 7.7844\n",
            "Epoch 2439/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0106 - val_loss: 7.8299\n",
            "Epoch 2440/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9970 - val_loss: 7.7669\n",
            "Epoch 2441/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0712 - val_loss: 7.9082\n",
            "Epoch 2442/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0541 - val_loss: 7.8567\n",
            "Epoch 2443/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9567 - val_loss: 7.8120\n",
            "Epoch 2444/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9616 - val_loss: 7.8345\n",
            "Epoch 2445/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9763 - val_loss: 7.8115\n",
            "Epoch 2446/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9964 - val_loss: 7.8163\n",
            "Epoch 2447/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9532 - val_loss: 7.8620\n",
            "Epoch 2448/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0078 - val_loss: 7.8303\n",
            "Epoch 2449/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9744 - val_loss: 7.8146\n",
            "Epoch 2450/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9829 - val_loss: 7.8146\n",
            "Epoch 2451/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9287 - val_loss: 7.8420\n",
            "Epoch 2452/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9588 - val_loss: 7.8103\n",
            "Epoch 2453/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9262 - val_loss: 7.8293\n",
            "Epoch 2454/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9439 - val_loss: 7.8167\n",
            "Epoch 2455/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9845 - val_loss: 7.7884\n",
            "Epoch 2456/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0905 - val_loss: 7.8694\n",
            "Epoch 2457/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9568 - val_loss: 7.8262\n",
            "Epoch 2458/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9618 - val_loss: 7.8059\n",
            "Epoch 2459/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9076 - val_loss: 7.8121\n",
            "Epoch 2460/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9680 - val_loss: 7.8179\n",
            "Epoch 2461/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9235 - val_loss: 7.8228\n",
            "Epoch 2462/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9663 - val_loss: 7.8627\n",
            "Epoch 2463/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9321 - val_loss: 7.7961\n",
            "Epoch 2464/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9385 - val_loss: 7.8038\n",
            "Epoch 2465/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9440 - val_loss: 7.8352\n",
            "Epoch 2466/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9394 - val_loss: 7.8335\n",
            "Epoch 2467/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9459 - val_loss: 7.7516\n",
            "Epoch 2468/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9540 - val_loss: 7.8278\n",
            "Epoch 2469/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9928 - val_loss: 7.8233\n",
            "Epoch 2470/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9759 - val_loss: 7.7689\n",
            "Epoch 2471/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0147 - val_loss: 7.8372\n",
            "Epoch 2472/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0744 - val_loss: 7.8325\n",
            "Epoch 2473/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0543 - val_loss: 7.8433\n",
            "Epoch 2474/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9837 - val_loss: 7.8637\n",
            "Epoch 2475/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0048 - val_loss: 7.7981\n",
            "Epoch 2476/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2517 - val_loss: 7.7860\n",
            "Epoch 2477/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1263 - val_loss: 7.8849\n",
            "Epoch 2478/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0499 - val_loss: 7.8511\n",
            "Epoch 2479/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0559 - val_loss: 7.8476\n",
            "Epoch 2480/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0648 - val_loss: 7.8281\n",
            "Epoch 2481/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9905 - val_loss: 7.8086\n",
            "Epoch 2482/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0691 - val_loss: 7.8095\n",
            "Epoch 2483/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0368 - val_loss: 7.8790\n",
            "Epoch 2484/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0652 - val_loss: 7.8165\n",
            "Epoch 2485/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9877 - val_loss: 7.8459\n",
            "Epoch 2486/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9947 - val_loss: 7.8777\n",
            "Epoch 2487/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9845 - val_loss: 7.8737\n",
            "Epoch 2488/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9376 - val_loss: 7.8433\n",
            "Epoch 2489/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0190 - val_loss: 7.8111\n",
            "Epoch 2490/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9861 - val_loss: 7.7796\n",
            "Epoch 2491/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0104 - val_loss: 7.8805\n",
            "Epoch 2492/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0246 - val_loss: 7.8710\n",
            "Epoch 2493/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9875 - val_loss: 7.8287\n",
            "Epoch 2494/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9530 - val_loss: 7.7979\n",
            "Epoch 2495/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0246 - val_loss: 7.8930\n",
            "Epoch 2496/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0359 - val_loss: 7.8751\n",
            "Epoch 2497/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0450 - val_loss: 7.9071\n",
            "Epoch 2498/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.0365 - val_loss: 7.7402\n",
            "Epoch 2499/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0400 - val_loss: 7.8507\n",
            "Epoch 2500/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0514 - val_loss: 7.8966\n",
            "Epoch 2501/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0033 - val_loss: 7.8642\n",
            "Epoch 2502/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9757 - val_loss: 7.8922\n",
            "Epoch 2503/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9684 - val_loss: 7.9077\n",
            "Epoch 2504/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9514 - val_loss: 7.8335\n",
            "Epoch 2505/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9706 - val_loss: 7.8489\n",
            "Epoch 2506/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9310 - val_loss: 7.8705\n",
            "Epoch 2507/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9517 - val_loss: 7.8725\n",
            "Epoch 2508/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9169 - val_loss: 7.8213\n",
            "Epoch 2509/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9507 - val_loss: 7.8357\n",
            "Epoch 2510/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9208 - val_loss: 7.8630\n",
            "Epoch 2511/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9619 - val_loss: 7.8036\n",
            "Epoch 2512/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2053 - val_loss: 7.8275\n",
            "Epoch 2513/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1858 - val_loss: 7.8267\n",
            "Epoch 2514/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1410 - val_loss: 7.9896\n",
            "Epoch 2515/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0193 - val_loss: 7.8893\n",
            "Epoch 2516/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9924 - val_loss: 7.8684\n",
            "Epoch 2517/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9867 - val_loss: 7.8766\n",
            "Epoch 2518/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9572 - val_loss: 7.8818\n",
            "Epoch 2519/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3416 - val_loss: 7.9477\n",
            "Epoch 2520/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1709 - val_loss: 7.9179\n",
            "Epoch 2521/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0548 - val_loss: 7.8209\n",
            "Epoch 2522/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0056 - val_loss: 7.9020\n",
            "Epoch 2523/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0163 - val_loss: 7.8784\n",
            "Epoch 2524/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9832 - val_loss: 7.9208\n",
            "Epoch 2525/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9537 - val_loss: 7.8623\n",
            "Epoch 2526/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9643 - val_loss: 7.8819\n",
            "Epoch 2527/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9870 - val_loss: 7.8562\n",
            "Epoch 2528/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9755 - val_loss: 7.8247\n",
            "Epoch 2529/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0660 - val_loss: 7.8230\n",
            "Epoch 2530/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9713 - val_loss: 7.8217\n",
            "Epoch 2531/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9372 - val_loss: 7.8050\n",
            "Epoch 2532/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9036 - val_loss: 7.8678\n",
            "Epoch 2533/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9130 - val_loss: 7.8099\n",
            "Epoch 2534/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8850 - val_loss: 7.8073\n",
            "Epoch 2535/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9144 - val_loss: 7.8131\n",
            "Epoch 2536/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9157 - val_loss: 7.8413\n",
            "Epoch 2537/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9182 - val_loss: 7.8433\n",
            "Epoch 2538/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9162 - val_loss: 7.8517\n",
            "Epoch 2539/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9487 - val_loss: 7.8727\n",
            "Epoch 2540/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9145 - val_loss: 7.8918\n",
            "Epoch 2541/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9145 - val_loss: 7.8982\n",
            "Epoch 2542/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9686 - val_loss: 7.8626\n",
            "Epoch 2543/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9491 - val_loss: 7.9032\n",
            "Epoch 2544/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9789 - val_loss: 7.8103\n",
            "Epoch 2545/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9097 - val_loss: 7.8736\n",
            "Epoch 2546/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9440 - val_loss: 7.8715\n",
            "Epoch 2547/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9123 - val_loss: 7.7768\n",
            "Epoch 2548/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9290 - val_loss: 7.8384\n",
            "Epoch 2549/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9580 - val_loss: 7.8380\n",
            "Epoch 2550/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9601 - val_loss: 7.8179\n",
            "Epoch 2551/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9263 - val_loss: 7.8729\n",
            "Epoch 2552/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8998 - val_loss: 7.8815\n",
            "Epoch 2553/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9274 - val_loss: 7.8315\n",
            "Epoch 2554/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3036 - val_loss: 7.9114\n",
            "Epoch 2555/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1245 - val_loss: 7.8828\n",
            "Epoch 2556/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0264 - val_loss: 7.7963\n",
            "Epoch 2557/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0243 - val_loss: 7.8409\n",
            "Epoch 2558/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9517 - val_loss: 7.8842\n",
            "Epoch 2559/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9429 - val_loss: 7.8640\n",
            "Epoch 2560/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9121 - val_loss: 7.8741\n",
            "Epoch 2561/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9310 - val_loss: 7.8539\n",
            "Epoch 2562/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8978 - val_loss: 7.9093\n",
            "Epoch 2563/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9218 - val_loss: 7.8491\n",
            "Epoch 2564/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9053 - val_loss: 7.7740\n",
            "Epoch 2565/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9400 - val_loss: 7.9324\n",
            "Epoch 2566/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9037 - val_loss: 7.8684\n",
            "Epoch 2567/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9300 - val_loss: 7.8487\n",
            "Epoch 2568/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8922 - val_loss: 7.8016\n",
            "Epoch 2569/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8862 - val_loss: 7.8382\n",
            "Epoch 2570/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9358 - val_loss: 7.8024\n",
            "Epoch 2571/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9715 - val_loss: 7.8552\n",
            "Epoch 2572/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9791 - val_loss: 7.8931\n",
            "Epoch 2573/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9288 - val_loss: 7.8623\n",
            "Epoch 2574/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9389 - val_loss: 7.8245\n",
            "Epoch 2575/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9264 - val_loss: 7.8956\n",
            "Epoch 2576/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9343 - val_loss: 7.7423\n",
            "Epoch 2577/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2243 - val_loss: 7.8900\n",
            "Epoch 2578/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0754 - val_loss: 7.8365\n",
            "Epoch 2579/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9521 - val_loss: 7.8225\n",
            "Epoch 2580/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9273 - val_loss: 7.8202\n",
            "Epoch 2581/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9719 - val_loss: 7.8695\n",
            "Epoch 2582/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9588 - val_loss: 7.8103\n",
            "Epoch 2583/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9463 - val_loss: 7.8972\n",
            "Epoch 2584/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9382 - val_loss: 7.8914\n",
            "Epoch 2585/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9102 - val_loss: 7.8406\n",
            "Epoch 2586/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9091 - val_loss: 7.9128\n",
            "Epoch 2587/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9224 - val_loss: 7.8584\n",
            "Epoch 2588/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8911 - val_loss: 7.8688\n",
            "Epoch 2589/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8757 - val_loss: 7.8384\n",
            "Epoch 2590/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8822 - val_loss: 7.9147\n",
            "Epoch 2591/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8986 - val_loss: 7.8462\n",
            "Epoch 2592/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8606 - val_loss: 7.8975\n",
            "Epoch 2593/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9047 - val_loss: 7.8720\n",
            "Epoch 2594/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8996 - val_loss: 7.8904\n",
            "Epoch 2595/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9177 - val_loss: 7.8866\n",
            "Epoch 2596/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9287 - val_loss: 7.8335\n",
            "Epoch 2597/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9214 - val_loss: 7.8269\n",
            "Epoch 2598/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9246 - val_loss: 7.8835\n",
            "Epoch 2599/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2124 - val_loss: 7.8545\n",
            "Epoch 2600/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1368 - val_loss: 7.7621\n",
            "Epoch 2601/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9754 - val_loss: 7.7887\n",
            "Epoch 2602/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9634 - val_loss: 7.8433\n",
            "Epoch 2603/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9604 - val_loss: 7.8922\n",
            "Epoch 2604/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9157 - val_loss: 7.8390\n",
            "Epoch 2605/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9080 - val_loss: 7.8604\n",
            "Epoch 2606/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8884 - val_loss: 7.8652\n",
            "Epoch 2607/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9484 - val_loss: 7.8271\n",
            "Epoch 2608/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8926 - val_loss: 7.8627\n",
            "Epoch 2609/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8789 - val_loss: 7.8697\n",
            "Epoch 2610/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9070 - val_loss: 7.8151\n",
            "Epoch 2611/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8807 - val_loss: 7.8148\n",
            "Epoch 2612/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9182 - val_loss: 7.8560\n",
            "Epoch 2613/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9061 - val_loss: 7.8029\n",
            "Epoch 2614/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9741 - val_loss: 7.8132\n",
            "Epoch 2615/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9790 - val_loss: 7.8468\n",
            "Epoch 2616/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9347 - val_loss: 7.8838\n",
            "Epoch 2617/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9008 - val_loss: 7.9041\n",
            "Epoch 2618/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0081 - val_loss: 7.9076\n",
            "Epoch 2619/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9730 - val_loss: 7.8474\n",
            "Epoch 2620/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9144 - val_loss: 7.8595\n",
            "Epoch 2621/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8865 - val_loss: 7.8855\n",
            "Epoch 2622/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9433 - val_loss: 7.8366\n",
            "Epoch 2623/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8771 - val_loss: 7.7982\n",
            "Epoch 2624/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8886 - val_loss: 7.8495\n",
            "Epoch 2625/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8941 - val_loss: 7.8053\n",
            "Epoch 2626/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9042 - val_loss: 7.8934\n",
            "Epoch 2627/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9005 - val_loss: 7.9061\n",
            "Epoch 2628/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9425 - val_loss: 7.8527\n",
            "Epoch 2629/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9177 - val_loss: 7.7834\n",
            "Epoch 2630/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9674 - val_loss: 7.7455\n",
            "Epoch 2631/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9223 - val_loss: 7.8641\n",
            "Epoch 2632/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8938 - val_loss: 7.8136\n",
            "Epoch 2633/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8796 - val_loss: 7.8103\n",
            "Epoch 2634/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8847 - val_loss: 7.8226\n",
            "Epoch 2635/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8753 - val_loss: 7.8175\n",
            "Epoch 2636/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8602 - val_loss: 7.8523\n",
            "Epoch 2637/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8574 - val_loss: 7.7755\n",
            "Epoch 2638/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8784 - val_loss: 7.7673\n",
            "Epoch 2639/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.5056 - val_loss: 8.0633\n",
            "Epoch 2640/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2753 - val_loss: 7.9269\n",
            "Epoch 2641/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0523 - val_loss: 7.9418\n",
            "Epoch 2642/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9616 - val_loss: 7.8404\n",
            "Epoch 2643/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8955 - val_loss: 7.8680\n",
            "Epoch 2644/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8993 - val_loss: 7.8415\n",
            "Epoch 2645/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9135 - val_loss: 7.8211\n",
            "Epoch 2646/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8845 - val_loss: 7.8432\n",
            "Epoch 2647/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8863 - val_loss: 7.8567\n",
            "Epoch 2648/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8723 - val_loss: 7.9433\n",
            "Epoch 2649/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8773 - val_loss: 7.8201\n",
            "Epoch 2650/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8841 - val_loss: 7.7988\n",
            "Epoch 2651/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9601 - val_loss: 7.8418\n",
            "Epoch 2652/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9239 - val_loss: 7.9154\n",
            "Epoch 2653/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8902 - val_loss: 7.8543\n",
            "Epoch 2654/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9983 - val_loss: 7.8402\n",
            "Epoch 2655/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9702 - val_loss: 7.9072\n",
            "Epoch 2656/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8648 - val_loss: 7.8534\n",
            "Epoch 2657/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8700 - val_loss: 7.8074\n",
            "Epoch 2658/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8408 - val_loss: 7.7987\n",
            "Epoch 2659/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8384 - val_loss: 7.8698\n",
            "Epoch 2660/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8373 - val_loss: 7.8526\n",
            "Epoch 2661/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8606 - val_loss: 7.8046\n",
            "Epoch 2662/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8718 - val_loss: 7.8512\n",
            "Epoch 2663/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8504 - val_loss: 7.8674\n",
            "Epoch 2664/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8442 - val_loss: 7.7608\n",
            "Epoch 2665/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9030 - val_loss: 7.7505\n",
            "Epoch 2666/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8864 - val_loss: 7.7384\n",
            "Epoch 2667/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9083 - val_loss: 7.8398\n",
            "Epoch 2668/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8731 - val_loss: 7.7438\n",
            "Epoch 2669/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8624 - val_loss: 7.7886\n",
            "Epoch 2670/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9715 - val_loss: 7.9298\n",
            "Epoch 2671/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8772 - val_loss: 7.8203\n",
            "Epoch 2672/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8923 - val_loss: 7.8154\n",
            "Epoch 2673/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8751 - val_loss: 7.8406\n",
            "Epoch 2674/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0132 - val_loss: 7.9058\n",
            "Epoch 2675/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9983 - val_loss: 7.8674\n",
            "Epoch 2676/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8672 - val_loss: 7.8457\n",
            "Epoch 2677/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8455 - val_loss: 7.8051\n",
            "Epoch 2678/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8612 - val_loss: 7.8401\n",
            "Epoch 2679/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9136 - val_loss: 7.8466\n",
            "Epoch 2680/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8984 - val_loss: 7.7734\n",
            "Epoch 2681/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9296 - val_loss: 7.8960\n",
            "Epoch 2682/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8557 - val_loss: 7.8252\n",
            "Epoch 2683/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8545 - val_loss: 7.7752\n",
            "Epoch 2684/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8678 - val_loss: 7.7836\n",
            "Epoch 2685/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8701 - val_loss: 7.8999\n",
            "Epoch 2686/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8842 - val_loss: 7.9072\n",
            "Epoch 2687/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9619 - val_loss: 7.7592\n",
            "Epoch 2688/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4479 - val_loss: 7.8284\n",
            "Epoch 2689/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3653 - val_loss: 7.8340\n",
            "Epoch 2690/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0744 - val_loss: 7.8250\n",
            "Epoch 2691/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0466 - val_loss: 7.7775\n",
            "Epoch 2692/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9787 - val_loss: 7.8153\n",
            "Epoch 2693/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9455 - val_loss: 7.8492\n",
            "Epoch 2694/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9098 - val_loss: 7.8604\n",
            "Epoch 2695/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9010 - val_loss: 7.8412\n",
            "Epoch 2696/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9010 - val_loss: 7.8203\n",
            "Epoch 2697/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8715 - val_loss: 7.7470\n",
            "Epoch 2698/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8731 - val_loss: 7.7614\n",
            "Epoch 2699/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8399 - val_loss: 7.8083\n",
            "Epoch 2700/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8170 - val_loss: 7.8304\n",
            "Epoch 2701/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8141 - val_loss: 7.8181\n",
            "Epoch 2702/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8190 - val_loss: 7.8199\n",
            "Epoch 2703/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8413 - val_loss: 7.8145\n",
            "Epoch 2704/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9007 - val_loss: 7.8321\n",
            "Epoch 2705/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8075 - val_loss: 7.7734\n",
            "Epoch 2706/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0482 - val_loss: 7.8564\n",
            "Epoch 2707/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9606 - val_loss: 7.8055\n",
            "Epoch 2708/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9383 - val_loss: 7.7688\n",
            "Epoch 2709/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8521 - val_loss: 7.8265\n",
            "Epoch 2710/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8564 - val_loss: 7.8232\n",
            "Epoch 2711/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8139 - val_loss: 7.7810\n",
            "Epoch 2712/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8538 - val_loss: 7.8804\n",
            "Epoch 2713/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8698 - val_loss: 7.8133\n",
            "Epoch 2714/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9008 - val_loss: 7.8203\n",
            "Epoch 2715/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8659 - val_loss: 7.8296\n",
            "Epoch 2716/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8507 - val_loss: 7.8521\n",
            "Epoch 2717/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8868 - val_loss: 7.7351\n",
            "Epoch 2718/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4666 - val_loss: 7.8399\n",
            "Epoch 2719/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0663 - val_loss: 7.8243\n",
            "Epoch 2720/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9147 - val_loss: 7.8377\n",
            "Epoch 2721/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9273 - val_loss: 7.7722\n",
            "Epoch 2722/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8784 - val_loss: 7.7933\n",
            "Epoch 2723/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9098 - val_loss: 7.7798\n",
            "Epoch 2724/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8927 - val_loss: 7.7437\n",
            "Epoch 2725/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8324 - val_loss: 7.7991\n",
            "Epoch 2726/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8468 - val_loss: 7.8918\n",
            "Epoch 2727/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8536 - val_loss: 7.8144\n",
            "Epoch 2728/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8305 - val_loss: 7.7086\n",
            "Epoch 2729/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8830 - val_loss: 7.8792\n",
            "Epoch 2730/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9285 - val_loss: 7.8522\n",
            "Epoch 2731/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8807 - val_loss: 7.8182\n",
            "Epoch 2732/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8354 - val_loss: 7.8127\n",
            "Epoch 2733/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8351 - val_loss: 7.8814\n",
            "Epoch 2734/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9202 - val_loss: 7.8308\n",
            "Epoch 2735/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8523 - val_loss: 7.8533\n",
            "Epoch 2736/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8757 - val_loss: 7.8706\n",
            "Epoch 2737/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9732 - val_loss: 7.8108\n",
            "Epoch 2738/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9545 - val_loss: 7.8537\n",
            "Epoch 2739/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8762 - val_loss: 7.8499\n",
            "Epoch 2740/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8577 - val_loss: 7.8531\n",
            "Epoch 2741/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8279 - val_loss: 7.7454\n",
            "Epoch 2742/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8421 - val_loss: 7.8619\n",
            "Epoch 2743/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8236 - val_loss: 7.7604\n",
            "Epoch 2744/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8516 - val_loss: 7.7840\n",
            "Epoch 2745/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8246 - val_loss: 7.8002\n",
            "Epoch 2746/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8274 - val_loss: 7.7935\n",
            "Epoch 2747/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8088 - val_loss: 7.7842\n",
            "Epoch 2748/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8042 - val_loss: 7.7230\n",
            "Epoch 2749/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2005 - val_loss: 7.8273\n",
            "Epoch 2750/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1063 - val_loss: 7.7496\n",
            "Epoch 2751/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9287 - val_loss: 7.7628\n",
            "Epoch 2752/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8635 - val_loss: 7.7910\n",
            "Epoch 2753/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8566 - val_loss: 7.7783\n",
            "Epoch 2754/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8005 - val_loss: 7.7856\n",
            "Epoch 2755/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8192 - val_loss: 7.7367\n",
            "Epoch 2756/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8005 - val_loss: 7.7574\n",
            "Epoch 2757/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8754 - val_loss: 7.7442\n",
            "Epoch 2758/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8075 - val_loss: 7.7603\n",
            "Epoch 2759/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8811 - val_loss: 7.8325\n",
            "Epoch 2760/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8141 - val_loss: 7.8136\n",
            "Epoch 2761/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8036 - val_loss: 7.7085\n",
            "Epoch 2762/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4365 - val_loss: 7.8580\n",
            "Epoch 2763/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2012 - val_loss: 7.7583\n",
            "Epoch 2764/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0780 - val_loss: 7.7999\n",
            "Epoch 2765/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9936 - val_loss: 7.9170\n",
            "Epoch 2766/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9556 - val_loss: 7.8241\n",
            "Epoch 2767/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9424 - val_loss: 7.8360\n",
            "Epoch 2768/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8591 - val_loss: 7.7782\n",
            "Epoch 2769/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8590 - val_loss: 7.8963\n",
            "Epoch 2770/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8911 - val_loss: 7.9090\n",
            "Epoch 2771/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8471 - val_loss: 7.7882\n",
            "Epoch 2772/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8176 - val_loss: 7.8025\n",
            "Epoch 2773/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8689 - val_loss: 7.7887\n",
            "Epoch 2774/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8080 - val_loss: 7.7879\n",
            "Epoch 2775/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8358 - val_loss: 7.8071\n",
            "Epoch 2776/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8060 - val_loss: 7.8191\n",
            "Epoch 2777/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7966 - val_loss: 7.7694\n",
            "Epoch 2778/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7963 - val_loss: 7.7987\n",
            "Epoch 2779/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7754 - val_loss: 7.8098\n",
            "Epoch 2780/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8263 - val_loss: 7.8423\n",
            "Epoch 2781/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0046 - val_loss: 7.8574\n",
            "Epoch 2782/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9084 - val_loss: 7.8244\n",
            "Epoch 2783/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8418 - val_loss: 7.8277\n",
            "Epoch 2784/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8214 - val_loss: 7.7893\n",
            "Epoch 2785/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8524 - val_loss: 7.8318\n",
            "Epoch 2786/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8080 - val_loss: 7.8212\n",
            "Epoch 2787/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8232 - val_loss: 7.7903\n",
            "Epoch 2788/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8065 - val_loss: 7.7572\n",
            "Epoch 2789/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8160 - val_loss: 7.7605\n",
            "Epoch 2790/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8130 - val_loss: 7.7733\n",
            "Epoch 2791/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8354 - val_loss: 7.7208\n",
            "Epoch 2792/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8735 - val_loss: 7.8796\n",
            "Epoch 2793/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8230 - val_loss: 7.8400\n",
            "Epoch 2794/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7800 - val_loss: 7.7298\n",
            "Epoch 2795/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8774 - val_loss: 7.8438\n",
            "Epoch 2796/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8066 - val_loss: 7.8583\n",
            "Epoch 2797/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8109 - val_loss: 7.7909\n",
            "Epoch 2798/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7971 - val_loss: 7.8110\n",
            "Epoch 2799/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8359 - val_loss: 7.8267\n",
            "Epoch 2800/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8407 - val_loss: 7.7647\n",
            "Epoch 2801/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8286 - val_loss: 7.8941\n",
            "Epoch 2802/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8551 - val_loss: 7.7818\n",
            "Epoch 2803/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8074 - val_loss: 7.8395\n",
            "Epoch 2804/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8507 - val_loss: 7.7604\n",
            "Epoch 2805/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8671 - val_loss: 7.8033\n",
            "Epoch 2806/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8829 - val_loss: 7.8655\n",
            "Epoch 2807/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8462 - val_loss: 7.8387\n",
            "Epoch 2808/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8615 - val_loss: 7.8349\n",
            "Epoch 2809/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7970 - val_loss: 7.8198\n",
            "Epoch 2810/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8698 - val_loss: 7.8006\n",
            "Epoch 2811/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8495 - val_loss: 7.8703\n",
            "Epoch 2812/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8665 - val_loss: 7.8161\n",
            "Epoch 2813/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7978 - val_loss: 7.8346\n",
            "Epoch 2814/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8426 - val_loss: 7.7905\n",
            "Epoch 2815/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8187 - val_loss: 7.8173\n",
            "Epoch 2816/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7886 - val_loss: 7.7715\n",
            "Epoch 2817/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0842 - val_loss: 7.8983\n",
            "Epoch 2818/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0470 - val_loss: 7.8387\n",
            "Epoch 2819/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9819 - val_loss: 7.8090\n",
            "Epoch 2820/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9410 - val_loss: 7.8253\n",
            "Epoch 2821/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8334 - val_loss: 7.7820\n",
            "Epoch 2822/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8245 - val_loss: 7.7889\n",
            "Epoch 2823/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8186 - val_loss: 7.7868\n",
            "Epoch 2824/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8204 - val_loss: 7.7288\n",
            "Epoch 2825/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8330 - val_loss: 7.9251\n",
            "Epoch 2826/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8681 - val_loss: 7.8258\n",
            "Epoch 2827/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8697 - val_loss: 7.7358\n",
            "Epoch 2828/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8105 - val_loss: 7.7815\n",
            "Epoch 2829/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8206 - val_loss: 7.9097\n",
            "Epoch 2830/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8468 - val_loss: 7.8111\n",
            "Epoch 2831/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8084 - val_loss: 7.8020\n",
            "Epoch 2832/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7698 - val_loss: 7.7658\n",
            "Epoch 2833/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7600 - val_loss: 7.7895\n",
            "Epoch 2834/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8182 - val_loss: 7.8181\n",
            "Epoch 2835/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8632 - val_loss: 7.8094\n",
            "Epoch 2836/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7980 - val_loss: 7.8089\n",
            "Epoch 2837/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8210 - val_loss: 7.7747\n",
            "Epoch 2838/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7561 - val_loss: 7.8327\n",
            "Epoch 2839/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8086 - val_loss: 7.7895\n",
            "Epoch 2840/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8123 - val_loss: 7.7930\n",
            "Epoch 2841/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8169 - val_loss: 7.7608\n",
            "Epoch 2842/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7770 - val_loss: 7.8760\n",
            "Epoch 2843/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8387 - val_loss: 7.7716\n",
            "Epoch 2844/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7985 - val_loss: 7.7160\n",
            "Epoch 2845/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7514 - val_loss: 7.8051\n",
            "Epoch 2846/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8542 - val_loss: 7.8943\n",
            "Epoch 2847/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8117 - val_loss: 7.7948\n",
            "Epoch 2848/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7881 - val_loss: 7.7906\n",
            "Epoch 2849/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7563 - val_loss: 7.7311\n",
            "Epoch 2850/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7847 - val_loss: 7.7764\n",
            "Epoch 2851/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7483 - val_loss: 7.7549\n",
            "Epoch 2852/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7934 - val_loss: 7.7934\n",
            "Epoch 2853/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7980 - val_loss: 7.8060\n",
            "Epoch 2854/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7750 - val_loss: 7.8003\n",
            "Epoch 2855/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8062 - val_loss: 7.7703\n",
            "Epoch 2856/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7497 - val_loss: 7.8027\n",
            "Epoch 2857/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7755 - val_loss: 7.7426\n",
            "Epoch 2858/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9099 - val_loss: 7.8046\n",
            "Epoch 2859/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8199 - val_loss: 7.7731\n",
            "Epoch 2860/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7881 - val_loss: 7.7800\n",
            "Epoch 2861/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8158 - val_loss: 7.7688\n",
            "Epoch 2862/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7815 - val_loss: 7.8428\n",
            "Epoch 2863/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7745 - val_loss: 7.6931\n",
            "Epoch 2864/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2359 - val_loss: 7.8555\n",
            "Epoch 2865/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9951 - val_loss: 7.7892\n",
            "Epoch 2866/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8571 - val_loss: 7.7884\n",
            "Epoch 2867/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8867 - val_loss: 7.7869\n",
            "Epoch 2868/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7882 - val_loss: 7.7827\n",
            "Epoch 2869/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8052 - val_loss: 7.8326\n",
            "Epoch 2870/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8536 - val_loss: 7.8296\n",
            "Epoch 2871/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8348 - val_loss: 7.8054\n",
            "Epoch 2872/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0568 - val_loss: 7.7687\n",
            "Epoch 2873/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9075 - val_loss: 7.7918\n",
            "Epoch 2874/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8554 - val_loss: 7.8330\n",
            "Epoch 2875/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.3018 - val_loss: 7.9109\n",
            "Epoch 2876/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3370 - val_loss: 7.8049\n",
            "Epoch 2877/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9789 - val_loss: 7.7433\n",
            "Epoch 2878/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8500 - val_loss: 7.7640\n",
            "Epoch 2879/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8232 - val_loss: 7.8067\n",
            "Epoch 2880/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7561 - val_loss: 7.8063\n",
            "Epoch 2881/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7849 - val_loss: 7.7609\n",
            "Epoch 2882/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7489 - val_loss: 7.7619\n",
            "Epoch 2883/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7732 - val_loss: 7.8365\n",
            "Epoch 2884/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7549 - val_loss: 7.7598\n",
            "Epoch 2885/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7410 - val_loss: 7.8141\n",
            "Epoch 2886/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7426 - val_loss: 7.7478\n",
            "Epoch 2887/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7319 - val_loss: 7.7951\n",
            "Epoch 2888/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7437 - val_loss: 7.8242\n",
            "Epoch 2889/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7411 - val_loss: 7.8979\n",
            "Epoch 2890/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1249 - val_loss: 7.9368\n",
            "Epoch 2891/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9689 - val_loss: 7.8693\n",
            "Epoch 2892/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9285 - val_loss: 7.7533\n",
            "Epoch 2893/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8410 - val_loss: 7.8392\n",
            "Epoch 2894/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8047 - val_loss: 7.8788\n",
            "Epoch 2895/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8127 - val_loss: 7.8214\n",
            "Epoch 2896/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7986 - val_loss: 7.7615\n",
            "Epoch 2897/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7689 - val_loss: 7.7874\n",
            "Epoch 2898/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7727 - val_loss: 7.7551\n",
            "Epoch 2899/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8154 - val_loss: 7.8016\n",
            "Epoch 2900/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8455 - val_loss: 7.7953\n",
            "Epoch 2901/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7714 - val_loss: 7.7409\n",
            "Epoch 2902/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7698 - val_loss: 7.8457\n",
            "Epoch 2903/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7479 - val_loss: 7.7417\n",
            "Epoch 2904/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7558 - val_loss: 7.8609\n",
            "Epoch 2905/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7866 - val_loss: 7.7343\n",
            "Epoch 2906/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8180 - val_loss: 7.7848\n",
            "Epoch 2907/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8279 - val_loss: 7.8719\n",
            "Epoch 2908/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7381 - val_loss: 7.7997\n",
            "Epoch 2909/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7723 - val_loss: 7.8020\n",
            "Epoch 2910/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7100 - val_loss: 7.7094\n",
            "Epoch 2911/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7559 - val_loss: 7.7577\n",
            "Epoch 2912/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7819 - val_loss: 7.7600\n",
            "Epoch 2913/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8570 - val_loss: 7.7362\n",
            "Epoch 2914/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8191 - val_loss: 7.7098\n",
            "Epoch 2915/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7813 - val_loss: 7.7835\n",
            "Epoch 2916/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8047 - val_loss: 7.8104\n",
            "Epoch 2917/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8552 - val_loss: 7.7127\n",
            "Epoch 2918/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8350 - val_loss: 7.8326\n",
            "Epoch 2919/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8165 - val_loss: 7.8109\n",
            "Epoch 2920/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7274 - val_loss: 7.7757\n",
            "Epoch 2921/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7337 - val_loss: 7.7128\n",
            "Epoch 2922/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2581 - val_loss: 7.9684\n",
            "Epoch 2923/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1233 - val_loss: 7.8098\n",
            "Epoch 2924/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8978 - val_loss: 7.9050\n",
            "Epoch 2925/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8846 - val_loss: 7.8275\n",
            "Epoch 2926/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8298 - val_loss: 7.7604\n",
            "Epoch 2927/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8364 - val_loss: 7.8473\n",
            "Epoch 2928/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8199 - val_loss: 7.7724\n",
            "Epoch 2929/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0042 - val_loss: 7.7833\n",
            "Epoch 2930/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9365 - val_loss: 7.7728\n",
            "Epoch 2931/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9586 - val_loss: 7.7872\n",
            "Epoch 2932/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8510 - val_loss: 7.7810\n",
            "Epoch 2933/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8242 - val_loss: 7.7961\n",
            "Epoch 2934/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7828 - val_loss: 7.7713\n",
            "Epoch 2935/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7972 - val_loss: 7.7560\n",
            "Epoch 2936/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7465 - val_loss: 7.7729\n",
            "Epoch 2937/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9027 - val_loss: 7.7888\n",
            "Epoch 2938/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8566 - val_loss: 7.8509\n",
            "Epoch 2939/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8854 - val_loss: 7.8095\n",
            "Epoch 2940/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8799 - val_loss: 7.8908\n",
            "Epoch 2941/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8144 - val_loss: 7.8019\n",
            "Epoch 2942/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7748 - val_loss: 7.8350\n",
            "Epoch 2943/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7676 - val_loss: 7.8129\n",
            "Epoch 2944/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9007 - val_loss: 7.7983\n",
            "Epoch 2945/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9091 - val_loss: 7.8436\n",
            "Epoch 2946/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8574 - val_loss: 7.8123\n",
            "Epoch 2947/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7797 - val_loss: 7.7763\n",
            "Epoch 2948/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7909 - val_loss: 7.8070\n",
            "Epoch 2949/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7342 - val_loss: 7.7717\n",
            "Epoch 2950/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8093 - val_loss: 7.7769\n",
            "Epoch 2951/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7396 - val_loss: 7.8407\n",
            "Epoch 2952/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7606 - val_loss: 7.8298\n",
            "Epoch 2953/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7445 - val_loss: 7.8477\n",
            "Epoch 2954/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7400 - val_loss: 7.8104\n",
            "Epoch 2955/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7282 - val_loss: 7.7348\n",
            "Epoch 2956/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7090 - val_loss: 7.7757\n",
            "Epoch 2957/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7399 - val_loss: 7.7804\n",
            "Epoch 2958/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7039 - val_loss: 7.7932\n",
            "Epoch 2959/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7165 - val_loss: 7.8023\n",
            "Epoch 2960/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7024 - val_loss: 7.7802\n",
            "Epoch 2961/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7282 - val_loss: 7.7664\n",
            "Epoch 2962/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6994 - val_loss: 7.7996\n",
            "Epoch 2963/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6972 - val_loss: 7.7408\n",
            "Epoch 2964/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7460 - val_loss: 7.7972\n",
            "Epoch 2965/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7343 - val_loss: 7.7860\n",
            "Epoch 2966/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6902 - val_loss: 7.8302\n",
            "Epoch 2967/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3230 - val_loss: 7.7825\n",
            "Epoch 2968/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9823 - val_loss: 7.7525\n",
            "Epoch 2969/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8356 - val_loss: 7.7415\n",
            "Epoch 2970/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7878 - val_loss: 7.7059\n",
            "Epoch 2971/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7961 - val_loss: 7.7640\n",
            "Epoch 2972/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8085 - val_loss: 7.7791\n",
            "Epoch 2973/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7431 - val_loss: 7.7753\n",
            "Epoch 2974/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7421 - val_loss: 7.7199\n",
            "Epoch 2975/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7079 - val_loss: 7.7264\n",
            "Epoch 2976/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7557 - val_loss: 7.7458\n",
            "Epoch 2977/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7206 - val_loss: 7.7001\n",
            "Epoch 2978/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7860 - val_loss: 7.7858\n",
            "Epoch 2979/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7432 - val_loss: 7.8019\n",
            "Epoch 2980/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7392 - val_loss: 7.7969\n",
            "Epoch 2981/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0012 - val_loss: 7.8622\n",
            "Epoch 2982/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8777 - val_loss: 7.7692\n",
            "Epoch 2983/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8279 - val_loss: 7.7576\n",
            "Epoch 2984/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7723 - val_loss: 7.7899\n",
            "Epoch 2985/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7369 - val_loss: 7.7588\n",
            "Epoch 2986/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7711 - val_loss: 7.8876\n",
            "Epoch 2987/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7766 - val_loss: 7.7710\n",
            "Epoch 2988/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7066 - val_loss: 7.8555\n",
            "Epoch 2989/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7492 - val_loss: 7.7999\n",
            "Epoch 2990/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7298 - val_loss: 7.8232\n",
            "Epoch 2991/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7854 - val_loss: 7.8457\n",
            "Epoch 2992/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7778 - val_loss: 7.9361\n",
            "Epoch 2993/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7279 - val_loss: 7.7653\n",
            "Epoch 2994/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6970 - val_loss: 7.8058\n",
            "Epoch 2995/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7134 - val_loss: 7.8477\n",
            "Epoch 2996/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7305 - val_loss: 7.7773\n",
            "Epoch 2997/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7161 - val_loss: 7.7524\n",
            "Epoch 2998/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6768 - val_loss: 7.7542\n",
            "Epoch 2999/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7167 - val_loss: 7.7847\n",
            "Epoch 3000/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7264 - val_loss: 7.7815\n",
            "Epoch 3001/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7128 - val_loss: 7.7932\n",
            "Epoch 3002/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7025 - val_loss: 7.7589\n",
            "Epoch 3003/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7002 - val_loss: 7.8107\n",
            "Epoch 3004/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7169 - val_loss: 7.7498\n",
            "Epoch 3005/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7309 - val_loss: 7.8276\n",
            "Epoch 3006/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7104 - val_loss: 7.7572\n",
            "Epoch 3007/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7181 - val_loss: 7.8175\n",
            "Epoch 3008/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6961 - val_loss: 7.7229\n",
            "Epoch 3009/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.8717 - val_loss: 7.7905\n",
            "Epoch 3010/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6354 - val_loss: 7.7192\n",
            "Epoch 3011/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3842 - val_loss: 7.7023\n",
            "Epoch 3012/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1348 - val_loss: 7.6859\n",
            "Epoch 3013/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0406 - val_loss: 7.7277\n",
            "Epoch 3014/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9444 - val_loss: 7.6939\n",
            "Epoch 3015/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9057 - val_loss: 7.7044\n",
            "Epoch 3016/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8872 - val_loss: 7.7985\n",
            "Epoch 3017/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8388 - val_loss: 7.7572\n",
            "Epoch 3018/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8105 - val_loss: 7.7313\n",
            "Epoch 3019/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7971 - val_loss: 7.8113\n",
            "Epoch 3020/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.6171 - val_loss: 8.1537\n",
            "Epoch 3021/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4888 - val_loss: 7.9600\n",
            "Epoch 3022/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1767 - val_loss: 7.8650\n",
            "Epoch 3023/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9265 - val_loss: 7.8394\n",
            "Epoch 3024/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8535 - val_loss: 7.8411\n",
            "Epoch 3025/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8266 - val_loss: 7.8637\n",
            "Epoch 3026/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7326 - val_loss: 7.7789\n",
            "Epoch 3027/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7023 - val_loss: 7.7944\n",
            "Epoch 3028/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7037 - val_loss: 7.7963\n",
            "Epoch 3029/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7511 - val_loss: 7.7607\n",
            "Epoch 3030/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6876 - val_loss: 7.7424\n",
            "Epoch 3031/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6968 - val_loss: 7.7580\n",
            "Epoch 3032/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7052 - val_loss: 7.7555\n",
            "Epoch 3033/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6710 - val_loss: 7.7491\n",
            "Epoch 3034/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6572 - val_loss: 7.7718\n",
            "Epoch 3035/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6661 - val_loss: 7.7681\n",
            "Epoch 3036/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6876 - val_loss: 7.7904\n",
            "Epoch 3037/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6786 - val_loss: 7.7886\n",
            "Epoch 3038/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6856 - val_loss: 7.7329\n",
            "Epoch 3039/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6833 - val_loss: 7.7651\n",
            "Epoch 3040/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6571 - val_loss: 7.7333\n",
            "Epoch 3041/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6632 - val_loss: 7.7488\n",
            "Epoch 3042/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6787 - val_loss: 7.7662\n",
            "Epoch 3043/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6622 - val_loss: 7.7677\n",
            "Epoch 3044/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7130 - val_loss: 7.7301\n",
            "Epoch 3045/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6617 - val_loss: 7.7787\n",
            "Epoch 3046/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7000 - val_loss: 7.7992\n",
            "Epoch 3047/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6822 - val_loss: 7.7928\n",
            "Epoch 3048/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6599 - val_loss: 7.7584\n",
            "Epoch 3049/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6964 - val_loss: 7.7470\n",
            "Epoch 3050/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6744 - val_loss: 7.7332\n",
            "Epoch 3051/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6812 - val_loss: 7.7465\n",
            "Epoch 3052/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7215 - val_loss: 7.7469\n",
            "Epoch 3053/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8027 - val_loss: 7.6698\n",
            "Epoch 3054/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7858 - val_loss: 7.7740\n",
            "Epoch 3055/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7309 - val_loss: 7.7501\n",
            "Epoch 3056/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6940 - val_loss: 7.7751\n",
            "Epoch 3057/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6972 - val_loss: 7.7917\n",
            "Epoch 3058/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7268 - val_loss: 7.7608\n",
            "Epoch 3059/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7001 - val_loss: 7.7644\n",
            "Epoch 3060/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6812 - val_loss: 7.7805\n",
            "Epoch 3061/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6731 - val_loss: 7.7530\n",
            "Epoch 3062/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6826 - val_loss: 7.7735\n",
            "Epoch 3063/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6852 - val_loss: 7.7850\n",
            "Epoch 3064/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6628 - val_loss: 7.7556\n",
            "Epoch 3065/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6731 - val_loss: 7.8281\n",
            "Epoch 3066/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7057 - val_loss: 7.8180\n",
            "Epoch 3067/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6998 - val_loss: 7.7758\n",
            "Epoch 3068/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6823 - val_loss: 7.7599\n",
            "Epoch 3069/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6850 - val_loss: 7.8056\n",
            "Epoch 3070/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6747 - val_loss: 7.7551\n",
            "Epoch 3071/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6951 - val_loss: 7.7728\n",
            "Epoch 3072/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6928 - val_loss: 7.8337\n",
            "Epoch 3073/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6883 - val_loss: 7.7604\n",
            "Epoch 3074/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6622 - val_loss: 7.7887\n",
            "Epoch 3075/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8868 - val_loss: 7.7265\n",
            "Epoch 3076/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8382 - val_loss: 7.7877\n",
            "Epoch 3077/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7435 - val_loss: 7.7488\n",
            "Epoch 3078/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6996 - val_loss: 7.7330\n",
            "Epoch 3079/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6772 - val_loss: 7.7865\n",
            "Epoch 3080/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7595 - val_loss: 7.8516\n",
            "Epoch 3081/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7292 - val_loss: 7.7531\n",
            "Epoch 3082/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7176 - val_loss: 7.8074\n",
            "Epoch 3083/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7342 - val_loss: 7.8227\n",
            "Epoch 3084/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7364 - val_loss: 7.7650\n",
            "Epoch 3085/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6753 - val_loss: 7.7852\n",
            "Epoch 3086/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6768 - val_loss: 7.8066\n",
            "Epoch 3087/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6621 - val_loss: 7.7788\n",
            "Epoch 3088/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6816 - val_loss: 7.7837\n",
            "Epoch 3089/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6701 - val_loss: 7.8101\n",
            "Epoch 3090/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6870 - val_loss: 7.8254\n",
            "Epoch 3091/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6625 - val_loss: 7.7640\n",
            "Epoch 3092/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6784 - val_loss: 7.7820\n",
            "Epoch 3093/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6683 - val_loss: 7.8279\n",
            "Epoch 3094/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6939 - val_loss: 7.7960\n",
            "Epoch 3095/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6666 - val_loss: 7.7768\n",
            "Epoch 3096/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6817 - val_loss: 7.7960\n",
            "Epoch 3097/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6326 - val_loss: 7.8284\n",
            "Epoch 3098/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6877 - val_loss: 7.8142\n",
            "Epoch 3099/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6445 - val_loss: 7.8314\n",
            "Epoch 3100/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6200 - val_loss: 7.7942\n",
            "Epoch 3101/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6682 - val_loss: 7.8063\n",
            "Epoch 3102/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6478 - val_loss: 7.7619\n",
            "Epoch 3103/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7170 - val_loss: 7.7755\n",
            "Epoch 3104/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7994 - val_loss: 7.8164\n",
            "Epoch 3105/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7183 - val_loss: 7.8022\n",
            "Epoch 3106/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6902 - val_loss: 7.7768\n",
            "Epoch 3107/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6580 - val_loss: 7.8339\n",
            "Epoch 3108/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6836 - val_loss: 7.8745\n",
            "Epoch 3109/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6893 - val_loss: 7.7759\n",
            "Epoch 3110/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7128 - val_loss: 7.8137\n",
            "Epoch 3111/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6767 - val_loss: 7.8788\n",
            "Epoch 3112/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6816 - val_loss: 7.8147\n",
            "Epoch 3113/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6287 - val_loss: 7.8294\n",
            "Epoch 3114/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.0373 - val_loss: 8.1242\n",
            "Epoch 3115/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9123 - val_loss: 7.9838\n",
            "Epoch 3116/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8225 - val_loss: 7.8670\n",
            "Epoch 3117/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8072 - val_loss: 7.7765\n",
            "Epoch 3118/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7599 - val_loss: 7.8036\n",
            "Epoch 3119/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6858 - val_loss: 7.8022\n",
            "Epoch 3120/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7638 - val_loss: 7.8481\n",
            "Epoch 3121/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6917 - val_loss: 7.7874\n",
            "Epoch 3122/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7358 - val_loss: 7.8022\n",
            "Epoch 3123/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7031 - val_loss: 7.7863\n",
            "Epoch 3124/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7157 - val_loss: 7.8154\n",
            "Epoch 3125/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6923 - val_loss: 7.8030\n",
            "Epoch 3126/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6514 - val_loss: 7.7887\n",
            "Epoch 3127/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6629 - val_loss: 7.7810\n",
            "Epoch 3128/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6403 - val_loss: 7.8095\n",
            "Epoch 3129/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6804 - val_loss: 7.7914\n",
            "Epoch 3130/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6630 - val_loss: 7.8165\n",
            "Epoch 3131/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6810 - val_loss: 7.8457\n",
            "Epoch 3132/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6615 - val_loss: 7.8134\n",
            "Epoch 3133/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6434 - val_loss: 7.8085\n",
            "Epoch 3134/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6383 - val_loss: 7.8548\n",
            "Epoch 3135/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1170 - val_loss: 7.8383\n",
            "Epoch 3136/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0163 - val_loss: 7.8402\n",
            "Epoch 3137/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8270 - val_loss: 7.7689\n",
            "Epoch 3138/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7473 - val_loss: 7.7840\n",
            "Epoch 3139/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6857 - val_loss: 7.8111\n",
            "Epoch 3140/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6755 - val_loss: 7.8249\n",
            "Epoch 3141/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7869 - val_loss: 7.8623\n",
            "Epoch 3142/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7421 - val_loss: 7.7599\n",
            "Epoch 3143/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7057 - val_loss: 7.8025\n",
            "Epoch 3144/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6781 - val_loss: 7.8529\n",
            "Epoch 3145/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8136 - val_loss: 7.7680\n",
            "Epoch 3146/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7157 - val_loss: 7.8025\n",
            "Epoch 3147/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7315 - val_loss: 7.8282\n",
            "Epoch 3148/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6613 - val_loss: 7.8388\n",
            "Epoch 3149/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7110 - val_loss: 7.7987\n",
            "Epoch 3150/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6575 - val_loss: 7.8015\n",
            "Epoch 3151/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6966 - val_loss: 7.8127\n",
            "Epoch 3152/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6476 - val_loss: 7.7903\n",
            "Epoch 3153/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.6534 - val_loss: 7.7877\n",
            "Epoch 3154/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6586 - val_loss: 7.8086\n",
            "Epoch 3155/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6301 - val_loss: 7.7924\n",
            "Epoch 3156/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9123 - val_loss: 7.8344\n",
            "Epoch 3157/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8571 - val_loss: 7.8201\n",
            "Epoch 3158/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7321 - val_loss: 7.8420\n",
            "Epoch 3159/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7249 - val_loss: 7.8657\n",
            "Epoch 3160/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7003 - val_loss: 7.8066\n",
            "Epoch 3161/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6969 - val_loss: 7.7678\n",
            "Epoch 3162/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6491 - val_loss: 7.7788\n",
            "Epoch 3163/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6808 - val_loss: 7.8191\n",
            "Epoch 3164/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6560 - val_loss: 7.8033\n",
            "Epoch 3165/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6714 - val_loss: 7.8222\n",
            "Epoch 3166/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6624 - val_loss: 7.8429\n",
            "Epoch 3167/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6290 - val_loss: 7.8052\n",
            "Epoch 3168/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6942 - val_loss: 7.8102\n",
            "Epoch 3169/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6368 - val_loss: 7.8334\n",
            "Epoch 3170/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6502 - val_loss: 7.8352\n",
            "Epoch 3171/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6359 - val_loss: 7.8451\n",
            "Epoch 3172/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7979 - val_loss: 7.7620\n",
            "Epoch 3173/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8559 - val_loss: 7.8232\n",
            "Epoch 3174/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7000 - val_loss: 7.8364\n",
            "Epoch 3175/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7179 - val_loss: 7.7996\n",
            "Epoch 3176/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6681 - val_loss: 7.7403\n",
            "Epoch 3177/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6633 - val_loss: 7.7701\n",
            "Epoch 3178/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6616 - val_loss: 7.8232\n",
            "Epoch 3179/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6582 - val_loss: 7.7927\n",
            "Epoch 3180/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6598 - val_loss: 7.7692\n",
            "Epoch 3181/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7321 - val_loss: 7.7225\n",
            "Epoch 3182/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6624 - val_loss: 7.7633\n",
            "Epoch 3183/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0057 - val_loss: 8.0671\n",
            "Epoch 3184/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8760 - val_loss: 7.9565\n",
            "Epoch 3185/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7170 - val_loss: 7.8894\n",
            "Epoch 3186/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7114 - val_loss: 7.8172\n",
            "Epoch 3187/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6374 - val_loss: 7.8258\n",
            "Epoch 3188/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6531 - val_loss: 7.8362\n",
            "Epoch 3189/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6349 - val_loss: 7.8512\n",
            "Epoch 3190/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6642 - val_loss: 7.8199\n",
            "Epoch 3191/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6378 - val_loss: 7.8236\n",
            "Epoch 3192/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6595 - val_loss: 7.8258\n",
            "Epoch 3193/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6098 - val_loss: 7.7875\n",
            "Epoch 3194/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6172 - val_loss: 7.8209\n",
            "Epoch 3195/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6477 - val_loss: 7.8098\n",
            "Epoch 3196/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6782 - val_loss: 7.8344\n",
            "Epoch 3197/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6464 - val_loss: 7.8199\n",
            "Epoch 3198/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6262 - val_loss: 7.8050\n",
            "Epoch 3199/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6231 - val_loss: 7.8070\n",
            "Epoch 3200/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6111 - val_loss: 7.7952\n",
            "Epoch 3201/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6164 - val_loss: 7.7621\n",
            "Epoch 3202/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6423 - val_loss: 7.8231\n",
            "Epoch 3203/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6635 - val_loss: 7.8259\n",
            "Epoch 3204/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6399 - val_loss: 7.7475\n",
            "Epoch 3205/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6684 - val_loss: 7.8003\n",
            "Epoch 3206/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6307 - val_loss: 7.7926\n",
            "Epoch 3207/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6311 - val_loss: 7.7811\n",
            "Epoch 3208/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6013 - val_loss: 7.8470\n",
            "Epoch 3209/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6592 - val_loss: 7.7903\n",
            "Epoch 3210/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6159 - val_loss: 7.8402\n",
            "Epoch 3211/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6756 - val_loss: 7.8074\n",
            "Epoch 3212/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6313 - val_loss: 7.8147\n",
            "Epoch 3213/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5997 - val_loss: 7.8161\n",
            "Epoch 3214/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6455 - val_loss: 7.8324\n",
            "Epoch 3215/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6091 - val_loss: 7.8409\n",
            "Epoch 3216/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5911 - val_loss: 7.7931\n",
            "Epoch 3217/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6675 - val_loss: 7.8430\n",
            "Epoch 3218/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6780 - val_loss: 7.8483\n",
            "Epoch 3219/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6092 - val_loss: 7.8351\n",
            "Epoch 3220/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6352 - val_loss: 7.8285\n",
            "Epoch 3221/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6068 - val_loss: 7.7860\n",
            "Epoch 3222/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8885 - val_loss: 7.9050\n",
            "Epoch 3223/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7467 - val_loss: 7.8729\n",
            "Epoch 3224/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6828 - val_loss: 7.8001\n",
            "Epoch 3225/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6622 - val_loss: 7.8129\n",
            "Epoch 3226/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6295 - val_loss: 7.7642\n",
            "Epoch 3227/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6234 - val_loss: 7.8582\n",
            "Epoch 3228/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6241 - val_loss: 7.8158\n",
            "Epoch 3229/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6138 - val_loss: 7.8528\n",
            "Epoch 3230/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6125 - val_loss: 7.8675\n",
            "Epoch 3231/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6498 - val_loss: 7.8858\n",
            "Epoch 3232/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6993 - val_loss: 7.8376\n",
            "Epoch 3233/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6456 - val_loss: 7.8541\n",
            "Epoch 3234/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8280 - val_loss: 8.0502\n",
            "Epoch 3235/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8228 - val_loss: 8.0076\n",
            "Epoch 3236/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7238 - val_loss: 7.9130\n",
            "Epoch 3237/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6796 - val_loss: 7.8819\n",
            "Epoch 3238/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6353 - val_loss: 7.8751\n",
            "Epoch 3239/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6684 - val_loss: 7.8475\n",
            "Epoch 3240/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6823 - val_loss: 7.8336\n",
            "Epoch 3241/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6292 - val_loss: 7.8836\n",
            "Epoch 3242/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6026 - val_loss: 7.8629\n",
            "Epoch 3243/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7640 - val_loss: 7.8741\n",
            "Epoch 3244/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6721 - val_loss: 7.9178\n",
            "Epoch 3245/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6512 - val_loss: 7.8739\n",
            "Epoch 3246/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6463 - val_loss: 7.8578\n",
            "Epoch 3247/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6409 - val_loss: 7.8515\n",
            "Epoch 3248/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5934 - val_loss: 7.8578\n",
            "Epoch 3249/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6234 - val_loss: 7.8818\n",
            "Epoch 3250/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5915 - val_loss: 7.8853\n",
            "Epoch 3251/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6349 - val_loss: 7.8290\n",
            "Epoch 3252/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6047 - val_loss: 7.8748\n",
            "Epoch 3253/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6481 - val_loss: 7.8656\n",
            "Epoch 3254/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5843 - val_loss: 7.8327\n",
            "Epoch 3255/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5811 - val_loss: 7.8493\n",
            "Epoch 3256/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6202 - val_loss: 7.8468\n",
            "Epoch 3257/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5762 - val_loss: 7.8682\n",
            "Epoch 3258/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6553 - val_loss: 7.8150\n",
            "Epoch 3259/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7231 - val_loss: 7.8862\n",
            "Epoch 3260/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.6047 - val_loss: 7.9061\n",
            "Epoch 3261/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6099 - val_loss: 7.8549\n",
            "Epoch 3262/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5674 - val_loss: 7.8398\n",
            "Epoch 3263/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6051 - val_loss: 7.8851\n",
            "Epoch 3264/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6626 - val_loss: 7.8391\n",
            "Epoch 3265/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6095 - val_loss: 7.8565\n",
            "Epoch 3266/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5998 - val_loss: 7.8594\n",
            "Epoch 3267/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5838 - val_loss: 7.8615\n",
            "Epoch 3268/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5937 - val_loss: 7.8345\n",
            "Epoch 3269/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6327 - val_loss: 7.8824\n",
            "Epoch 3270/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6368 - val_loss: 7.8706\n",
            "Epoch 3271/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5892 - val_loss: 7.8743\n",
            "Epoch 3272/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5997 - val_loss: 7.8710\n",
            "Epoch 3273/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5974 - val_loss: 7.8864\n",
            "Epoch 3274/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5817 - val_loss: 7.9028\n",
            "Epoch 3275/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2605 - val_loss: 8.2043\n",
            "Epoch 3276/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4099 - val_loss: 8.0202\n",
            "Epoch 3277/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1050 - val_loss: 8.0435\n",
            "Epoch 3278/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9293 - val_loss: 7.9875\n",
            "Epoch 3279/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8038 - val_loss: 7.9665\n",
            "Epoch 3280/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7240 - val_loss: 7.9708\n",
            "Epoch 3281/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7110 - val_loss: 7.9579\n",
            "Epoch 3282/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6878 - val_loss: 7.9055\n",
            "Epoch 3283/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6780 - val_loss: 7.9161\n",
            "Epoch 3284/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9971 - val_loss: 7.9279\n",
            "Epoch 3285/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9327 - val_loss: 7.8853\n",
            "Epoch 3286/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7615 - val_loss: 7.8616\n",
            "Epoch 3287/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7126 - val_loss: 7.8691\n",
            "Epoch 3288/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7345 - val_loss: 7.8976\n",
            "Epoch 3289/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6897 - val_loss: 7.9096\n",
            "Epoch 3290/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6455 - val_loss: 7.8811\n",
            "Epoch 3291/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6175 - val_loss: 7.9067\n",
            "Epoch 3292/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6259 - val_loss: 7.9090\n",
            "Epoch 3293/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6167 - val_loss: 7.9165\n",
            "Epoch 3294/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6022 - val_loss: 7.8877\n",
            "Epoch 3295/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6371 - val_loss: 7.9059\n",
            "Epoch 3296/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6261 - val_loss: 7.8623\n",
            "Epoch 3297/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6006 - val_loss: 7.8898\n",
            "Epoch 3298/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6110 - val_loss: 7.8872\n",
            "Epoch 3299/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5709 - val_loss: 7.9044\n",
            "Epoch 3300/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5750 - val_loss: 7.9016\n",
            "Epoch 3301/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6315 - val_loss: 7.9101\n",
            "Epoch 3302/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5965 - val_loss: 7.8812\n",
            "Epoch 3303/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5727 - val_loss: 7.9060\n",
            "Epoch 3304/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5942 - val_loss: 7.8886\n",
            "Epoch 3305/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6203 - val_loss: 7.9091\n",
            "Epoch 3306/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5913 - val_loss: 7.8808\n",
            "Epoch 3307/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5501 - val_loss: 7.8959\n",
            "Epoch 3308/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6318 - val_loss: 7.8676\n",
            "Epoch 3309/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5741 - val_loss: 7.8783\n",
            "Epoch 3310/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6210 - val_loss: 7.8319\n",
            "Epoch 3311/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5737 - val_loss: 7.8777\n",
            "Epoch 3312/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5728 - val_loss: 7.8905\n",
            "Epoch 3313/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5654 - val_loss: 7.8862\n",
            "Epoch 3314/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5814 - val_loss: 7.8947\n",
            "Epoch 3315/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5481 - val_loss: 7.8754\n",
            "Epoch 3316/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5522 - val_loss: 7.8865\n",
            "Epoch 3317/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5564 - val_loss: 7.9270\n",
            "Epoch 3318/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5863 - val_loss: 7.8645\n",
            "Epoch 3319/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6624 - val_loss: 7.9339\n",
            "Epoch 3320/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5846 - val_loss: 7.9028\n",
            "Epoch 3321/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6024 - val_loss: 7.8985\n",
            "Epoch 3322/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5634 - val_loss: 7.8943\n",
            "Epoch 3323/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5716 - val_loss: 7.8643\n",
            "Epoch 3324/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6934 - val_loss: 7.9159\n",
            "Epoch 3325/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6259 - val_loss: 7.8958\n",
            "Epoch 3326/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8217 - val_loss: 7.9456\n",
            "Epoch 3327/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7094 - val_loss: 7.9210\n",
            "Epoch 3328/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6238 - val_loss: 7.8852\n",
            "Epoch 3329/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6375 - val_loss: 7.9340\n",
            "Epoch 3330/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5957 - val_loss: 7.9324\n",
            "Epoch 3331/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5904 - val_loss: 7.9078\n",
            "Epoch 3332/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5777 - val_loss: 7.9054\n",
            "Epoch 3333/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6006 - val_loss: 7.9272\n",
            "Epoch 3334/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5664 - val_loss: 7.9120\n",
            "Epoch 3335/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5755 - val_loss: 7.9188\n",
            "Epoch 3336/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6093 - val_loss: 7.9144\n",
            "Epoch 3337/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5754 - val_loss: 7.8943\n",
            "Epoch 3338/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6120 - val_loss: 7.9468\n",
            "Epoch 3339/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7992 - val_loss: 7.9688\n",
            "Epoch 3340/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6689 - val_loss: 8.0132\n",
            "Epoch 3341/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6339 - val_loss: 7.9541\n",
            "Epoch 3342/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6039 - val_loss: 7.9599\n",
            "Epoch 3343/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5885 - val_loss: 7.9397\n",
            "Epoch 3344/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6008 - val_loss: 7.8944\n",
            "Epoch 3345/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6109 - val_loss: 7.8970\n",
            "Epoch 3346/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6098 - val_loss: 7.9303\n",
            "Epoch 3347/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5890 - val_loss: 7.9015\n",
            "Epoch 3348/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7530 - val_loss: 7.8631\n",
            "Epoch 3349/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9130 - val_loss: 7.9006\n",
            "Epoch 3350/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8602 - val_loss: 7.8696\n",
            "Epoch 3351/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7522 - val_loss: 7.8561\n",
            "Epoch 3352/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8947 - val_loss: 7.9250\n",
            "Epoch 3353/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8518 - val_loss: 7.8291\n",
            "Epoch 3354/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7367 - val_loss: 7.8484\n",
            "Epoch 3355/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9038 - val_loss: 7.8650\n",
            "Epoch 3356/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8168 - val_loss: 7.9532\n",
            "Epoch 3357/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7111 - val_loss: 7.8705\n",
            "Epoch 3358/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6294 - val_loss: 7.8985\n",
            "Epoch 3359/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6107 - val_loss: 7.8747\n",
            "Epoch 3360/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6076 - val_loss: 7.9105\n",
            "Epoch 3361/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6096 - val_loss: 7.8973\n",
            "Epoch 3362/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5625 - val_loss: 7.9112\n",
            "Epoch 3363/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6150 - val_loss: 7.9218\n",
            "Epoch 3364/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5797 - val_loss: 7.9068\n",
            "Epoch 3365/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5874 - val_loss: 7.9038\n",
            "Epoch 3366/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.5610 - val_loss: 7.9076\n",
            "Epoch 3367/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5942 - val_loss: 7.9455\n",
            "Epoch 3368/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6663 - val_loss: 7.9607\n",
            "Epoch 3369/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6186 - val_loss: 7.9857\n",
            "Epoch 3370/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5829 - val_loss: 7.9545\n",
            "Epoch 3371/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6483 - val_loss: 7.9419\n",
            "Epoch 3372/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6418 - val_loss: 7.9203\n",
            "Epoch 3373/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6444 - val_loss: 7.9484\n",
            "Epoch 3374/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6111 - val_loss: 7.8935\n",
            "Epoch 3375/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6461 - val_loss: 7.9544\n",
            "Epoch 3376/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5534 - val_loss: 7.9327\n",
            "Epoch 3377/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6680 - val_loss: 7.8719\n",
            "Epoch 3378/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6294 - val_loss: 7.9352\n",
            "Epoch 3379/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6421 - val_loss: 7.8701\n",
            "Epoch 3380/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5687 - val_loss: 7.9359\n",
            "Epoch 3381/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5246 - val_loss: 7.9380\n",
            "Epoch 3382/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5680 - val_loss: 7.9401\n",
            "Epoch 3383/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5353 - val_loss: 7.9253\n",
            "Epoch 3384/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5245 - val_loss: 7.9236\n",
            "Epoch 3385/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5269 - val_loss: 7.9128\n",
            "Epoch 3386/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5566 - val_loss: 7.9649\n",
            "Epoch 3387/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5938 - val_loss: 7.9085\n",
            "Epoch 3388/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5555 - val_loss: 7.9302\n",
            "Epoch 3389/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5700 - val_loss: 7.9475\n",
            "Epoch 3390/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5843 - val_loss: 7.9359\n",
            "Epoch 3391/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5760 - val_loss: 7.9603\n",
            "Epoch 3392/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5782 - val_loss: 7.9844\n",
            "Epoch 3393/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5595 - val_loss: 7.9233\n",
            "Epoch 3394/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5612 - val_loss: 8.0100\n",
            "Epoch 3395/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.7102 - val_loss: 8.2935\n",
            "Epoch 3396/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4545 - val_loss: 8.0779\n",
            "Epoch 3397/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.2722 - val_loss: 8.2179\n",
            "Epoch 3398/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0940 - val_loss: 8.1636\n",
            "Epoch 3399/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8827 - val_loss: 8.0672\n",
            "Epoch 3400/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7817 - val_loss: 8.0194\n",
            "Epoch 3401/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7643 - val_loss: 8.0030\n",
            "Epoch 3402/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7106 - val_loss: 7.9892\n",
            "Epoch 3403/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7139 - val_loss: 7.9726\n",
            "Epoch 3404/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6235 - val_loss: 7.9738\n",
            "Epoch 3405/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6251 - val_loss: 7.9698\n",
            "Epoch 3406/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6039 - val_loss: 7.9717\n",
            "Epoch 3407/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6029 - val_loss: 7.9359\n",
            "Epoch 3408/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5883 - val_loss: 7.9771\n",
            "Epoch 3409/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5843 - val_loss: 7.8968\n",
            "Epoch 3410/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5802 - val_loss: 7.9417\n",
            "Epoch 3411/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5779 - val_loss: 7.9238\n",
            "Epoch 3412/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5211 - val_loss: 7.9387\n",
            "Epoch 3413/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5351 - val_loss: 7.9699\n",
            "Epoch 3414/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5178 - val_loss: 7.9264\n",
            "Epoch 3415/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5342 - val_loss: 7.9406\n",
            "Epoch 3416/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5238 - val_loss: 7.9481\n",
            "Epoch 3417/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5148 - val_loss: 7.9656\n",
            "Epoch 3418/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5092 - val_loss: 7.9532\n",
            "Epoch 3419/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5072 - val_loss: 7.9701\n",
            "Epoch 3420/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5183 - val_loss: 7.9509\n",
            "Epoch 3421/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5950 - val_loss: 7.9692\n",
            "Epoch 3422/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5581 - val_loss: 7.9739\n",
            "Epoch 3423/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5399 - val_loss: 7.9793\n",
            "Epoch 3424/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5347 - val_loss: 7.9866\n",
            "Epoch 3425/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5207 - val_loss: 7.9916\n",
            "Epoch 3426/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5476 - val_loss: 7.9667\n",
            "Epoch 3427/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5117 - val_loss: 8.0124\n",
            "Epoch 3428/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5164 - val_loss: 7.9627\n",
            "Epoch 3429/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5084 - val_loss: 7.9477\n",
            "Epoch 3430/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5678 - val_loss: 7.9734\n",
            "Epoch 3431/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5256 - val_loss: 7.9616\n",
            "Epoch 3432/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5577 - val_loss: 7.9610\n",
            "Epoch 3433/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5224 - val_loss: 7.9401\n",
            "Epoch 3434/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5297 - val_loss: 7.9434\n",
            "Epoch 3435/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5291 - val_loss: 7.9797\n",
            "Epoch 3436/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5587 - val_loss: 7.9361\n",
            "Epoch 3437/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5568 - val_loss: 7.9136\n",
            "Epoch 3438/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5722 - val_loss: 7.9864\n",
            "Epoch 3439/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4884 - val_loss: 7.9759\n",
            "Epoch 3440/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7445 - val_loss: 7.9590\n",
            "Epoch 3441/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6206 - val_loss: 7.9615\n",
            "Epoch 3442/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5526 - val_loss: 7.9659\n",
            "Epoch 3443/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5555 - val_loss: 7.9698\n",
            "Epoch 3444/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5412 - val_loss: 7.9936\n",
            "Epoch 3445/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7590 - val_loss: 7.9916\n",
            "Epoch 3446/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6915 - val_loss: 7.9082\n",
            "Epoch 3447/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.4462 - val_loss: 7.8906\n",
            "Epoch 3448/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0963 - val_loss: 7.9814\n",
            "Epoch 3449/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8107 - val_loss: 7.9634\n",
            "Epoch 3450/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6658 - val_loss: 8.0080\n",
            "Epoch 3451/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6236 - val_loss: 7.9840\n",
            "Epoch 3452/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5861 - val_loss: 7.9790\n",
            "Epoch 3453/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5824 - val_loss: 7.9592\n",
            "Epoch 3454/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5847 - val_loss: 7.9813\n",
            "Epoch 3455/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5579 - val_loss: 7.9855\n",
            "Epoch 3456/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5737 - val_loss: 7.9907\n",
            "Epoch 3457/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5530 - val_loss: 7.9684\n",
            "Epoch 3458/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6297 - val_loss: 7.9968\n",
            "Epoch 3459/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6162 - val_loss: 7.9387\n",
            "Epoch 3460/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5634 - val_loss: 7.9963\n",
            "Epoch 3461/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5722 - val_loss: 7.9617\n",
            "Epoch 3462/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5283 - val_loss: 8.0534\n",
            "Epoch 3463/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5904 - val_loss: 7.9608\n",
            "Epoch 3464/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5566 - val_loss: 7.9524\n",
            "Epoch 3465/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5611 - val_loss: 7.9421\n",
            "Epoch 3466/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1408 - val_loss: 7.9548\n",
            "Epoch 3467/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0604 - val_loss: 8.0211\n",
            "Epoch 3468/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6980 - val_loss: 7.9747\n",
            "Epoch 3469/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6507 - val_loss: 8.0184\n",
            "Epoch 3470/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6538 - val_loss: 7.9772\n",
            "Epoch 3471/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6132 - val_loss: 7.9454\n",
            "Epoch 3472/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6048 - val_loss: 8.0328\n",
            "Epoch 3473/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6007 - val_loss: 8.0079\n",
            "Epoch 3474/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5795 - val_loss: 8.0101\n",
            "Epoch 3475/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5330 - val_loss: 8.0141\n",
            "Epoch 3476/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5285 - val_loss: 8.0219\n",
            "Epoch 3477/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5208 - val_loss: 8.0097\n",
            "Epoch 3478/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5215 - val_loss: 8.0292\n",
            "Epoch 3479/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5160 - val_loss: 8.0208\n",
            "Epoch 3480/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5006 - val_loss: 8.0426\n",
            "Epoch 3481/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4969 - val_loss: 8.0285\n",
            "Epoch 3482/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5709 - val_loss: 7.9912\n",
            "Epoch 3483/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5456 - val_loss: 8.0474\n",
            "Epoch 3484/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5886 - val_loss: 8.0038\n",
            "Epoch 3485/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5366 - val_loss: 7.9710\n",
            "Epoch 3486/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5809 - val_loss: 8.0202\n",
            "Epoch 3487/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5421 - val_loss: 8.0247\n",
            "Epoch 3488/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5609 - val_loss: 7.9977\n",
            "Epoch 3489/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5371 - val_loss: 8.0106\n",
            "Epoch 3490/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5288 - val_loss: 8.0137\n",
            "Epoch 3491/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5245 - val_loss: 7.9962\n",
            "Epoch 3492/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5249 - val_loss: 8.0047\n",
            "Epoch 3493/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5215 - val_loss: 8.0224\n",
            "Epoch 3494/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5094 - val_loss: 8.0151\n",
            "Epoch 3495/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5372 - val_loss: 8.0583\n",
            "Epoch 3496/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5073 - val_loss: 8.0136\n",
            "Epoch 3497/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4977 - val_loss: 8.0187\n",
            "Epoch 3498/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5240 - val_loss: 8.0175\n",
            "Epoch 3499/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4926 - val_loss: 7.9966\n",
            "Epoch 3500/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5885 - val_loss: 8.0413\n",
            "Epoch 3501/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5846 - val_loss: 8.0198\n",
            "Epoch 3502/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5091 - val_loss: 8.0332\n",
            "Epoch 3503/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5067 - val_loss: 7.9959\n",
            "Epoch 3504/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4928 - val_loss: 8.0104\n",
            "Epoch 3505/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4999 - val_loss: 8.0031\n",
            "Epoch 3506/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5520 - val_loss: 7.9726\n",
            "Epoch 3507/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5457 - val_loss: 8.0311\n",
            "Epoch 3508/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5043 - val_loss: 7.9727\n",
            "Epoch 3509/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4806 - val_loss: 7.9858\n",
            "Epoch 3510/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5587 - val_loss: 8.0054\n",
            "Epoch 3511/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4992 - val_loss: 7.9765\n",
            "Epoch 3512/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5246 - val_loss: 7.9797\n",
            "Epoch 3513/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4865 - val_loss: 8.0303\n",
            "Epoch 3514/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5654 - val_loss: 8.0377\n",
            "Epoch 3515/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5389 - val_loss: 8.0350\n",
            "Epoch 3516/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5682 - val_loss: 8.0372\n",
            "Epoch 3517/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5642 - val_loss: 8.0137\n",
            "Epoch 3518/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5277 - val_loss: 8.0277\n",
            "Epoch 3519/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5609 - val_loss: 8.0218\n",
            "Epoch 3520/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5371 - val_loss: 7.9959\n",
            "Epoch 3521/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5162 - val_loss: 8.0074\n",
            "Epoch 3522/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5227 - val_loss: 8.0019\n",
            "Epoch 3523/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4978 - val_loss: 8.0280\n",
            "Epoch 3524/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.5156 - val_loss: 8.0173\n",
            "Epoch 3525/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5002 - val_loss: 8.0211\n",
            "Epoch 3526/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4843 - val_loss: 8.0242\n",
            "Epoch 3527/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4837 - val_loss: 7.9940\n",
            "Epoch 3528/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5797 - val_loss: 8.0042\n",
            "Epoch 3529/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5476 - val_loss: 8.0300\n",
            "Epoch 3530/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5504 - val_loss: 8.0061\n",
            "Epoch 3531/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5264 - val_loss: 7.9727\n",
            "Epoch 3532/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5197 - val_loss: 8.0342\n",
            "Epoch 3533/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4818 - val_loss: 7.9852\n",
            "Epoch 3534/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4852 - val_loss: 8.0435\n",
            "Epoch 3535/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5140 - val_loss: 8.0566\n",
            "Epoch 3536/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5956 - val_loss: 7.9916\n",
            "Epoch 3537/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5360 - val_loss: 8.0206\n",
            "Epoch 3538/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4962 - val_loss: 8.0169\n",
            "Epoch 3539/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5231 - val_loss: 8.0110\n",
            "Epoch 3540/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4876 - val_loss: 8.0139\n",
            "Epoch 3541/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4973 - val_loss: 8.0257\n",
            "Epoch 3542/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5456 - val_loss: 8.0286\n",
            "Epoch 3543/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7376 - val_loss: 8.0168\n",
            "Epoch 3544/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7473 - val_loss: 8.0067\n",
            "Epoch 3545/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6008 - val_loss: 8.0209\n",
            "Epoch 3546/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5515 - val_loss: 7.9900\n",
            "Epoch 3547/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5438 - val_loss: 7.9789\n",
            "Epoch 3548/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5405 - val_loss: 8.0309\n",
            "Epoch 3549/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5464 - val_loss: 8.0012\n",
            "Epoch 3550/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5360 - val_loss: 8.0199\n",
            "Epoch 3551/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5090 - val_loss: 7.9919\n",
            "Epoch 3552/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.5145 - val_loss: 8.0465\n",
            "Epoch 3553/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4788 - val_loss: 8.0116\n",
            "Epoch 3554/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5056 - val_loss: 8.0375\n",
            "Epoch 3555/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5110 - val_loss: 8.0512\n",
            "Epoch 3556/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5251 - val_loss: 8.0339\n",
            "Epoch 3557/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5298 - val_loss: 8.0080\n",
            "Epoch 3558/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8979 - val_loss: 8.1256\n",
            "Epoch 3559/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8847 - val_loss: 8.0609\n",
            "Epoch 3560/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6992 - val_loss: 8.0528\n",
            "Epoch 3561/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5846 - val_loss: 8.0577\n",
            "Epoch 3562/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5445 - val_loss: 8.0730\n",
            "Epoch 3563/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5308 - val_loss: 8.0862\n",
            "Epoch 3564/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5236 - val_loss: 8.0430\n",
            "Epoch 3565/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6915 - val_loss: 8.0224\n",
            "Epoch 3566/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6957 - val_loss: 7.9774\n",
            "Epoch 3567/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6082 - val_loss: 8.0659\n",
            "Epoch 3568/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6275 - val_loss: 7.9679\n",
            "Epoch 3569/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5716 - val_loss: 8.0536\n",
            "Epoch 3570/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5120 - val_loss: 8.0269\n",
            "Epoch 3571/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5089 - val_loss: 8.0611\n",
            "Epoch 3572/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4938 - val_loss: 8.0360\n",
            "Epoch 3573/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5312 - val_loss: 8.0147\n",
            "Epoch 3574/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6510 - val_loss: 8.0365\n",
            "Epoch 3575/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5646 - val_loss: 8.0539\n",
            "Epoch 3576/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5516 - val_loss: 8.0180\n",
            "Epoch 3577/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5263 - val_loss: 8.0583\n",
            "Epoch 3578/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5005 - val_loss: 8.0624\n",
            "Epoch 3579/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5389 - val_loss: 8.0126\n",
            "Epoch 3580/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4999 - val_loss: 8.0636\n",
            "Epoch 3581/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4755 - val_loss: 8.0496\n",
            "Epoch 3582/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5442 - val_loss: 8.0647\n",
            "Epoch 3583/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5485 - val_loss: 8.0375\n",
            "Epoch 3584/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5154 - val_loss: 8.0917\n",
            "Epoch 3585/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4853 - val_loss: 8.1156\n",
            "Epoch 3586/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4878 - val_loss: 8.1148\n",
            "Epoch 3587/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4829 - val_loss: 8.0416\n",
            "Epoch 3588/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4701 - val_loss: 8.0722\n",
            "Epoch 3589/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4618 - val_loss: 8.0671\n",
            "Epoch 3590/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4809 - val_loss: 8.0780\n",
            "Epoch 3591/10000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.5729 - val_loss: 8.0465\n",
            "Epoch 3592/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5415 - val_loss: 8.0576\n",
            "Epoch 3593/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5089 - val_loss: 8.0485\n",
            "Epoch 3594/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4860 - val_loss: 8.0244\n",
            "Epoch 3595/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4837 - val_loss: 8.0436\n",
            "Epoch 3596/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5023 - val_loss: 8.0725\n",
            "Epoch 3597/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4974 - val_loss: 8.0947\n",
            "Epoch 3598/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4891 - val_loss: 8.0704\n",
            "Epoch 3599/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4795 - val_loss: 8.0939\n",
            "Epoch 3600/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4891 - val_loss: 8.0547\n",
            "Epoch 3601/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4773 - val_loss: 8.1118\n",
            "Epoch 3602/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4469 - val_loss: 8.0893\n",
            "Epoch 3603/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4862 - val_loss: 8.1036\n",
            "Epoch 3604/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4369 - val_loss: 8.0561\n",
            "Epoch 3605/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4763 - val_loss: 8.0660\n",
            "Epoch 3606/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4531 - val_loss: 8.1095\n",
            "Epoch 3607/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4776 - val_loss: 8.0781\n",
            "Epoch 3608/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5114 - val_loss: 8.1025\n",
            "Epoch 3609/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5515 - val_loss: 8.0731\n",
            "Epoch 3610/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5127 - val_loss: 8.1038\n",
            "Epoch 3611/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5353 - val_loss: 8.0589\n",
            "Epoch 3612/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5376 - val_loss: 8.0834\n",
            "Epoch 3613/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5425 - val_loss: 8.1001\n",
            "Epoch 3614/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5175 - val_loss: 8.0778\n",
            "Epoch 3615/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5190 - val_loss: 8.0774\n",
            "Epoch 3616/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4926 - val_loss: 8.0574\n",
            "Epoch 3617/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4814 - val_loss: 8.0623\n",
            "Epoch 3618/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5473 - val_loss: 8.0852\n",
            "Epoch 3619/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5004 - val_loss: 8.0643\n",
            "Epoch 3620/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5199 - val_loss: 8.0514\n",
            "Epoch 3621/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5184 - val_loss: 8.0854\n",
            "Epoch 3622/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5185 - val_loss: 8.1269\n",
            "Epoch 3623/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4855 - val_loss: 8.0632\n",
            "Epoch 3624/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4996 - val_loss: 8.0997\n",
            "Epoch 3625/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4649 - val_loss: 8.0815\n",
            "Epoch 3626/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4910 - val_loss: 8.1059\n",
            "Epoch 3627/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4885 - val_loss: 8.0666\n",
            "Epoch 3628/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9551 - val_loss: 8.0917\n",
            "Epoch 3629/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7957 - val_loss: 8.1284\n",
            "Epoch 3630/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5892 - val_loss: 8.1385\n",
            "Epoch 3631/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5486 - val_loss: 8.1248\n",
            "Epoch 3632/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5316 - val_loss: 8.1232\n",
            "Epoch 3633/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5020 - val_loss: 8.1825\n",
            "Epoch 3634/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.3418 - val_loss: 8.2826\n",
            "Epoch 3635/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1253 - val_loss: 8.1473\n",
            "Epoch 3636/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7430 - val_loss: 8.0994\n",
            "Epoch 3637/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6171 - val_loss: 8.0987\n",
            "Epoch 3638/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5791 - val_loss: 8.0983\n",
            "Epoch 3639/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5768 - val_loss: 8.1329\n",
            "Epoch 3640/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5293 - val_loss: 8.1363\n",
            "Epoch 3641/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7786 - val_loss: 8.1449\n",
            "Epoch 3642/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6441 - val_loss: 8.1626\n",
            "Epoch 3643/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6274 - val_loss: 8.1838\n",
            "Epoch 3644/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9262 - val_loss: 8.1472\n",
            "Epoch 3645/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7507 - val_loss: 8.1541\n",
            "Epoch 3646/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6229 - val_loss: 8.1146\n",
            "Epoch 3647/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5978 - val_loss: 8.1554\n",
            "Epoch 3648/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5919 - val_loss: 8.0990\n",
            "Epoch 3649/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5262 - val_loss: 8.0951\n",
            "Epoch 3650/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5252 - val_loss: 8.1287\n",
            "Epoch 3651/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5431 - val_loss: 8.1193\n",
            "Epoch 3652/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4767 - val_loss: 8.1606\n",
            "Epoch 3653/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5358 - val_loss: 8.1283\n",
            "Epoch 3654/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4574 - val_loss: 8.1579\n",
            "Epoch 3655/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4657 - val_loss: 8.1416\n",
            "Epoch 3656/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4938 - val_loss: 8.1270\n",
            "Epoch 3657/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4424 - val_loss: 8.1135\n",
            "Epoch 3658/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6373 - val_loss: 8.2189\n",
            "Epoch 3659/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6076 - val_loss: 8.1578\n",
            "Epoch 3660/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5692 - val_loss: 8.1405\n",
            "Epoch 3661/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5222 - val_loss: 8.1608\n",
            "Epoch 3662/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5613 - val_loss: 8.1398\n",
            "Epoch 3663/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5137 - val_loss: 8.1082\n",
            "Epoch 3664/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5210 - val_loss: 8.1779\n",
            "Epoch 3665/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5062 - val_loss: 8.1314\n",
            "Epoch 3666/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4652 - val_loss: 8.1072\n",
            "Epoch 3667/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4920 - val_loss: 8.1457\n",
            "Epoch 3668/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4417 - val_loss: 8.1059\n",
            "Epoch 3669/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4401 - val_loss: 8.1023\n",
            "Epoch 3670/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4662 - val_loss: 8.1239\n",
            "Epoch 3671/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4024 - val_loss: 8.1230\n",
            "Epoch 3672/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4701 - val_loss: 8.1221\n",
            "Epoch 3673/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5140 - val_loss: 8.1724\n",
            "Epoch 3674/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8055 - val_loss: 8.2050\n",
            "Epoch 3675/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5922 - val_loss: 8.1767\n",
            "Epoch 3676/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5063 - val_loss: 8.1405\n",
            "Epoch 3677/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5182 - val_loss: 8.1361\n",
            "Epoch 3678/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5051 - val_loss: 8.1277\n",
            "Epoch 3679/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4613 - val_loss: 8.1162\n",
            "Epoch 3680/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4866 - val_loss: 8.1341\n",
            "Epoch 3681/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4480 - val_loss: 8.1046\n",
            "Epoch 3682/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4793 - val_loss: 8.0786\n",
            "Epoch 3683/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4682 - val_loss: 8.1427\n",
            "Epoch 3684/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5061 - val_loss: 8.1287\n",
            "Epoch 3685/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4762 - val_loss: 8.1314\n",
            "Epoch 3686/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4757 - val_loss: 8.0996\n",
            "Epoch 3687/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5124 - val_loss: 8.1480\n",
            "Epoch 3688/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4539 - val_loss: 8.1420\n",
            "Epoch 3689/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4936 - val_loss: 8.1434\n",
            "Epoch 3690/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4702 - val_loss: 8.1299\n",
            "Epoch 3691/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4622 - val_loss: 8.0851\n",
            "Epoch 3692/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4419 - val_loss: 8.1104\n",
            "Epoch 3693/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4696 - val_loss: 8.0968\n",
            "Epoch 3694/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4457 - val_loss: 8.1365\n",
            "Epoch 3695/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4529 - val_loss: 8.1462\n",
            "Epoch 3696/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4118 - val_loss: 8.1525\n",
            "Epoch 3697/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4481 - val_loss: 8.1821\n",
            "Epoch 3698/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4470 - val_loss: 8.1434\n",
            "Epoch 3699/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4706 - val_loss: 8.1549\n",
            "Epoch 3700/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4641 - val_loss: 8.1530\n",
            "Epoch 3701/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5043 - val_loss: 8.1250\n",
            "Epoch 3702/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4538 - val_loss: 8.1225\n",
            "Epoch 3703/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4412 - val_loss: 8.0868\n",
            "Epoch 3704/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4817 - val_loss: 8.1187\n",
            "Epoch 3705/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4541 - val_loss: 8.1167\n",
            "Epoch 3706/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4841 - val_loss: 8.1555\n",
            "Epoch 3707/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4732 - val_loss: 8.1180\n",
            "Epoch 3708/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4602 - val_loss: 8.1265\n",
            "Epoch 3709/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4613 - val_loss: 8.1475\n",
            "Epoch 3710/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4252 - val_loss: 8.1531\n",
            "Epoch 3711/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4432 - val_loss: 8.1457\n",
            "Epoch 3712/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4756 - val_loss: 8.1129\n",
            "Epoch 3713/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4424 - val_loss: 8.1066\n",
            "Epoch 3714/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4632 - val_loss: 8.0933\n",
            "Epoch 3715/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4369 - val_loss: 8.1382\n",
            "Epoch 3716/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6424 - val_loss: 8.1029\n",
            "Epoch 3717/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5515 - val_loss: 8.1068\n",
            "Epoch 3718/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5511 - val_loss: 8.0762\n",
            "Epoch 3719/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5234 - val_loss: 8.1531\n",
            "Epoch 3720/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5164 - val_loss: 8.0998\n",
            "Epoch 3721/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4969 - val_loss: 8.1005\n",
            "Epoch 3722/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4849 - val_loss: 8.1049\n",
            "Epoch 3723/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5247 - val_loss: 8.1665\n",
            "Epoch 3724/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4666 - val_loss: 8.1120\n",
            "Epoch 3725/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4462 - val_loss: 8.1327\n",
            "Epoch 3726/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4429 - val_loss: 8.1080\n",
            "Epoch 3727/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4372 - val_loss: 8.1342\n",
            "Epoch 3728/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4595 - val_loss: 8.1608\n",
            "Epoch 3729/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4445 - val_loss: 8.0837\n",
            "Epoch 3730/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5913 - val_loss: 8.1332\n",
            "Epoch 3731/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4636 - val_loss: 8.1373\n",
            "Epoch 3732/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5371 - val_loss: 8.1797\n",
            "Epoch 3733/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5278 - val_loss: 8.1881\n",
            "Epoch 3734/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4523 - val_loss: 8.1857\n",
            "Epoch 3735/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4327 - val_loss: 8.1745\n",
            "Epoch 3736/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4445 - val_loss: 8.1032\n",
            "Epoch 3737/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4596 - val_loss: 8.1237\n",
            "Epoch 3738/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4254 - val_loss: 8.1353\n",
            "Epoch 3739/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4556 - val_loss: 8.1373\n",
            "Epoch 3740/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4106 - val_loss: 8.1057\n",
            "Epoch 3741/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4450 - val_loss: 8.0878\n",
            "Epoch 3742/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4599 - val_loss: 8.1342\n",
            "Epoch 3743/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8170 - val_loss: 8.2097\n",
            "Epoch 3744/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6997 - val_loss: 8.1706\n",
            "Epoch 3745/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7121 - val_loss: 8.0752\n",
            "Epoch 3746/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5903 - val_loss: 8.1052\n",
            "Epoch 3747/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5301 - val_loss: 8.0780\n",
            "Epoch 3748/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4788 - val_loss: 8.1292\n",
            "Epoch 3749/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5078 - val_loss: 8.0948\n",
            "Epoch 3750/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5452 - val_loss: 8.1661\n",
            "Epoch 3751/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4654 - val_loss: 8.1546\n",
            "Epoch 3752/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4825 - val_loss: 8.1346\n",
            "Epoch 3753/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4295 - val_loss: 8.1435\n",
            "Epoch 3754/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5061 - val_loss: 8.2235\n",
            "Epoch 3755/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4951 - val_loss: 8.2018\n",
            "Epoch 3756/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4968 - val_loss: 8.1946\n",
            "Epoch 3757/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4455 - val_loss: 8.1676\n",
            "Epoch 3758/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4818 - val_loss: 8.1727\n",
            "Epoch 3759/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4296 - val_loss: 8.2046\n",
            "Epoch 3760/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4385 - val_loss: 8.1497\n",
            "Epoch 3761/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4464 - val_loss: 8.1927\n",
            "Epoch 3762/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4738 - val_loss: 8.1950\n",
            "Epoch 3763/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4282 - val_loss: 8.1642\n",
            "Epoch 3764/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5101 - val_loss: 8.1954\n",
            "Epoch 3765/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4384 - val_loss: 8.1729\n",
            "Epoch 3766/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4231 - val_loss: 8.1702\n",
            "Epoch 3767/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4197 - val_loss: 8.1717\n",
            "Epoch 3768/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4779 - val_loss: 8.2237\n",
            "Epoch 3769/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5210 - val_loss: 8.2550\n",
            "Epoch 3770/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4707 - val_loss: 8.1615\n",
            "Epoch 3771/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4622 - val_loss: 8.1708\n",
            "Epoch 3772/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4669 - val_loss: 8.1513\n",
            "Epoch 3773/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4360 - val_loss: 8.1299\n",
            "Epoch 3774/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4674 - val_loss: 8.1804\n",
            "Epoch 3775/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4392 - val_loss: 8.1428\n",
            "Epoch 3776/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4981 - val_loss: 8.1425\n",
            "Epoch 3777/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4642 - val_loss: 8.1739\n",
            "Epoch 3778/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4341 - val_loss: 8.1162\n",
            "Epoch 3779/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4687 - val_loss: 8.1125\n",
            "Epoch 3780/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.2930 - val_loss: 8.1607\n",
            "Epoch 3781/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8388 - val_loss: 8.1868\n",
            "Epoch 3782/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6610 - val_loss: 8.1580\n",
            "Epoch 3783/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5442 - val_loss: 8.2709\n",
            "Epoch 3784/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5385 - val_loss: 8.1130\n",
            "Epoch 3785/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5253 - val_loss: 8.1576\n",
            "Epoch 3786/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4852 - val_loss: 8.2274\n",
            "Epoch 3787/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4802 - val_loss: 8.1628\n",
            "Epoch 3788/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4564 - val_loss: 8.2080\n",
            "Epoch 3789/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4401 - val_loss: 8.1892\n",
            "Epoch 3790/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4239 - val_loss: 8.1918\n",
            "Epoch 3791/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5001 - val_loss: 8.1707\n",
            "Epoch 3792/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6208 - val_loss: 8.2716\n",
            "Epoch 3793/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7143 - val_loss: 8.1984\n",
            "Epoch 3794/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5773 - val_loss: 8.2068\n",
            "Epoch 3795/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4552 - val_loss: 8.2092\n",
            "Epoch 3796/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4761 - val_loss: 8.1400\n",
            "Epoch 3797/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5971 - val_loss: 8.1597\n",
            "Epoch 3798/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5856 - val_loss: 8.1313\n",
            "Epoch 3799/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4776 - val_loss: 8.1456\n",
            "Epoch 3800/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4610 - val_loss: 8.1699\n",
            "Epoch 3801/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4901 - val_loss: 8.1729\n",
            "Epoch 3802/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4282 - val_loss: 8.1976\n",
            "Epoch 3803/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4311 - val_loss: 8.2643\n",
            "Epoch 3804/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4255 - val_loss: 8.1796\n",
            "Epoch 3805/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4081 - val_loss: 8.1921\n",
            "Epoch 3806/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4191 - val_loss: 8.2187\n",
            "Epoch 3807/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4507 - val_loss: 8.1702\n",
            "Epoch 3808/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4984 - val_loss: 8.1957\n",
            "Epoch 3809/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4561 - val_loss: 8.1854\n",
            "Epoch 3810/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4431 - val_loss: 8.2001\n",
            "Epoch 3811/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4322 - val_loss: 8.2543\n",
            "Epoch 3812/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4406 - val_loss: 8.1748\n",
            "Epoch 3813/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3951 - val_loss: 8.1735\n",
            "Epoch 3814/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4737 - val_loss: 8.1119\n",
            "Epoch 3815/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4719 - val_loss: 8.1973\n",
            "Epoch 3816/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4722 - val_loss: 8.1740\n",
            "Epoch 3817/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4801 - val_loss: 8.1967\n",
            "Epoch 3818/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4223 - val_loss: 8.2028\n",
            "Epoch 3819/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4554 - val_loss: 8.1928\n",
            "Epoch 3820/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4479 - val_loss: 8.1696\n",
            "Epoch 3821/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3989 - val_loss: 8.1947\n",
            "Epoch 3822/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8088 - val_loss: 8.3515\n",
            "Epoch 3823/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.6502 - val_loss: 8.2150\n",
            "Epoch 3824/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5277 - val_loss: 8.2283\n",
            "Epoch 3825/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5568 - val_loss: 8.2001\n",
            "Epoch 3826/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4883 - val_loss: 8.2137\n",
            "Epoch 3827/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4772 - val_loss: 8.2006\n",
            "Epoch 3828/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4207 - val_loss: 8.2440\n",
            "Epoch 3829/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9992 - val_loss: 8.3097\n",
            "Epoch 3830/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8665 - val_loss: 8.1877\n",
            "Epoch 3831/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.6544 - val_loss: 8.1881\n",
            "Epoch 3832/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5388 - val_loss: 8.1928\n",
            "Epoch 3833/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.5067 - val_loss: 8.1731\n",
            "Epoch 3834/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.5144 - val_loss: 8.1256\n",
            "Epoch 3835/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4593 - val_loss: 8.1582\n",
            "Epoch 3836/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4265 - val_loss: 8.1447\n",
            "Epoch 3837/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4712 - val_loss: 8.1500\n",
            "Epoch 3838/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4581 - val_loss: 8.1440\n",
            "Epoch 3839/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4487 - val_loss: 8.1721\n",
            "Epoch 3840/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3932 - val_loss: 8.1683\n",
            "Epoch 3841/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4777 - val_loss: 8.2587\n",
            "Epoch 3842/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4507 - val_loss: 8.1672\n",
            "Epoch 3843/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4381 - val_loss: 8.1972\n",
            "Epoch 3844/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3921 - val_loss: 8.1959\n",
            "Epoch 3845/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4784 - val_loss: 8.1803\n",
            "Epoch 3846/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.4304 - val_loss: 8.1999\n",
            "Epoch 3847/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3781 - val_loss: 8.1793\n",
            "Epoch 3848/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3688 - val_loss: 8.2006\n",
            "Epoch 3849/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.3585 - val_loss: 8.1586\n",
            "Epoch 3850/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.3962 - val_loss: 8.2059\n",
            "Epoch 3851/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4160 - val_loss: 8.1700\n",
            "Epoch 3852/10000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.4487 - val_loss: 8.2420\n",
            "Epoch 3853/10000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1694 - val_loss: 8.3118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.plot_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xTQiLcfZddiX",
        "outputId": "413dbd09-bf69-4d6d-ea4a-266363242c7a"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnMpOF7HtIAiTsCkGQgDvWfd9albbWqtfq/alVu7nVLtZqF9trbb292l43bLGVam9rtdYFUaQiEpB9DQFCQvZ9X2a+vz/OARMIWyaTM5n5PB+PPDJzZuacd84k887ZxRiDUkqp8ONyOoBSSilnaAEopVSY0gJQSqkwpQWglFJhSgtAKaXClNvpAABpaWkmLy/P6RhKKTWirFq1qtYYkz7Y1wdFAeTl5VFUVOR0DKWUGlFEZLc/r9dVQEopFaa0AJRSKkxpASilVJgKim0ASqnw1NPTQ1lZGZ2dnU5HCWrR0dHk5ubi8XiGdLxaAEopx5SVlREfH09eXh4i4nScoGSMoa6ujrKyMvLz84d03EdcBSQiz4lItYhs6DMsRUTeEZHt9vdke7iIyG9EpFhE1onIiUOaVikVUjo7O0lNTdUP/8MQEVJTUwOylHQ02wBeAC48YNj9wGJjzCRgsX0f4CJgkv11K/DU0MRUSoUq/fA/skDNoyMWgDFmKVB/wOArgAX27QXAlX2Gv2gsHwNJIjJ6qMIeaGvRYpa/8ACNNXsDNQmllApZg90LKNMYU2HfrgQy7ds5wJ4+zyuzhx1ERG4VkSIRKaqpqRlUiIbNH3DKrv+h+pmrQa9roJQahLi4OKcjOMbv3UCNdUWZY/70Ncb83hhTaIwpTE8f3JHMJ1//MO/lf4fJXRup3fbxoMahlFLharAFULVv1Y79vdoeXg6M6fO8XHtYwIw760Z6jYuqT14N5GSUUiHOGMM999zD9OnTKSgo4OWXXwagoqKCefPmMXPmTKZPn86HH36I1+vlxhtv3P/cX/3qVw6nH5zB7gb6GnAD8DP7+9/7DP+6iPwZOAlo6rOqKCDGj8lltUwlo/yDQE5GKRVgP/rHRjbtbR7ScR6fncAPL5t2VM/961//ypo1a1i7di21tbXMmTOHefPm8dJLL3HBBRfw4IMP4vV6aW9vZ82aNZSXl7Nhg7VzZGNj45DmHi5Hsxvon4DlwBQRKRORm7E++M8Tke3AufZ9gH8CJUAx8L/A7QFJ3T8flUmzyO4shu62QE9OKRWili1bxpe+9CUiIiLIzMzkzDPPZOXKlcyZM4fnn3+ehx56iPXr1xMfH8/48eMpKSnhzjvv5F//+hcJCQlOxx+UIy4BGGO+dIiHzhnguQa4w99Qx6onu5CIxoV07V5F1KR5wz15pdQQONr/1IfbvHnzWLp0KW+88QY33ngj3/rWt/jqV7/K2rVreeutt3j66adZtGgRzz33nNNRj1lInAsodvzJANQX64ZgpdTgnHHGGbz88st4vV5qampYunQpc+fOZffu3WRmZnLLLbfwta99jdWrV1NbW4vP5+MLX/gCjzzyCKtXr3Y6/qCExKkg8seOodIk012+3ukoSqkR6qqrrmL58uWccMIJiAiPPfYYWVlZLFiwgF/84hd4PB7i4uJ48cUXKS8v56abbsLn8wHw05/+1OH0gyMmCPafLywsNP5cEKbH62P5jz7H5LgOsu5dOYTJlFKBtHnzZo477jinY4wIA80rEVlljCkc7DhDYhWQJ8JFZfR4Ujt2grfX6ThKKTUihEQBALQmTsZjeqC+xOkoSik1IoRMAZB5PADeqo0OB1FKqZEhZAogPncavcZFa+lap6MopdSIEDIFMC4zld0mk+6KTU5HUUqpESFkCiA/LZZSk4E0ljodRSmlRoSQKYC0uEiqXJnEtOu1AZRS6miETAGICJ2x2cR6m6Crxek4SqkQdLhrB+zatYvp06cPYxr/hUwBAJBkn4m6cc/hn6eUUio0TgWxT3RaPuyFnvpdeOzdQpVSI8Sb90PlEJ/OJasALvrZIR++//77GTNmDHfcYZ3D8qGHHsLtdrNkyRIaGhro6enhkUce4YorrjimyXZ2dnLbbbdRVFSE2+3m8ccf56yzzmLjxo3cdNNNdHd34/P5ePXVV8nOzubaa6+lrKwMr9fL97//febPn+/Xj320QqoAkkfnwTpoqNhFhh5drpQ6gvnz5/ONb3xjfwEsWrSIt956i7vuuouEhARqa2s5+eSTufzyy4/pwuy//e1vERHWr1/Pli1bOP/889m2bRtPP/00d999N9dddx3d3d14vV7++c9/kp2dzRtvvAFAU1NTQH7WgYRUAeSMti4/3FBfS4bDWZRSx+gw/6kHyqxZs6iurmbv3r3U1NSQnJxMVlYW3/zmN1m6dCkul4vy8nKqqqrIyso66vEuW7aMO++8E4CpU6cybtw4tm3bximnnMKjjz5KWVkZn//855k0aRIFBQV8+9vf5r777uPSSy/ljDPOCNSPe5CQ2gaQnZZMl3HT3VrndBSl1AhxzTXX8Morr/Dyyy8zf/58Fi5cSE1NDatWrWLNmjVkZmbS2dk5JNP68pe/zGuvvUZMTAwXX3wx7733HpMnT2b16tUUFBTwve99j4cffnhIpnU0QmoJIHFUJPXEYjpG5uXZlFLDb/78+dxyyy3U1tbywQcfsGjRIjIyMvB4PCxZsoTdu3cf8zjPOOMMFi5cyNlnn822bdsoLS1lypQplJSUMH78eO666y5KS0tZt24dU6dOJSUlha985SskJSXxzDPPBOCnHFhIFUCES2iROFydw7cOTSk1sk2bNo2WlhZycnIYPXo01113HZdddhkFBQUUFhYyderUYx7n7bffzm233UZBQQFut5sXXniBqKgoFi1axB/+8Ac8Hg9ZWVl897vfZeXKldxzzz24XC48Hg9PPfVUAH7KgYXE9QD62vjwXCKiY5l675IhGZ9SKnD0egBHT68HcBQ63IlE9TQ7HUMppYJeSK0CAuiJTCSmfZfTMZRSIWr9+vVcf/31/YZFRUWxYsUKhxINXsgVgDcqibjWVqdjKKWOkjHmmPaxd1pBQQFr1qwZ1mkGalV9yK0CMtFJxNGO6e12OopS6giio6Opq6sL2AdcKDDGUFdXR3R09JCPO+SWAFyxKQC0NdcRlzLa4TRKqcPJzc2lrKyMmpoap6MEtejoaHJzc4d8vCFXAG67AJrra7UAlApyHo+H/Px8p2OErZBbBRSTkApAc0O1w0mUUiq4hVwBJKRYZwFqbtBFSqWUOpyQK4CUVKsA2hu1AJRS6nBCrgDik60C6NITwiml1GGFXAFITBI+BF9bvdNRlFIqqIVcAeCKoE3icLXXOp1EKaWCWugVANDuScLT3eB0DKWUCmohWQDdUSmM6mnUowuVUuowQrIAfDGpJNNMfZueDkIppQ7FrwIQkW+KyEYR2SAifxKRaBHJF5EVIlIsIi+LSORQhT1artg0UqSZyuahuYybUkqFokEXgIjkAHcBhcaY6UAE8EXg58CvjDETgQbg5qEIeiw88ekk00plY/twT1oppUYMf1cBuYEYEXEDo4AK4GzgFfvxBcCVfk7jmMUkZ+IWH/V1ejoIpZQ6lEEXgDGmHPglUIr1wd8ErAIajTG99tPKgJyBXi8it4pIkYgUDfWZAOOSMwForasc0vEqpVQo8WcVUDJwBZAPZAOxwIVH+3pjzO+NMYXGmML09PTBxhhQRJw1vo7GqiEdr1JKhRJ/VgGdC+w0xtQYY3qAvwKnAUn2KiGAXKDcz4zHLjYNgO4WPR+QUkodij8FUAqcLCKjxLqe2znAJmAJcLX9nBuAv/sXcRBGWQWAHg2slFKH5M82gBVYG3tXA+vtcf0euA/4logUA6nAs0OQ89iMsq4J4OrQ8wEppdSh+HVFMGPMD4EfHjC4BJjrz3j95ommO2IUcV2NtHf3Mioy5C58ppRSfgvJI4EBeqJSrIPBmvRgMKWUGkjIFoAvJpUUWrQAlFLqEEK2AFwJWWRKAxVaAEopNaCQLYCo1HGMljrKGzucjqKUUkEpZAvAnZxLgnRQU6Ong1BKqYGEbAGQmAtAR12pw0GUUio4hW4BJFgFQGOZszmUUipIhW4B2EsA0e176fH6HA6jlFLBJ3QLID4Ln0SQJXXs1Q3BSil1kNAtAFcEPaMyyZY69tRrASil1IFCtwAAEnPJljp217c5nUQppYJOSBdAZMpYcqSO3XV6aUillDpQSBeAJOaSJfXsrmlxOopSSgWdkC4AEnPx0EtT7fBfk0YppYJdyBcAQG9DGT6fcTiMUkoFl9AugATrevTpvhoqmvWkcEop1VdoF4C9BJAtteyq1T2BlFKqr9AugJhkfO4YsqWeEi0ApZTqJ7QLQARJGsOYiDp21mgBKKVUX6FdAIAk5DDO3UBJbavTUZRSKqiEfAGQNIZsqtmpq4CUUqqf0C+A9KnEe5toq6+kq9frdBqllAoaYVEAABOljFI9JYRSSu0X+gWQcRwAk6SMHbohWCml9gv9AogfjYlKZIrs0Q3BSinVR+gXgAiSeTwFnjJKdAlAKaX2C/0CAMiZzXGmhD01DU4nUUqpoBEeBTDuVCLpIaZmndNJlFIqaIRHAYw5CYCp3Rupbe1yOIxSSgWH8CiA2DTaEyZQ6NrKtiq9OIxSSkG4FAAg405mjmsr2yqanI6ilFJBIWwKIHriPBKlnZZdnzodRSmlgkLYFICMPwuApIplDidRSqngEDYFQHwmldETmNRahDF6eUillPKrAEQkSUReEZEtIrJZRE4RkRQReUdEttvfk4cqrL/qM09lFluorNfjAZRSyt8lgF8D/zLGTAVOADYD9wOLjTGTgMX2/aDgmng2UdJDzYb3nY6ilFKOG3QBiEgiMA94FsAY022MaQSuABbYT1sAXOlvyKGSWXA2PSYCX8lSp6MopZTj/FkCyAdqgOdF5FMReUZEYoFMY0yF/ZxKIHOgF4vIrSJSJCJFNTU1fsQ4eslJSWyTfOJrdE8gpZTypwDcwInAU8aYWUAbB6zuMdbW1gG3uBpjfm+MKTTGFKanp/sR49iUxk4nt30zeHuGbZpKKRWM/CmAMqDMGLPCvv8KViFUichoAPt7tX8Rh1Zrxmyi6MJUrnc6ilJKOWrQBWCMqQT2iMgUe9A5wCbgNeAGe9gNwN/9SjjEIsZZ5wVq2qbHAyilwpvbz9ffCSwUkUigBLgJq1QWicjNwG7gWj+nMaTG5E2i3KTi3vkxnHWX03GUUsoxfhWAMWYNUDjAQ+f4M95AmpwRz1LfJM6uXAHGgIjTkZRSyhHhcySwLXGUh02eAmK7a6F6s9NxlFLKMWFXAAA1GadaN8o+cTaIUko5KCwLICF7CvUmHlO64shPVkqpEBWWBTA5K56PfMfjLX7P2g6glFJhKCwLYFJmPO/7ZuJuq4SKtU7HUUopR4RpAcSx2DsLHy7Y+qbTcZRSyhFhWQAJ0R6iEzMojZ4CO95zOo5SSjkiLAsArNVAH3EClBdBR6PTcZRSatiFbQFMzojj9dYpYHywS08LoZQKP+FbAJnxFPWOx7gi9XgApVRYCt8CyIqnGw9NScfBnpVOx1FKqWEXtgUwKSMOgNKoyVC1UY8HUEqFnbAtgNgoN2NSYtjamwldTdBW63QkpZQaVmFbAAAzcpNY3pRi3anb7mwYpZQaZmFdADNzk/ikZV8BFDsbRimlhllYF0BBbiJ7TRo+lwdqdQlAKRVewroApmbF48NFY8wYqNvhdByllBpWYV0ASaMiyUyIosyVo6uAlFJhJ6wLAKwDwrb2ZEJ9CXh7nY6jlFLDJuwLYEpmPJ+2pYKvB5pKnY6jlFLDJuwLYHJWPFt7s6w7tboaSCkVPsK+AKZkxrPTjLbu6HYApVQYCfsCmJQZR4PE0+mO1wJQSoWVsC+AUZFuxqbEUunO0aOBlVJhJewLAKw9gbZ7R+s2AKVUWNECwNoOsKEjFVr2Qk+n03GUUmpYaAFg7Qm025dh3WnUXUGVUuFBCwBrCaDU7CuA3c6GUUqpYaIFAOSnxVLhyrTu1O90NoxSSg0TLQAg0u0iITWHTomGBi0ApVR40AKwTR6dQDkZugSglAobWgC2yRlxlPSm4WvY5XQUpZQaFloAtvHpcewxGZiG3XqBeKVUWNACsI1Pj2WPSSeitx3a65yOo5RSAed3AYhIhIh8KiKv2/fzRWSFiBSLyMsiEul/zMDLS41lz75dQRt0V1ClVOgbiiWAu4HNfe7/HPiVMWYi0ADcPATTCLiYyAi64sZYd3RPIKVUGPCrAEQkF7gEeMa+L8DZwCv2UxYAV/ozjeEUmZZv3dCDwZRSYcDfJYAngHsBn30/FWg0xuy7tmIZkDPQC0XkVhEpEpGimpoaP2MMjZzMNOpIsDYEK6VUiBt0AYjIpUC1MWbVYF5vjPm9MabQGFOYnp4+2BhDKj8tlj2+dHpqdRWQUir0uf147WnA5SJyMRANJAC/BpJExG0vBeQC5f7HHB7j0+MoM+lMbdATwimlQt+glwCMMQ8YY3KNMXnAF4H3jDHXAUuAq+2n3QD83e+Uw2R8Wix7TSrutgo9FkApFfICcRzAfcC3RKQYa5vAswGYRkBkJ8VQI6m4fV3Q0eB0HKWUCih/VgHtZ4x5H3jfvl0CzB2K8Q63CJfgix8N7UBzOYxKcTqSUkoFjB4JfIDIZPtYgOa9zgZRSqkA0wI4QFzmOAC8jXscTqKUUoGlBXCAjNFj6TCRtJZvdTqKUkoFlBbAAcZnJFBssumt2nzkJyul1AimBXCA8WnWsQCu5jKnoyilVEBpARwgOTaS2ogMYjv1WAClVGjTAhhAV2wOkb5OPRZAKRXStAAG4E4Za91o1FNCKKVClxbAABKzrNNCN1fpSeGUUqFLC2AAWWMnAVBXXuxwEqWUChwtgAFMGGcdC9BWrdcFUEqFLi2AAaTHR7NXMpBGXQWklApdWgADEBHqoseS2LbL6ShKKRUwWgCH0JU4gczeCnw93U5HUUqpgNACOARP5hQ84qVy9xanoyilVEBoARxCYt5MAGp2rHY4iVJKBYYWwCGMnTgdgPIdGx1OopRSgaEFcAixCclUk0Jcyw6noyilVEBoARxGU9x4Ujt2YvSkcEqpEKQFcBhxkS6mUUJlY6vTUZRSashpARyGZBwHQOlW3RCslAo9WgCHET/nSwDUlJU4nEQppYaeFsBhxKZbF4hv3KsbgpVSoUcL4HDismiNSCK+bi1dvV6n0yil1JDSAjgcl4uOrNnMMpv5qLjW6TRKKTWktACOIGnGRYx11VC0aqXTUZRSakhpARyBZ/J5APi2v0Nnj64GUkqFDi2AI0nOoz1hPCd5P+Wf6yucTqOUUkNGC+AoxBx3AadEbGbR8m1OR1FKqSGjBXAUZNK5RNFNdPlyNu1tdjqOUkoNCS2AozHudIw7hvPca/jl21udTqOUUkNCC+BoeKKRKRdyScTHfLhlL+vLmpxOpJRSftMCOFonfIkk08yZrrUsXLHb6TRKKeW3QReAiIwRkSUisklENorI3fbwFBF5R0S229+Thy6ugyacDbHp3J68kv/7tJz6Nr1WsFJqZPNnCaAX+LYx5njgZOAOETkeuB9YbIyZBCy27498ER4ouIaZHR8T1dvMgo92OZ1IKaX8MugCMMZUGGNW27dbgM1ADnAFsMB+2gLgSn9DBo0TvojL182TGa/z9Ac7KG/scDqRUkoN2pBsAxCRPGAWsALINMbsO2KqEsgcimkEhawZAJzR/SE9vb1c9uQyhwMppdTg+V0AIhIHvAp8wxjTbyd5Y11LccDrKYrIrSJSJCJFNTU1/sYYHiJw9fO4Ohv4asJq6tu6Ka5ucTqVUkoNil8FICIerA//hcaYv9qDq0RktP34aKB6oNcaY35vjCk0xhSmp6f7E2N4HX8FRETxUPfjJHt6ufTJZXrNYKXUiOTPXkACPAtsNsY83ueh14Ab7Ns3AH8ffLwg5IqAM74NwE+mFNPZ4+N3S/WKYUqpkcefJYDTgOuBs0Vkjf11MfAz4DwR2Q6ca98PLfO+A1kFXFj/RyLw8rM3t9DU0eN0KqWUOib+7AW0zBgjxpgZxpiZ9tc/jTF1xphzjDGTjDHnGmPqhzJwUHBFwOceQOpLeH7GZgC+97cNuipIKTWi6JHAgzXlYsgsYN62n/DNmfCPtXuZ9sO3WLy5yulkSil1VLQABksEzv4eAHfWPwJAe7eXmxcUkXf/G/zP+8VOplNKqSPSAvDHlAth4nm4qjexZfZr/R567F961lClVHDTAvDX/D8CEL3xz2y8OZ7MhKj9DxXtCr3NH0qp0KEF4C9PNNy5GoDYhZfx1u0n7n/o6qeXk3f/G2zcq6ePVkoFHy2AoZA6Ac59CICkJ/LZ+eOzueucSfsfvuQ3y/pdQ+DdTVU8uXj7MIdUSqn+JBh2XSwsLDRFRUVOx/Dfwmth+1vW7e/upaozgjN+voRur2//U3KSYvafRG7jjy5gbVkjp05IcyKtUmqEE5FVxpjCQb9eC2CI/eEq2PGedfvWDyB7JjUtXTz9wQ6eXbZzwJc8cuV0zpqaQU5SzDAGVUqNdFoAweiFS2HXh9btK5+CmV8GoLvXx98+LeeFj3axqeLgi8tHuIQHLz6OL8zOxe0SPtxey4XTs/Y/7vUZjDG4I3TNnVJKCyB4rVoA/7jLuj31UqsIohP2P9zr9fGLt7Ye8TxCN52Wx/cvOR6fMUx88E1iPBFs/vGFAHxcUseT723n2RvmEO2JCNiPopQKTloAway7Df78ZSh5/7Nh36sGd9RBT61t7eK/3t7Gnz4pPeJoPz8rh8eunsGlTy5jS2ULf/l/pzAnL2UIgyulRgItgJFg8+vw8nX9h923G2KSDvmSvY0drC9v4qUVpXyw7cjXS7jhlHH0+AyJMR6+ee5k3C7BawyeCBdtXb1sKG/ipPGp/v4kSqkgogUwUnh74aNfw+KHPxs27x6Iz4LZN1knmDsMYwwN7T38eWUp/9pQybqyYz+24D/PHM/vPijhifkzeWVVGZsqmnnv22eSNCqy33ReW7uXUyekkR5/8JLK0fL5DPXt3aTFDX4cSqnD0wIYabpa4cXLoXzVwY9d/RzkzoWkMcc0yt11bXy0o44N5U0sXHHkVUgHSoh209zZe9Dw52+cQ0ZCFBEuwRPhIj81FpdLAGhq7yEhxo11WYiD/dfbW3nyvWLW/OC8fgUD0NbVS31bN2NSRh1zVqXUZ7QARrKKdfC7Mw4enjENsqZD3ulQcA14Br97qNdn+GRnPe3dvRRXt/LTN7f4Efhgs8clc1J+Cu9sqmJ7dSv3XjiFPy7fzd6mTgCuP3kcP7jseGY9/A63fW4C1xaO4dE3NvG3NXt57AszeH19Bd84dxInjk3uN95XVpXxnb+sZVJGHNurW1n/0PnER3sOmv62qhYef3sbt8zLZ/Y43Q6iwosWQKgoW2XtOrrqeWgqB1+fC8wkjoHOJuhqhi++BBPPHXBDsj+8PsPexg721LdT0dTJe1uqKdpdT1Vz15BO51DGpY5id107ABnxUVS39J9uWlwks8Ymc+LYZJ56v5jmzl7mF47h5aI9+5/z+p2nMykzjn9tqGRShnVepn/vqOPX725jek4iT8yfiddneHNDJceNTmDV7nqumT2Gzl4va/c0kR4fybmPLyUrIZpl952FSwQR+OOKUmbkJDIjN5Eer8FnzCH3ujLG8O7mas6ZmrF/aamve19ZywXTsjjnuExWlNTx30uK+eU1J5CZEA1YOwP88LWN/OTKAhJHHVx4je3d3PqHVTz2hRnkpcUOen47afmOOiLdLmaPSz7yk4dYTUuXX6s2g40WQCgyBmq2wHuPQM1WaKu2CqCv6ERr2JRLIG0SNJbCSf8JMcmQOglcgT9WoL27l4qmTowx7GnooKali5bOXp5btpNxqaO4alYOP359E5fPzOajHXWU1LQdclwxngg6erwBzzxUXAJz81PITIhmXVkTN52Wx5vrK1leUgfAJQWjuXbOGDwu4cvPrADg6tm5vLKqDIDHrp7Bva+sA+C0iaks/NrJdPf6+PXibfx2yQ6+dno+37v0eHw+w8pd9czNT0FE+NMnpTzw1/VcOC2Lp6+f3S9TbWsXcVFuoj0RVDV3srO2jZPHp1LZ1InPWDsIRLpddPf6iI1yY4zhodc2cuWsHGaNTabX6+NX727jq6fk8cnOejwRLi6cnkVDWzcvLt/NbZ+bQKR74N+rmpYuNuxt4nOT0xER2rp66er1kRJrrf5buaueGbmJRLkjyLv/DQD+47R8fnDZ8UPyfqzZ00hTRw9nTj709cUXb67i5gVFLPzaSZw2MY0er4/fLN7OzafnH7Sa8kg6ur2s2t3A6ZOO7ij+soZ24qLc/abj8xnaunuJjXQP+M/C0dACCBfNFfDa18HbDbXbITkfSj86+tePPgE6GiHnRBh/FqRPhYRscEdDVFz/1UzGWNc7cEiv10dDew+psZFsrmwmJTaS2pZualu7qG3tomhXA0mjPHh9hvLGDj4tbaTH66OurRuXgM9YSwy1rd0HjXvfB+BIMD499rClOTUrni2VLcRHu2kZYBsOwJTMeLZWtQz42L55BXBSfgordh757LUn5acwPSeRZ5ft5OrZuXgiXJTWt/Hv4rr9z7lqVg7/92n5/vs3nprHCx/tAuBHl0/jh69t3P9YyU8uprS+HY/bxZrSRi6ansXf15bzxrpKkkd52FLZwjWFuUzLTuDpD0r49vmTmZqVwL+LaxEgOymG3OQYJj74JmAtBU7PSaS6pZOm9h5+t7SEquZOXvyPubzw0S5+9I9NXDM7l19ccwJvrKvgjpesEznOHpfMq7ed2u9n9fkM1S1drNxVz6UzRvfb3nXST96lqrmLO86awD0XTGVHTSsT0uP6vb6quZMIl5AWF0Xe/W8QF+Vm/UPn09Hj5ZE3NnP+8Znc+PxKHr5iGl89Je+I834gWgDhrmoTVKyFd74PPR3Q3RrY6cVmwPTPW8URlwnLHoe2GmsDtjFQtRFSJ0LVBqjdBuf9GEalWKusquw//OhEqN4MyXkQlQBJY8HXCy63VVSVxw0AAApdSURBVEQOlI8xBmPAAD1eH109Plwu2FXbTnKshz31HXR7ffT0+mjv8ZIU46GkppVRUW62V7VgDHT0eJmQHsdHO2rx+gwVTZ1MzYpnT0MHLZ09jE6MOWiX3rOmpJOVGM2OmjY+sT+AU2NcTBuTSnevl49LBv5Qjva48PoMPV7n/35HkgRaaSaO6TkJbCg/+Gj8mWOSWLOnsV857hPhEq4+MZctlc2sLWskgXaa6b8a7prZuby6uqzfa+eOS+TT3XVE0kMvEUTRQ75UsMnkUejayjVXXcvn5+QN6ufRAlCHZwy010NXE6z7C7z/E+uD1jfwf4wj3sTzoPidQz8++UKroJb/d//hkXGfleeYkyF7Jmx/2yq50uXW8AnnWAf3eaKtg/vO+zH0dsKSR2HevdYuvW98y3rujPlWAe79FPLOsJbaxAXpU6ByPRgfGK+1Gi82w7q4UG+39b5seMUaX9IYq+DXvARzvwZR8dBabY3D22M91+eF+CxM/GikvgTiMmDTa9DZCHXFmNPuRra/bV2vuq0G09mMGT0LX+oEpK4Y01KNq62S1sy5RLg9eKJHUZVxBmbvGpJ8DfT6DFU55xFf8iZ7PWPxxWaQV/9v9sROJ7f5UzaaPFpi84jrbWBschTtFVsprvfSGZlMYeQuPhx1HnWd0NbrIlY6Oa31bRomXMFJFS+xK2Icn2R/hdL6dqZEVPDhxl3kjp9K9vaXuML1b36W9hNaK4tpMaOIpJfr3e+wPvVCPq3ykiItfN39N/7pnUsNSfzQ/SJx0smjo+6jvLGDU1yb2GvSSJFmTnZtYo1vIte73wWgQ2J4qvsS2ohmmmsXmTRwWsRGXveeRLOJxYdgEApcO3HhY4brs3N4VZgU2hjFRCnr9+vTZdyUmzTipYNYOhklR7/trGLO/Yy+5IGjfn5fWgAqMIyxvspWQmKOtY3B57U+dDobYfM/rL2UihdD0x7rdNidzdaG7IgoKH4XEnNhwlkgEfDWA9a2ibrtMOYk2GOtFydpnLV0kJANKROg6FlrdVXF2v55PKOgp32454IKNzHJ0N1uHZdz4O+buDDRidDTifRaZ/QlZ7a1S3fKeEiZgPF2W9vvXG6k2VoN5ksej6vBOuWLcbmRPv98tRV8ldhLHu13mphjoQWgwpO3FyLc0NVirY5yuT97rLPRKi9vN0TYG906GqxVZKPsXUXrdlj/xWdOs/auaq2xVj2NPRl6u6BhF1RvslZTbXjV+u/88ietjesuD7RUQm+HVYC5c6zxuCKgrRbqd1h5jM/6zz82zdqzKyEbWiqgfqe1Yd/lgdPutqZV/K71H/7cWyA23frPv7fTWgLZvQzaG6Bxt1Ww8aOtEt30N0jIsbYHRSdAa5U1fMXTcPyV1hJG/Gjr7LSJudb3yHiYdB6MSoWV/wvZJ1rbgHYutR5Lnwz5Z1qr9g40+SKruDvqreNVyj6xhkfGQ3cLRCVaS5p9nXqntf2qqxlKP7a+7zP9amsJaM8Kq+BbK+GcH8CeT6z3ddpVsOwJOPF662erWAtTLrJ2jph0gfVeTjrfep+jE60P4d5Oa77X7bBWLfZ0WO9HTqH1z0v2LGjYCXFZ4O36bAkswmO9Zw5u+xoMLQCllApT/haAnldYKaXClBaAUkqFKS0ApZQKU1oASikVprQAlFIqTGkBKKVUmNICUEqpMKUFoJRSYSooDgQTkRpg9yBfngbUDmGcoRbM+YI5GwR3vmDOBsGdL5izQXDnOzDbOGPMoc+BfQRBUQD+EJEif46EC7RgzhfM2SC48wVzNgjufMGcDYI731Bn01VASikVprQAlFIqTIVCAfze6QBHEMz5gjkbBHe+YM4GwZ0vmLNBcOcb0mwjfhuAUkqpwQmFJQCllFKDoAWglFJhakQXgIhcKCJbRaRYRO53KMMuEVkvImtEpMgeliIi74jIdvt7sj1cROQ3dt51InJiAPI8JyLVIrKhz7BjziMiN9jP3y4iNwQw20MiUm7PvzUicnGfxx6ws20VkQv6DA/I+y4iY0RkiYhsEpGNInK3Pdzx+XeYbEEx/0QkWkQ+EZG1dr4f2cPzRWSFPa2XRSTSHh5l3y+2H887Uu4AZHtBRHb2mXcz7eHD+ndhjzdCRD4Vkdft+8Mz34wxI/ILiAB2AOOBSGAtcLwDOXYBaQcMewy43759P/Bz+/bFwJuAACcDKwKQZx5wIrBhsHmAFKDE/p5s304OULaHgO8M8Nzj7fc0Csi33+uIQL7vwGjgRPt2PLDNzuH4/DtMtqCYf/Y8iLNve4AV9jxZBHzRHv40cJt9+3bgafv2F4GXD5c7QNleAK4e4PnD+ndhj/tbwEvA6/b9YZlvI3kJYC5QbIwpMcZ0A38GrnA40z5XAAvs2wuAK/sMf9FYPgaSRGT0UE7YGLMUqPczzwXAO8aYemNMA/AOcGGAsh3KFcCfjTFdxpidQDHWex6w990YU2GMWW3fbgE2AzkEwfw7TLZDGdb5Z8+DVvuux/4ywNnAK/bwA+fdvnn6CnCOiMhhcgci26EM69+FiOQClwDP2PeFYZpvI7kAcoA9fe6Xcfg/iEAxwNsiskpEbrWHZRpjKuzblUCmfdupzMeaZ7hzft1e1H5u3+oVp7PZi9azsP5bDKr5d0A2CJL5Z6/GWANUY3047gAajTG9A0xrfw778SYgNVD5DsxmjNk37x61592vRCTqwGwHZAjUvHsCuBfw2fdTGab5NpILIFicbow5EbgIuENE5vV90FjLZ0Gzr22w5QGeAiYAM4EK4L+cjQMiEge8CnzDGNPc9zGn598A2YJm/hljvMaYmUAu1n+fU53KcqADs4nIdOABrIxzsFbr3DfcuUTkUqDaGLNquKcNI7sAyoExfe7n2sOGlTGm3P5eDfwf1i9+1b5VO/b3avvpTmU+1jzDltMYU2X/cfqA/+WzxVZHsomIB+sDdqEx5q/24KCYfwNlC7b5Z2dqBJYAp2CtPnEPMK39OezHE4G6QOfrk+1Ce7WaMcZ0Ac/jzLw7DbhcRHZhrY47G/g1wzXfhmIDhhNfgBtrI0w+n23MmjbMGWKB+D63P8JaJ/gL+m80fMy+fQn9Ny59EqBcefTf0HpMebD+G9qJtaEr2b6dEqBso/vc/ibWekyAafTfqFWCtQEzYO+7PR9eBJ44YLjj8+8w2YJi/gHpQJJ9Owb4ELgU+Av9N2bebt++g/4bMxcdLneAso3uM2+fAH7m1N+FPf7P8dlG4GGZb0P+4TOcX1hb67dhrWt80IHpj7dn+lpg474MWOvkFgPbgXf3/ZLYv1C/tfOuBwoDkOlPWKsCerDWA948mDzAf2BtSCoGbgpgtj/Y014HvEb/D7QH7WxbgYsC/b4Dp2Ot3lkHrLG/Lg6G+XeYbEEx/4AZwKd2jg3AD/r8jXxiz4e/AFH28Gj7frH9+Pgj5Q5AtvfsebcB+COf7Sk0rH8Xfcb9OT4rgGGZb3oqCKWUClMjeRuAUkopP2gBKKVUmNICUEqpMKUFoJRSYUoLQCmlwpQWgFJKhSktAKWUClP/H6OWM7amGwizAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.m.evaluate(SalaryPrediction.x_test, SalaryPrediction.y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsXRP5q81xWc",
        "outputId": "f7ab4086-a2ae-425d-f08a-cc0344a8c452"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.669816493988037"
            ]
          },
          "metadata": {},
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SalaryPrediction.m.evaluate(SalaryPrediction.x_train, SalaryPrediction.y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpwGBpZpfP5l",
        "outputId": "f25e5357-d3c9-41c4-a881-cd6bf08e2b4a"
      },
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.801551818847656"
            ]
          },
          "metadata": {},
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def result_vis(features, label):\n",
        "  y_pred = SalaryPrediction.m.predict(features).flatten()\n",
        "  plt.figure(figsize = (7, 7))\n",
        "  plt.scatter(label, y_pred, alpha=0.6, s=75, c = 'g')\n",
        "  plt.xlabel('True Values')\n",
        "  plt.ylabel('Predictions')\n",
        "  di = [0, 900000]\n",
        "  plt.xlim(di)\n",
        "  plt.ylim(di)\n",
        "  plt.plot(di, di, linewidth=2)"
      ],
      "metadata": {
        "id": "LR0O9i2N1wlT"
      },
      "execution_count": 543,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_vis(SalaryPrediction.x_test, SalaryPrediction.y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "sQVGQlsWgEb3",
        "outputId": "98fc53fd-e972-412e-d462-cbc0495d1b7b"
      },
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_vis(SalaryPrediction.x_train, SalaryPrediction.y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Q5Ue7Yt3gSUn",
        "outputId": "ffa59aaf-8243-40b5-c2d3-c60898c92bee"
      },
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAGtCAYAAADK53caAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXwV1f3/8dfn3qyELOw7gooioAgEEqu1LW6oVbS1KsiiQLB1qdb+rLa2tdVqtba2pVq+sgkoi1alWqtStNZWK4GACFFQIvseCFnInnvP748MNGIIAbmZLO/n43Efd+bMnDmftJJ3ZubcueacQ0RERPwR8LsAERGRlkxBLCIi4iMFsYiIiI8UxCIiIj5SEIuIiPhIQSwiIuKjiAaxmd1hZtlm9pGZ3em1tTWzJWa23ntv47WbmU0xsxwzW21mg2scZ7y3/3ozG1+jfYiZrfH6TDEzq2sMERGRxiZiQWxmA4AMYBgwEPimmZ0K3Au85ZzrA7zlrQNcCvTxXpOBqd5x2gL3A2nese6vEaxTvTEO9hvhtR9pDBERkUYlkmfEZwCZzrkS51wV8A7wLWAkMMfbZw5wlbc8Epjrqi0FUsysC3AJsMQ5l+ec2w8sAUZ425Kcc0td9VNJ5h52rNrGEBERaVSiInjsbOAhM2sHlAKXAVlAJ+fcTm+fXUAnb7kbsLVG/21eW13t22ppp44xPsfMJlN99k1CQsKQvn37HuOPKCIizc2Bsio27SumfFfOXudch0iPF7Egds6tNbNHgX8AxcAqIHTYPs7MIvqMzbrGcM5NA6YBpKamuqysrEiWIiIijdw/1+3mu8+spHMozOZHv7m5IcaM6GQt59xM59wQ59z5wH7gU2C3d1kZ732Pt/t2oEeN7t29trrau9fSTh1jiIiI1OqN7F3c/MwKKkJhxp9zUoONG+lZ0x29955U3x+eD7wCHJz5PB542Vt+BRjnzZ5OBwq8y8uLgYvNrI03SetiYLG3rdDM0r3Z0uMOO1ZtY4iIiHzBq6t3cOv8lVSGHJPO680vruzfYGNH8h4xwIvePeJK4FbnXL6ZPQI8b2YTgc3Atd6+r1F9HzkHKAFuAnDO5ZnZg8Byb78HnHN53vItwGwgHnjdewEcaQwREZHPWfTBNn74/IeEHdzy9VO4+5LT8T4N2yBMX4NYTfeIRURanueztnLPi6txDu68sA93XNDnUAib2QrnXGqka4j0GbGIiEijNC9zM/ctygbg7ktO59ZvnOpLHQpiERFpcWa/t5Ff/O1jAH56+RlM+urJvtWiIBYRkRZl2r8/4+HX1gHwyyv7M/4rvXytR0EsIiItxpNv5/DY4k8AePjqMxmd1tPnihTEIiLSAjjn+MOb6/njW+sxg0e/fRbXpvY4escGoCAWEZFmzTnHbxZ/wtR/fUbA4PFrz+aqQd2O3rGBKIhFRKTZcs7xq7+vZea7GwkGjCnXD+Lys7r4XdbnKIhFRKRZCocdv/jbR8x9fzPRQeOJ0YO5pH9nv8v6AgWxiIg0O+Gw476/rmHBsq3ERAX4vzGDGd631i/i852CWEREmpVQ2PGjF1bz4sptxEYFmD4ulfNPi/i3GR43BbGIiDQbVaEwP/zLh7y8agfx0UFm3pjKV05p73dZdVIQi4hIs1AZCnPHwg94bc0uEmKCzJ4wjKG92vpd1lEpiEVEpMkrrwpx2/wPWPLxbhLjopgzYRiDe7bxu6x6URCLiEiTVlYZ4nvPruDtT3JJjo/m2YlpnNk92e+y6k1BLCIiTVZpRYiMuVm8m7OXtgkxPDsxjX5dk/wu65goiEVEpEkqLq9i4pzlLN2QR/vWsczPSOO0Tol+l3XMFMQiItLkFJVVctPTy8navJ+OibHMz0jn1I6t/S7ruCiIRUSkSSkorWT8rGWs2ppP1+Q45mek06t9gt9lHTcFsYiINBn7iysYOyuT7O2FdG8Tz4KMdHq0beV3WV+KglhERJqEvQfKGTMjk3W7iujVrhXzM9LpmhLvd1lfmoJYREQavT2FZdwwI5P1ew5wcocEFmSk0ykpzu+yTggFsYiINGq7CsoYPX0pG/YWc1qn1syblE6HxFi/yzphFMQiItJobc8vZfT0pWzeV8IZXZJ4duIw2rVuPiEMCmIREWmktuwrYdT0pWzPL+Ws7snMnTCMlFYxfpd1wimIRUSk0dm4t5jR05eys6CMQT1TmDNhGElx0X6XFREKYhERaVRy9hQxanomuUXlDO3VhqdvGkbr2OYbV833JxMRkSZn3a5Cbpieyb7iCs45uR0zb0ylVUzzjqrm/dOJiEiTkb29gLEzM9lfUslX+7Rn2thU4mOCfpcVcQpiERHx3Ydb8xk7M5PCsiqG9+3In28YTFx08w9hUBCLiIjPVmzO48ZZyykqr+KS/p3406jBxEQF/C6rwSiIRUTEN5kb9jFh9nKKK0JcflYX/nDd2UQHW04Ig4JYRER88l7OXibNyaK0MsTVg7rx2DVnEdXCQhgUxCIi4oN3Ps1l8twsyqvCfGdIdx759lkEA+Z3Wb6I6J8eZvYDM/vIzLLNbIGZxZlZbzPLNLMcM3vOzGK8fWO99Rxve68ax/mx1/6JmV1So32E15ZjZvfWaK91DBER8d+bH+8mY051CN+Q1pNHW3AIQwSD2My6Ad8HUp1zA4AgcD3wKPB759ypwH5gotdlIrDfa/+9tx9m1s/r1x8YAfzZzIJmFgSeBC4F+gGjvH2pYwwREfHRG9k7+e6zK6gIhbnxK7341VUDCLTgEIYInxFTfek73syigFbATmA48IK3fQ5wlbc80lvH236BmZnXvtA5V+6c2wjkAMO8V45zboNzrgJYCIz0+hxpDBER8cnfPtzBrfM/oCrsmHz+ydx/RT+qf2W3bBELYufcduC3wBaqA7gAWAHkO+eqvN22Ad285W7AVq9vlbd/u5rth/U5Unu7OsYQEREfvLRyG3cs/IBQ2HHbN07lx5f2VQh7Inlpug3VZ7O9ga5AAtWXlhsNM5tsZllmlpWbm+t3OSIizdLzy7fyw798SNjBXRedxv+75HSFcA2RvDR9IbDROZfrnKsEXgLOBVK8S9UA3YHt3vJ2oAeAtz0Z2Fez/bA+R2rfV8cYn+Ocm+acS3XOpXbo0OHL/KwiIlKLZ5Zu5kcvrsY5+NGI0/n+BX38LqnRiWQQbwHSzayVd9/2AuBj4G3gGm+f8cDL3vIr3jre9n8655zXfr03q7o30AdYBiwH+ngzpGOontD1itfnSGOIiEgDmfXuRn7212wAfnr5Gdzy9VN9rqhxitjniJ1zmWb2ArASqAI+AKYBfwcWmtmvvLaZXpeZwDNmlgPkUR2sOOc+MrPnqQ7xKuBW51wIwMxuAxZTPSN7lnPuI+9Y9xxhDBERaQBPvfMZv359HQAPjOzPuHN6+VtQI2bVJ5CSmprqsrKy/C5DRKTJ+9Nb6/ndkk8xg4evPpNRw3r6XdJxMbMVzrnUSI+jJ2uJiMgJ4Zzj90s+Zco/cwgY/OaagVwzpLvfZTV6CmIREfnSnHM88sY6nnpnA8GA8fi1Axl5tj45Wh8KYhER+VKcczz46lpmvbeRqIAxZdQgLjuzi99lNRkKYhEROW7hsOP+Vz7imaWbiQ4aT44ezMX9O/tdVpOiIBYRkeMSDjt+smgNC5dvJSYqwFNjh/CN0zv6XVaToyAWEZFjFgo77n7hQ15auZ246AAzxg3lvD7t/S6rSVIQi4jIMakMhbnr+Q/524c7aBUTZOb4oZxzSju/y2qyFMQiIlJvFVVh7lj4Aa9n76J1bBSzbxpKaq+2fpfVpCmIRUSkXsqrQtw6byVvrt1DYlwUcycMY1DPNn6X1eQpiEVE5KjKKkPc/MwK3vk0l5RW0Tw7MY0B3ZL9LqtZUBCLiEidSiqqyJibxXs5+2ibEMO8SWmc0SXJ77KaDQWxiIgc0YHyKibMXs6yjXm0bx3L/Iw0TuuU6HdZzYqCWEREalVYVslNTy9nxeb9dEqKZX5GOqd0aO13Wc2OglhERL6goKSScbMy+XBbAd1S4pmfkcZJ7RL8LqtZUhCLiMjn5BVXMHZmJh/tKKRH23jmT0qnR9tWfpfVbCmIRUTkkL0HyhkzI5N1u4ro3T6BeZPS6JoS73dZzZqCWEREANhTWMboGZnk7DnAKR0SWJCRTsekOL/LavYUxCIiws6CUkZPz2Tj3mJO75TIs5PS6JAY63dZLYKCWESkhdu2v4TR0zPZkldCvy5JPDspjbYJMX6X1WIoiEVEWrDN+4oZPT2T7fmlDOyezNwJaSS3iva7rBZFQSwi0kJtyD3A6OmZ7CosY3DPFGZPGEZSnEK4oSmIRURaoPW7ixg9I5PconKG9W7LrBuH0jpWkeAH/a8uItLCrN1ZyJgZmewrruArp7RjxvhUWsUoDvyi/+VFRFqQ7O0FjJmZSX5JJeef1oFpY4cQFx30u6wWTUEsItJCrNqaz7iZmRSWVXFB3448ecNghXAjoCAWEWkBsjblcePTyzlQXsWI/p2ZMmoQMVEBv8sSFMQiIs3e0g37mDB7OSUVIa4Y2JXHrx1IdFAh3FgoiEVEmrF31+9l0tzllFWG+dagbjz2nYEEA+Z3WVKDglhEpJl6+5M93PzMCiqqwlyX2oOHv3WmQrgRUhCLiDRDSz7eza3zVlIRCjMmvScPXDmAgEK4UVIQi4g0M6+v2cntCz6gKuy46dxe/Pyb/TBTCDdWCmIRkWbk5VXbuev5DwmFHTd/7WTuHdFXIdzIKYhFRJqJF1Zs40cvfEjYwfeHn8oPLjpNIdwEKIhFRJqBhcu28ONFa3AO7rroNL5/QR+/S5J6itgHyczsdDNbVeNVaGZ3mllbM1tiZuu99zbe/mZmU8wsx8xWm9ngGsca7+2/3szG12gfYmZrvD5TzPvT70hjiIg0R8+8v4l7X6oO4Xsv7asQbmIiFsTOuU+cc2c7584GhgAlwCLgXuAt51wf4C1vHeBSoI/3mgxMhepQBe4H0oBhwP01gnUqkFGj3wiv/UhjiIg0KzPf3cjPXv4IgJ99sx/f/dopPlckx6qhHq1yAfCZc24zMBKY47XPAa7ylkcCc121pUCKmXUBLgGWOOfynHP7gSXACG9bknNuqXPOAXMPO1ZtY4iINBtT//UZD776MQAPXjWAief19rkiOR4NdY/4emCBt9zJObfTW94FdPKWuwFba/TZ5rXV1b6tlva6xvgcM5tM9dk3PXv2PLafSETER1PeWs/jSz7FDB751plcN1S/w5qqiJ8Rm1kMcCXwl8O3eWeyLpLj1zWGc26acy7VOZfaoUOHSJYhInJCOOf47eJPeHzJpwQMfnvNQIVwE9cQl6YvBVY653Z767u9y8p473u89u1Ajxr9unttdbV3r6W9rjFERJos5xyPvL6OJ97OIRgw/nD9IL49pPvRO0qj1hBBPIr/XZYGeAU4OPN5PPByjfZx3uzpdKDAu7y8GLjYzNp4k7QuBhZ72wrNLN2bLT3usGPVNoaISJPknOOBVz/mqX9vICpgPDFqEFcO7Op3WXICRPQesZklABcBN9dofgR43swmApuBa73214DLgByqZ1jfBOCcyzOzB4Hl3n4POOfyvOVbgNlAPPC696prDBGRJiccdvzs5WzmZW4hJhjgzzcM5sJ+tU59kSbIqm+hSmpqqsvKyvK7DBGRzwmFHT9+aTXPZ20jJirAtLFD+PrpHf0uq0UwsxXOudRIj6Mna4mINFJVoTB3v7CaRR9sJy46wMzxQzn31PZ+lyUnmIJYRKQRqgyF+cFzq3h19U5axQSZdeNQ0k9u53dZEgEKYhGRRqaiKsztC1ay+KPdJMZGMXvCUIac1NbvsiRCFMQiIo1IWWWIW+et5K11e0iKi2LuxDTO7pHid1kSQQpiEZFGoqwyRMbcLP6zfi8praJ5dmIaA7ol+12WRJiCWESkESipqGLSnCz++9k+2iXEMC8jjb6dk/wuSxqAglhExGcHyquY8PRylm3Ko0NiLPMnpdGnU6LfZUkDURCLiPiosKySG2ctY+WWfDonxTE/I42TO7T2uyxpQApiERGf5JdUMG7WMlZvK6BbSjwLMtLp2a6V32VJA1MQi4j4IK+4gjEzMvl4ZyE927ZifkYa3dsohFsiBbGISAPLLSpnzIxMPtldxMntE5iXkUaX5Hi/yxKfKIhFRBrQ7sIyRk9fyme5xfTp2Jp5k9LomBTnd1niIwWxiEgD2ZFfyujpS9m0r4S+nRN5dlIa7VvH+l2W+ExBLCLSALbmlTB6xlK25pXSv2sSz05Mo01CjN9lSSOgIBYRibDN+4oZNW0pOwrKGNgjhbk3DSO5VbTfZUkjoSAWEYmgz3IPMHr6UnYXljPkpDbMvmkoiXEKYfkfBbGISIR8uruI0dMz2XugnLTebZl141ASYvVrVz5P/0WIiETAxzsKGTMzk7ziCs47tT3Tx6USHxP0uyxphBTEIiIn2JptBYyZmUlBaSVfO60DT40dQly0QlhqpyAWETmBPtiyn3GzllFUVsWFZ3TiyRsGERulEJYjUxCLiJwgyzflcdPTyzlQXsWlAzrzx+sHERMV8LssaeQUxCIiJ8D7n+1j4pzllFSEuHJgVx6/diBRQYWwHJ2CWETkS/rP+lwy5mZRVhnmW4O78dg1AwkGzO+ypIlQEIuIfAlvr9vDzc+uoKIqzPVDe/Dw1WcSUAjLMVAQi4gcp398tItb56+kMuQYm34Sv7yyv0JYjpmCWETkOPx99U7uWPgBVWHHxPN689PLz8BMISzHTkEsInKMXl61nR88t4qwg+9+7RTuGXG6QliOm4JYROQY/CVrKz96cTXOwfcv6MMPLuyjEJYvRUEsIlJP8zO38JNFawD4fxefxm3D+/hckTQHCmIRkXqY+/4mfv7yRwD85LK+TD7/FH8LkmZDQSwichQz/rOBX/19LQD3X9GPm87t7XNF0pwoiEVE6vDk2zk8tvgTAH511QDGpJ/kc0XS3CiIRURq4Zzjj2+t5w9vrscMHv3WWVw7tIffZUkzFNEHoZpZipm9YGbrzGytmZ1jZm3NbImZrffe23j7mplNMbMcM1ttZoNrHGe8t/96Mxtfo32Ima3x+kwxb+rikcYQEakP5xy//ccn/OHN9QQMHr92oEJYIibSTyT/I/CGc64vMBBYC9wLvOWc6wO85a0DXAr08V6TgalQHarA/UAaMAy4v0awTgUyavQb4bUfaQwRkTo553j4tbU8+fZnBAPGH68fxNWDuvtdljRjEQtiM0sGzgdmAjjnKpxz+cBIYI632xzgKm95JDDXVVsKpJhZF+ASYIlzLs85tx9YAozwtiU555Y65xww97Bj1TaGiMgROef45d8+Zvp/NhIdNJ4cPZgrBnb1uyxp5iJ5RtwbyAWeNrMPzGyGmSUAnZxzO719dgGdvOVuwNYa/bd5bXW1b6ulnTrG+Bwzm2xmWWaWlZubezw/o4g0E+Gw4yeLspn9303EBAP835ghjBjQ2e+ypAWIZBBHAYOBqc65QUAxh10i9s5kXQRrqHMM59w051yqcy61Q4cOkSxDRBqxUNjxoxdXs2DZFmKjAkwfn8oFZ9T697vICRfJIN4GbHPOZXrrL1AdzLu9y8p473u87duBmrMhunttdbV3r6WdOsYQEfmcqlCYHz6/ihdWbCM+OsjTNw7la6fpD3NpOBELYufcLmCrmZ3uNV0AfAy8Ahyc+TweeNlbfgUY582eTgcKvMvLi4GLzayNN0nrYmCxt63QzNK92dLjDjtWbWOIiBxSGQpzx8JV/HXVDhJigsyZMIyvnNre77KkhYn054hvB+aZWQywAbiJ6vB/3swmApuBa719XwMuA3KAEm9fnHN5ZvYgsNzb7wHnXJ63fAswG4gHXvdeAI8cYQwREQDKq0LcPv8D/vHxbhJjo5g9YRhDTtInHaXhWfUtVElNTXVZWVl+lyEiDaCsMsT3nl3B25/kkhQXxTMT0xjYI8XvsqSRMbMVzrnUSI+jJ2uJSItSWhFi8jNZ/Gf9Xtq0iubZSWn075rsd1nSgimIRaTFKKmoYuLsLN7fsI/2rWOYNymd0zsn+l2WtHAKYhFpEYrKKpkweznLN+2nY2Is8zPSObVja7/LElEQi0jzV1BayfhZy1i1NZ8uyXHMz0ind/sEv8sSARTEItLM5ZdUMHbmMtZsL6BbSjwLJ6fTo20rv8sSOURBLCLN1r4D5YyZuYy1Ows5qV0r5mek0y0l3u+yRD5HQSwizdKeojLGzMjk090HOLlDAvMnpdM5Oc7vskS+QEEsIs3OroIyRs9YyobcYvp0bM28jDQ6JiqEpXFSEItIs7I9v5TR05eyeV8JfTsnMm9SGu1ax/pdlsgRKYhFpNnYmlfCqOlL2ba/lAHdknhmQhptEmL8LkukTgpiEWkWNu0tZvT0pewoKOPsHinMmTCM5Phov8sSOSoFsYg0eTl7DjB6+lL2FJWTelIbnr5pKIlxCmFpGhTEItKkfbKriBtmLGXvgQrST27LzPFDSYjVrzZpOvRfq4g0WR/tKGDMjEz2l1Ty1T7tmTY2lfiYoN9liRwTBbGINEmrt+UzduYyCkor+cbpHZg6Zghx0QphaXoUxCLS5Kzcsp/xM5dRVF7FRf068cToQcRGKYSlaVIQi0iTsmxjHjc9vYziihCXn9mFP1x/NtHBgN9liRw3BbGINBn/zdnLxDlZlFaGGHl2V373nYFEKYSliVMQi0iT8O9Pc8mYm0V5VZhrhnTn0W+fRTBgfpcl8qUpiEWk0fvnut1895mVVITCjBrWk4euGkBAISzNhIJYRBq1N7J3cfuClVSGHOPPOYlfXNkfM4WwNB8KYhFptF5dvYM7Fq4iFHZMOq83911+hkJYmh0FsYg0Sos+2MYPn/+QsINbvn4Kd19yukJYmiUFsYg0Os9nbeWeF1fjHNx5YR/uuKCPQliaLQWxiDQq8zI3c9+ibADuvuR0bv3GqT5XJBJZCmIRaTRmv7eRX/ztYwDuu+wMMs4/2eeKRCJPQSwijcK0f3/Gw6+tA+AXV/TjxnN7+1yRSMNQEIuI7558O4fHFn8CwMNXn8notJ4+VyTScBTEIuIb5xx/eHM9f3xrPWbw6LfP4trUHn6XJdKgFMQi4gvnHL9Z/AlT//UZAYPHrz2bqwZ187sskQanIBaRBuec41d/X8vMdzcSDBh/vP5svnlWV7/LEvGFglhEGlQ47PjF3z5i7vubiQ4aT4wezCX9O/tdlohvFMQi0mDCYcd9f13DgmVbiYkK8H9jBjO8bye/yxLxVb2+yNPMTjGzWG/562b2fTNLqUe/TWa2xsxWmVmW19bWzJaY2XrvvY3XbmY2xcxyzGy1mQ2ucZzx3v7rzWx8jfYh3vFzvL5W1xgi4p9Q2HH3C6tZsGwrsVEBZoxLVQiLUM8gBl4EQmZ2KjAN6AHMr2ffbzjnznbOpXrr9wJvOef6AG956wCXAn2812RgKlSHKnA/kAYMA+6vEaxTgYwa/UYcZQwR8UFVKMxdz6/ixZXbiI8O8vRNQzn/tA5+lyXSKNQ3iMPOuSrgauBPzrm7gS7HOeZIYI63PAe4qkb7XFdtKZBiZl2AS4Alzrk859x+YAkwwtuW5Jxb6pxzwNzDjlXbGCLSwCpDYb6/8ANeXrWDhJggcyYM4yuntPe7LJFGo75BXGlmo4DxwKteW3Q9+jngH2a2wswme22dnHM7veVdwMFrU92ArTX6bvPa6mrfVkt7XWN8jplNNrMsM8vKzc2tx48jIseivCrELfNW8tqaXSTGRfHMpDSG9W7rd1kijUp9J2vdBHwXeMg5t9HMegPP1KPfec657WbWEVhiZutqbnTOOTNzx1bysalrDOfcNKovtZOamhrROkRamrLKEN97dgVvf5JLcnw0z05M48zuyX6XJdLo1OuM2Dn3sXPu+865Bd76Rufco/Xot9173wMsovoe727vsjLe+x5v9+1U33s+qLvXVld791raqWMMEWkApRUhJs3J4u1PcmmbEMOCjHSFsMgR1HfW9Lne7ONPzWyDmW00sw1H6ZNgZokHl4GLgWzgFaovceO9v+wtvwKM82ZPpwMF3uXlxcDFZtbGm6R1MbDY21ZoZunebOlxhx2rtjFEJMKKy6u4afYy3s3ZS/vWsSzISKdf1yS/yxJptOp7aXom8ANgBRCqZ59OwCLvE0VRwHzn3Btmthx43swmApuBa739XwMuA3KAEqovh+OcyzOzB4Hl3n4POOfyvOVbgNlAPPC69wJ45AhjiEgEFZVVctPTy8navJ+OibHMz0jn1I6t/S5LpFGz6gnHR9nJLNM5l9YA9fgmNTXVZWVl+V2GSJNVUFrJuFnL+HBrPl2T45ifkU6v9gl+lyVy3MxsRY2P3kZMfc+I3zazx4CXgPKDjc65lRGpSkSalP3FFYydlUn29kK6t4lnQUY6Pdq28rsskSahvkF88Gy45l8GDhh+YssRkaZm74FyxszIZN2uIk5q14oFGel0TYn3uyyRJqNeQeyc+0akCxGRpmdPYRk3zMhk/Z4DnNwhgQUZ6XRKivO7LJEmpb6zppPN7PGDD78ws9+ZmT6LINKC7Soo4/ppS1m/5wCndWrNc5PPUQiLHIf6PllrFlBE9ezja4FC4OlIFSUijdv2/FKum/Y+G/YWc0aXJBZkpNMhMdbvskSapPreIz7FOfftGuu/NLNVkShIRBq3LftKGDV9KdvzSzmrezJzJwwjpVWM32WJNFn1PSMuNbPzDq6Y2blAaWRKEpHGauPeYq6b9j7b80sZ1DOFZyelKYRFvqT6nhF/D5jj3Rc2IA+4MVJFiUjjk7OniFHTM8ktKmdorzY8fdMwWsfW91eIiBxJfWdNrwIGmlmSt14Y0apEpFFZt6uQG6Znsq+4gnNObsfMG1NpFaMQFjkR6vyXZGZjnHPPmtldh7UD4Jx7PIK1iUgjkL29gLEzM9lfUslX+7Rn2thU4mOCfpcl0mwc7U/ag8+nS6xlm742UKSZ+3BrPmNnZlJYVsXwvh358w2DiYtWCIucSHUGsXPuKW/xTefcezW3eRO2RKSZWrE5jxtnLaeovIqL+3XiidGDiYmq7+cY5goAACAASURBVPxOEamv+v6r+lM920SkGcjcsI+xM5dRVF7F5Wd14ckbFMIikXK0e8TnAF8BOhx2nzgJ0PUpkWbovZy9TJyznLLKMFcP6sZj15xFVFAhLBIpR7tHHAO09vareZ+4ELgmUkWJiD/e+TSXyXOzKK8K850h3Xnk22cRDJjfZYk0a0e7R/wO8I6ZzXbObW6gmkTEB29+vJtb5q2kIhRmdFpPfjVyAAGFsEjE1fd60wwzSzm4YmZtzGxxhGoSkQb2RvZOvvvsCipCYW78Si8eukohLNJQ6vuJ/PbOufyDK865/WbWMUI1iUgD+tuHO7jzuVWEwo7J55/Mjy/te+hZASISefU9Iw6bWc+DK2Z2EvocsUiT99LKbdyx8ANCYcdt3zhVISzig/qeEd8HvGtm71D9rOmvApMjVpWIRNzzy7dyz0urcQ5+cOFp3HFhH79LEmmR6vus6TfMbDCQ7jXd6ZzbG7myRCSSnlm6mZ/9NRuAH404nVu+fqrPFYm0XHVemjazvt77YKAnsMN79fTaRKSJmfXuxkMh/NPLz1AIi/jsaGfEPwQygN/Vss0Bw094RSISMU+98xm/fn0dAA+M7M+4c3r5W5CIHPVzxBne+zcaphwRiZQ/vbWe3y35FDN4+OozGTWs59E7iUjEHe0Rl9+qa7tz7qUTW46InGjOOX6/5FOm/DMHM3jsmoFcM6S732WJiOdol6av8N47Uv3M6X96698A/gsoiEUaMeccj7yxjqfe2UAwYDx+7UBGnt3N77JEpIajXZq+CcDM/gH0c87t9Na7ALMjXp2IHDfnHA++upZZ720kKmBMGTWIy87s4ndZInKY+n6OuMfBEPbspnoWtYg0QuGw4/5XPuKZpZuJDhpPjh7Mxf07+12WiNSivkH8lvds6QXe+nXAm5EpSUS+jHDY8ZNFa1i4fCsxUQGeGjOEb/TVE2lFGqv6PtDjNjO7Gjjfa5rmnFsUubJE5HiEwo67X/iQl1ZuJy46wPRxqXy1Twe/yxKROtT3jBhgJVDknHvTzFqZWaJzrihShYnIsakMhbnr+Q/524c7aBUTZOb4oZxzSju/yxKRo6jXlz6YWQbwAvCU19QN+GukihKRY1NRFeb7Cz7gbx/uoHVsFHMnDFMIizQR9f32pVuBc4FCAOfceqo/0iQiPiuvCnHLvBW8nr2LxLgonpk4jNRebf0uS0Tqqb6XpsudcxUHvx7NzKLQ1yCK+K6sMsTNz6zgnU9zSWkVzbMT0xjQLdnvskTkGNT3jPgdM/sJEG9mFwF/Af5Wn45mFjSzD8zsVW+9t5llmlmOmT1nZjFee6y3nuNt71XjGD/22j8xs0tqtI/w2nLM7N4a7bWOIdKclFRUMXHOct75NJe2CTHMn5SuEBZpguobxPcAucAa4GbgNeCn9ex7B7C2xvqjwO+dc6cC+4GJXvtEYL/X/ntvP8ysH3A90B8YAfzZC/cg8CRwKdAPGOXtW9cYIs3CgfIqbnx6Oe/l7KN961gWTk6nX9ckv8sSkeNw1CD2Am+tc266c+47zrlrvOWjXpo2s+7A5cAMb92o/samF7xd5gBXecsjvXW87Rd4+48EFjrnyp1zG4EcYJj3ynHObXDOVQALgZFHGUOkySssq2TczEyWbcyjU1Isz92czmmdEv0uS0SO01GD2DkXAj4xs+N5ktYfgB8BYW+9HZDvnKvy1rdRPQMb732rN2YVUODtf6j9sD5Haq9rjM8xs8lmlmVmWbm5ucfx44k0rIKSSsbOyGTllny6pcTz/M3ncEqH1n6XJSJfQn0na7UBPjKzZUDxwUbn3JVH6mBm3wT2OOdWmNnXv1SVEeKcmwZMA0hNTdXkM2nU8oorGDszk492FNKjbTzzJ6XTo20rv8sSkS+pvkH8s+M49rnAlWZ2GRAHJAF/BFLMLMo7Y+0ObPf23w70ALZ5s7KTgX012g+q2ae29n11jCHSJO09UM6YGZms21VE7/YJzJuURteUeL/LEpEToM5L02YWZ2Z3At8B+gLvOefeOfiqq69z7sfOue7OuV5UT7b6p3PuBuBt4Bpvt/HAy97yK9463vZ/evehXwGu92ZV9wb6AMuA5UAfb4Z0jDfGK16fI40h0uTsKSzj+mlLWberiFM6JPDc5HSFsEgzcrR7xHOAVKpnS18K/O4EjHkPcJeZ5VB9P3em1z4TaOe13wXcC+Cc+wh4HvgYeAO41TkX8s52bwMWUz0r+3lv37rGEGlSdhaUct20peTsOcDpnRJZOPkcOibF+V2WiJxAVtfkZzNb45w701uOApY55wY3VHENKTU11WVlZfldhsgh2/aXMHp6JlvySujXJYlnJ6XRNkEfiRdpKGa2wjmXGulxjnaPuPLggnOu6uCTtUQksjbvK2b09Ey255dyVvdk5k4YRkorhbBIc3S0IB5oZoXeslH9ZK1Cb9k55/QEAZET7LPcA9wwPZNdhWUM7pnC7AnDSIqL9rssEYmQOoPYORdsqEJEBNbvLmL0jExyi8oZ1rsts24cSuvYY/m2UhFpavQvXKSRWLuzkDEzMtlXXMFXTmnHjPGptIrRP1GR5k7/ykUageztBYyZmUl+SSXnn9aBaWOHEBetC1IiLYGCWMRnq7bmM25mJoVlVVzQtyNP3jBYISzSgiiIRXyUtSmPG59ezoHyKkb078yUUYOIiarvl6KJSHOgIBbxydIN+5gwezklFSGuGNiVx68dSHRQISzS0iiIRXzw7vq9TJq7nLLKMN8a1I3fXHMWUQphkRZJQSzSwN7+ZA83P7OCiqow16Z259ffOotgQA/LEWmpFMQiDWjJx7u5dd5KKkJhxqT35IErBxBQCIu0aApikQby+pqd3L7gA6rCjpvO7cXPv9kPPTZWRBTEIg3g5VXbuev5DwmFHTd/7WTuHdFXISwigIJYJOJeWLGNH73wIWEHtw8/lbsuOk0hLCKHKIhFImjhsi38eNEanIO7LjqN71/Qx++SRKSRURCLRMjc9zfx85c/AuDeS/vy3a+d4m9BItIoKYhFImDGfzbwq7+vBeBn3+zHxPN6+1yRiDRWCmKRE2zqvz7j0TfWAfDgyP6MPaeXvwWJSKOmIBY5gaa8tZ7Hl3yKGfz66jO5flhPv0sSkUZOQSxyAjjn+N0/PuWJt3MIGDx2zUC+PaS732WJSBOgIBb5kpxzPPL6Op769waCAeP3153NlQO7+l2WiDQRCmKRL8E5xwOvfszT720iKmD8adQgLj2zi99liUgToiAWOU7hsONnL2czL3MLMcEAf75hMBf26+R3WSLSxCiIRY5DKOz48UureT5rGzFRAaaNHcLXT+/od1ki0gQpiEWOUVUozN0vrGbRB9uJiw4wc/xQzj21vd9liUgTpSAWOQaVoTA/eG4Vr67eSauYILNuHEr6ye38LktEmjAFsUg9VVSFuX3BShZ/tJvWsVHMmTCUISe19bssEWniFMQi9VBWGeLWeSt5a90ekuKimDsxjbN7pPhdlog0AwpikaMoqwyRMTeL/6zfS0qraJ6dmMaAbsl+lyUizYSCWKQOJRVVTJqTxX8/20e7hBjmZaTRt3OS32WJSDOiIBY5ggPlVUx4ejnLNuXRITGW+ZPS6NMp0e+yRKSZURCL1KKwrJIbZy1j5ZZ8OifFMT8jjZM7tPa7LBFphhTEIofJL6lg3KxlrN5WQLeUeOZnpHFSuwS/yxKRZioQqQObWZyZLTOzD83sIzP7pdfe28wyzSzHzJ4zsxivPdZbz/G296pxrB977Z+Y2SU12kd4bTlmdm+N9lrHEDmavOIKRk/PZPW2Anq2bcVzN6crhEUkoiIWxEA5MNw5NxA4GxhhZunAo8DvnXOnAvuBid7+E4H9Xvvvvf0ws37A9UB/YATwZzMLmlkQeBK4FOgHjPL2pY4xRI4ot6icUdOW8vHOQk5un8BzN6fTvU0rv8sSkWYuYkHsqh3wVqO9lwOGAy947XOAq7zlkd463vYLzMy89oXOuXLn3EYgBxjmvXKccxuccxXAQmCk1+dIY4jUandhGddPe59PdhdxasfWLJycTpfkeL/LEpEWIJJnxHhnrquAPcAS4DMg3zlX5e2yDejmLXcDtgJ42wuAdjXbD+tzpPZ2dYxxeH2TzSzLzLJyc3O/zI8qTdiO/FKue+p9Psstpm/nRBZOTqdjUpzfZYlICxHRyVrOuRBwtpmlAIuAvpEc71g556YB0wBSU1Odz+WID7bmlTB6xlK25pXSv2sSz05Mo01Cy5xSEA6H+feWf7OzaCddErtwfs/zCQQi+rd6o+OcY2P+RgrKCkiOS6Z3Sm+qL7KJRE6DzJp2zuWb2dvAOUCKmUV5Z6zdge3ebtuBHsA2M4sCkoF9NdoPqtmntvZ9dYwhcsjmfcWMmraUHQVlDOyRwtybhpHcKtrvso4pDGrumxSbhHOOtXvXAtCvQz9ObnNyvYJk0dpF3PfP+9hbshfDCBOmQ6sOPDT8Ia4+4+oT+vM1Vtl7snli2RNsLdhKwAKEXIieyT25bdhtDOg4wO/ypBmLWBCbWQeg0gvheOAiqidRvQ1cQ/U93fHAy16XV7z1973t/3TOOTN7BZhvZo8DXYE+wDLAgD5m1pvqoL0eGO31OdIYIgB8lnuA0dOXsruwnCEntWH2TUNJjPM/hI8lDGrue6DiAJ/s+4QDFQeICcYQFYgiLiqO9O7p/PxrP68zSBatXcTNr95MbDCWtnFtsYDhwo6i8iJufvVmgGYfxtl7srlnyT0kRCfQLbEbZoZzjrySPO59814eufARhbFEjDkXmSuyZnYW1ROlglTfi37eOfeAmZ1MdUC2BT4Axjjnys0sDngGGATkAdc75zZ4x7oPmABUAXc651732i8D/uCNMcs595DXXusYddWbmprqsrKyTuT/BNJIfbq7iNHTM9l7oJxhvdvy9I1DSYit/9+kkbp8WTMMUuJSDoVBflk+JVUlnwuDmvuGXZh3t75LYXkhZoY5o2PrjuCgrKqMPu368OTlT9YaJOFwmP5T+3Og/ACtY7/4wJID5QdIjE0k+3vZzfYytXOO7/79u+wv2U+b+DZf2L6/dD9tW7Vl6uVTdZm6hTGzFc651IiPE6kgbmoUxC3DxzsKGTMzk7ziCs49tR3Tx6XSKqb+IRypy5fHEgbAoX1T4lL49+Z/s+PADgCCgSChcIhgIEjn1p2pqKoA4KKTL2LqN78YJP/a9C+u/cu1h86Ev1BX2LGvbB8vfudFzu91/nH/fI3Zhv0buP212w+dCR/OOce2om08edmT9G7T24cKxS8NFcTN809ckVqs2VbAqOlLySuu4GundWDm+KHHHML3LLmHvJI8uiV2o2tiV7ondj90+TJ7T/Zx17YxfyPbCraRElf7VyumxKWwpWALm/I3fW7foooiCisKCbkQAav+5xy0IJWhSipDlcQEY6gIVbBu3zo25W/6wnF3Fu3EsFpDGMACRoAA24ua7zSLgrICAhY44tmumRG0IPll+Q1cmbQUCmJpET7Ysp/RM5ZSUFrJhWd0Ytq4IcRFB+vd3znHn5b9iYToBNrEtzn0S9vMaBPfhlZRrXhi2RMc7xWmYwmDmvtWhCpwzlWH6cG+BoYRciEwCFiAsAvXGiRdErsQJowL1163CzvChOmWWOsnAJuF5LhkQi50xP/vnHOEXOiIfySJfFl61rQ0O4ffw92bn8yE2VkcKK/i0gGd+eP1g4iJOra/QQ+ehR4pkGqesR7P5cuaYXCky6MHw8DhDu0bE4ypvpeM+19fBw5H0ILgIOzCBCxQa5Cc3/N82rdqf8R7xMWVxXRo1YHzep53zD9TU9E7pTc9knsc8bZAflk+PZN70iulV8MXJy2CglialcPv4RYWdWLb5isIhaO4YmBXfn/tQKKCx34hKNKXL481DA7umxKXQlJMEgcqDhB2YYIWJORCRAejiQ5GU1FVQUwwhr7t+tYaJIFAgIeHP1w9O7ocEqITDs2aLq4spjxUzpThU5rtRC2o/v/u9mG3c8+SewBqnSj382E/10QtiZjm+69LWpw1u9dw+2u381neZyTGJhITOoutXgi3SlrDiCE7CR7hXujRRPry5cEwKK4sZn/p/kPjOOfYX7qfkqoSbht2W/Ws6Br75pflM6DjAFpFt6IqXEVFqIJwOEybuDaUV5ZTWllK96Tu3JZ22xGD5Oozruapbz5FYmwi+8r2kVeSx76yfSTGJvLUN59q9h9dAhjQcQCPXvQobVu1ZVvRNnYU7WBb0Tbatmqrjy5JxGnWtEezppu2NbvXcN0L17G/dD8xwRhceT8C+TcD0bj4d6lsNZeoqCCXnnopt6fdfsy/WBvqIy4Hz+i3FGw5dHZ7tM8RbynYQnFF8XF/jvigcDjMu1veZXvRdrolduO8nuc16zPh2jjn2JS/ifyyfFLiUuiV0ktnwi2YPr7UwBTETdea3WvIeCWDnP05JMUmEVU5mIq9Y4EoSqMX06rd34mNiqakooQzO56JBey4znKO5XO+X8axhEHNfZNjk7/wZK3ebfSIRpHjpSBuYAripungmfCeA3soriomvupcEktvx4iiLOY1SuKeIRis/kxtSUUJqV1TCVrwuM9ej+WMVUSatoYKYk3Wkibr4JnwnuI9xEfH48qG0Lr0NowAhVEvUhn3F6ICUVSGKqmoqsBRPcs4MSbxuGc4D+g4gKmXT9XlSxE5YRTE0iQdfiYcLhlGYtn3MAKUxL5AYeAZguEgUcEoDKMsVEZybDKJMYlfeoazmekJSyJywiiIpUkJh8PM/nA2v/3vb9lVtIukmCRc6bkklk0GoCD6WcpjXoZQ9b6hUOjQbOf+Hfofuq+rBzSISGOhIJYmY9HaRdz31n1syN9A2IWpClcRLvkqKRXVIVwav4CKqFeoClcBECZMRbiC+Kh4vtLjK7SNbwvoAQ0i0rgoiKVJOPhVfUELErQgMcEYAsUXklI1EYDCmFlUxSwhyvtPOjGm+jOxCdEJfL3X12kX304PaBCRRklBLI2ac47P8j7jrsV34XCHvtigVflVxFVdB8D+6KmURC0m3sUTIkSYMFWuih5JPUjtmsqBigPsKNpxaIbzz4fV73O1IiINQUEsjVb2nmz+lPkn3tn0DpsKNgEQJEhi5XXEVV2HI0x+zJMUR72Jc47kuGSiA9EUlhfSp20fpl0xjQEdB2iGs4g0agpiaZSy92Rzy99v4dO9n7K7ZHd1o4PEqtEkV12HI8T+2CmEYt8nGA5SFa6itLKUqmAVHVt3ZNoV0ziz05kAmuEsIo2aglgaHeccv/zXL8nek01BeQFG9UznlKoJJFd9C0eIvdG/pTz4X4KhIHFRcZRRRq+UXiTFJfHHEX88FMIiIo2dglganTdy3uD1nNcpqSzBVX+nH20qJ5MUuhJHJbkxv6E0+D7mqr/+ryxURnQgmsFdBvP99O/r/q+INCkKYmlUVu9azfde/V6NEDbaVt5CYuhSL4QfpjS4/ND+QQsSF4zj0Yse5eYhN+v+r4g0OQpiaTReWvsSN/71RooqiqobXIB2lbfTOnQRYcrJjXmIsuDKQ/s7HMFAkEcvepTvpn7Xp6pFRL4cBbE0CovWLiLjlQyKK4q9e8JGu8of0Dr0DcKUkRvzAGXB1QAECOBwtI5uzWV9LuPmITf7XL2IyPFTEIvvKisrue212yitLCVMmICLpl3lXSSEvkqYEvbE/JLy4Eef6xMXjCMlLoX7zr9Pl6NFpElrWd/6LY3OH5b+gbaPtWXHgR2UhkrBRdGu4kdeCBezO+bnXwhhMyM5Ppk/XqrZ0SLS9OmMWHzzu3d/x4/e+lH1pCzAXAztK35Mq/BQQhxgb+zPqQh8+oV+X+35VaZcOkUhLCLNgoJYGpxzjm8v/DaLPl10qM1cLB0q7iM+PJgQBeyO/SmVgY0ECQIQIkRCdALn9zyfV0e/SiCgizki0jwoiKVBZe/J5vJ5l7OlcMuhNnOxdKz4OXHhgYTY74XwZoBDZ8tRFsWgzoP4zcW/UQiLSLOi32jSYLL3ZDP6udGHhXA8HSseIC48kCr2sSv2x4dCGMAwgoEgw3sPZ+o3p+phHSLS7OiMWBpEOBxm9F9GsyZvzaE2cwl0Kv8lsa4vVZbL7pj7qArs+Fy/NvFteHD4g3pYh4g0WwpiibjsPdl87emvkVeWd6gt4FrTsfxBYl0fqmw3u2N+QlVg96HthpEQncCOH+wgOjraj7JFRBqEglgiKntPNsNnDz8shJPoVP4rYtzJVNoOdsfcRyiQ+7l+ZsaDwx9UCItIs6cglohxzjHp5Unklv4vZAMuhU7lDxHjTqLStrE79j5Ctu8LfX8z/DfcmX5nQ5YrIuILBbFEzD2L7yFzR+ah9aBrR6fyXxHtelBhm9kdex9hy/9Cv3FnjuOH5/2wIUsVEfGNglhOKOccG/M3cuW8K/lo3/+eiBUMd6BTxUNEu65U2EYvhAu/0H/kaSOZ8605DVmyiIivIvbxJTPrYWZvm9nHZvaRmd3htbc1syVmtt57b+O1m5lNMbMcM1ttZoNrHGu8t/96Mxtfo32Ima3x+kwxb1rtkcaQyMrek833/v49Bv3foM+FcFS4E50rfk2060q55bA79ie1hvDCqxby11F/bciSRUR8F8nPEVcBP3TO9QPSgVvNrB9wL/CWc64P8Ja3DnAp0Md7TQamQnWoAvcDacAw4P4awToVyKjRb4TXfqQxJEKy92Rz9+K7ydqWRWHF/0I2KtyFThW/Jsp1ptzWeWfCRV/o/9jwx7hu4HUNWbKISKMQsSB2zu10zq30louAtUA3YCRw8NrjHOAqb3kkMNdVWwqkmFkX4BJgiXMuzzm3H1gCjPC2JTnnljrnHDD3sGPVNoZEgHOOjFcyeHPjm6zYveJQe1S4O53KHyHKdaQs8BG7Y3+Gs+Iv9B/aeSj/76v/ryFLFhFpNBrkHrGZ9QIGAZlAJ+fcTm/TLqCTt9wN2Fqj2zavra72bbW0U8cYh9c1meqzb3r27HmMP5VAdQiPenEUS7cv/Vx7dPgkOpX/iiBtKAusZk/MAzgr+0L/K/pcwSujX6n1uBvzN1JQVkByXDK9U3rrgR4i0ixFPIjNrDXwInCnc66w5i9T55wzMxfJ8esawzk3DZgGkJqaGtE6mqPsPdnc+fqdvLXprc+1R4d7eyGcTGlgJbkxD+Gs/Av9fzP8N9z91btrPe4Ty55ga8FWAhYg5EL0TO7JbcNuo3+H/gpoEWlWIhrEZhZNdQjPc8695DXvNrMuzrmd3uXlPV77dqBHje7dvbbtwNcPa/+X1969lv3rGkNOkOw92Xzvb9/jvW3vfa49JnwqHcsfJEgiJYHl5MY8DFb5hf6PfP2RI4bwPUvuISE6gW6J3TAznHPkleRx699vpVPrThRXFH8hoPUMahFpqiI5a9qAmcBa59zjNTa9Ahyc+TweeLlG+zhv9nQ6UOBdXl4MXGxmbbxJWhcDi71thWaW7o017rBj1TaGnADOOaZkTmHlrpWHvh0JICZ8Op3KH/JC+H1yYx6qNYRTu6Ryz9fuqfW4f1r2JxKiE2gT3+bQma6Z4XB8uu9TVuxYQdfErnRN7Er3xO7kleRx75v3kr0nO3I/sIhIBEVy1vS5wFhguJmt8l6XAY8AF5nZeuBCbx3gNWADkANMB24BcM7lAQ8Cy73XA14b3j4zvD6fAa977UcaQ06AjfkbWbR2ESVVJYfaYkP96VT+4P9v787joyrvxY9/vrNmJQskgCwSq1aFqihFvVLrri29rXrRarXS20VtlV8XrdW61aVW2ttN6UVbF9Ten9dStfqqu/ZnW7y3gNaFwZ0QISAJWck66/f3xzkZJplJCJBJJsn3zYtXZp45zznPzJyZ7zzPeRY8FNLhWcX2wG0gsbS886fOZ+1Fa/vdb21rLaV5pb3SVZVQfYh8Xz7RRJSOqNPhS0Qoyy+jwFfAsjXLcPrsGWPM6JK1pmlVXQX0d/HupAzbK3BpP/u6F7g3Q/orQFqbpKo2ZjqG2XuqyrkPn0tDV0MyLS9+KBWR6/GQR4f3JRr8vwBJ9Mp3xgFn8NBZD5GXl9fvvlu7W/GIJ+2ab1ukjY5oBwX+AuLROOFYmOJAcfLx0rxSNrVuoqalhqqyqiF6psYYMzxsZi0zaG9ue5OTVpxEQzg1CM+lInItHoK0e5+n0X9HWhC+dN6lLFu4bJf7L8krIa5xVLVXMI7EI4j7T1GCvmCvfCKCV7y0dKdPl2mMMbkum03TZgz51T9+xeF3Hd4rCOfH51EZuR4PQdq8z9Dovz0tCJfnlXP7Z24f1DGqSquYUTIjLaAGvAEUJRwLUxQooihQ1OtxVSWu8bQmbWOMGQ0sEJtdevStR/nus9/t1TErP34MFZFrEPzs8P6ZJv9voM8osYAEuPvzd+PxDO40ExGWzF9CR7SD5q7m5DXfIn8RPo+P7lg3sytnI32ueLR0tzCzZCazSmft3RM1xpgRYIHYDCgej3PeyvN6pRXEFlARucoJwr7HaPbfmRaEAX5/1u858+Azd+t4cyrnsPSUpZQXlFPbVsvWtq1sad/CvH3msf/E/RGVZIBWVZq7mumMdXLZ/MtsPLExZlSya8SmX69vfZ2j7jmKCJFkWmHseCZGv4vgpdX3B1p8D2TsknfF0Vdw9pyz9+i4cyrnsHzhcmpaamjpbqE0r5RZpbNYv309y9YsY1PrJrziTY4jvn7+9TaO2BgzaokN+XDMmzdPX3nllZEuRs746p++yn1v3NcrrTB2MhOj/wfBQ4vvv2j1PZQxCC/+xGJWnLUiK+VS1bQAbTVhY0w2iMirqjov28exGvE4l2lO5+899b20IFwUO52J0csAaPbdzw7/yoz7+9z+n8taEAbnOrINUTLGjCUWiMexTHM6r9q4irZ472UKi2Ofozx6CQBNvnto8z+WcX//uv+/8sT56Qs4GGOMKdeWGAAAIABJREFU6Z911hqHVJWnP3iaS/58CZtaNrFPkTNl5EsbX0oLwhOiZ+4Mwv47+w3Clx91uQVhY4zZA1YjHmdC9SHuWH0HT3/wNLF4DJ/XR01LDQ2tDXTFu3ptOyF6DmWxCwFo9N9Bu+/ZjPv86Qk/5fvHpS/gYIwxZtcsEI8jPSsbKYqqUpJXgqK83fh27w0VSmJfojT2JZQEjf7b6fC9kHGfnz/g8xaEjTFmL1ggHidSVzaKaxyPeEDg3YZ3+2wIpbHFlMTORonT6P8lHb6XMu5z3tR5PP4lW9jKGGP2hl0jHidSVzYK+JwpI99peKf3Rgpl0a8ng3CD/2f9BuELZl/Q7ypKxhhjBs8C8TiRurJRcaCYLTu29N5AhbLoJUyIn4ESZXvgJ3T6VmXc1xVHX8GDix4chlIbY8zYZ03T40TqykZPvfcUCVIWZ1ChPHopxfHTUSJsD9xKlzfz5CYrF61k0exFw1RqY4wZ+ywQjxM9Kxs9/vbj1HXW7XxAPUyM/h+K4ieTIMz2wC10e19Lyy8Ir1/8OodOOXQYS22MMWOfBeJxQkTo6upKC8KTot+jMH48CbrZHriJbu+bGfNbEDbGmOywQDxOnHbvaTy3+bmdCeplUuT7FCYWkKCT+sCNhL3rM+b95Wm/tCBsjDFZYp21xoGJt03sE4R9VESudoNwO3XB6/oNwsdOP5YXql8gVB8aptIaY8z4YoF4jJv0k0k0hZt2Jqifysi1FCSOJk4bdcFriXjezZh3WvE0Dqk8hAJfAcvWLMNW6jLGmKFngXgM893oozHSmLwvGqQycj35iXnEaaUu+EMing8y5p2YP5FjZhyDIJTmlbKpdRM1LTXDVHJjjBk/7BrxGFVwcwFx4sn7onlURq4nL3EocZqpC15L1PNhxryzSmYxb9o8yvPKnbwieMVLS3fLsJTdGGPGEwvEY4yqctxdx9GV2LmAg2g+lZEfkZeYTYxG6oLXEPPUZsx/8r4nUzWxirZIGw2dDQR8AYr8RcQ1Tmle6XA9DWOMGTcsEI8hofoQp644lY+6PkqmiRYyOXwTQf04MamnLnANMc9HGfNPLZxKaWEpqzatoj3SjiAoit/j58h9jmRW6axheibGGDN+WCAeI0L1IT6x/BO90jxaTGX4ZoK6PzHZ5gbhuoz5T9z3RKIaZdWHq8j35VPoL0RRIrEIXdEu6trrWL99PXMq5wzH0zHGmHHDOmuNAaqaIQiXMDl8K0Hdn6hsZVvg6oxB2C9+wleHeWHxC0wumkyBv4CYxuiMdtIZ7STPn8exM49lcuFk6zltjDFZYDXiUU5VKb+1vFeaV8uoDN9CQPclKpupC15DXJrS8k4MTKTh6gYAqpur6Yx0cuKsE2mPthOJRwh4AxQHihERVDXZc7qqrGpYnpsxxowHFohHsVB9iEOXH4qys5bq1YlMDv8Yv04nIh9SF7yGhKT3dhYkGYRh5+pMHo+HCcEJ6dtbz2ljjMkKa5oepXquCfcKwokKJodvc4NwNXXBqzMGYYD49fFe91NXZ8pEVa3ntDHGZIEF4lEoHo9z5J1H9krzJSYzJXIbfp1KWN6nLvhDErIjY/6nz38aEemV1rM6U3813pbuFmaWzLSe08YYM8QsEI8yj739GPm35BPRSDLNl9iHyZHb8OlkwvIOdcFrSUh7Wt4gQY7b9zgmF05Oe0xEWDJ/CR3RDpq7mpM1Y1WluauZzlgnl82/LC2AG2OM2TsWiEeRx95+jLP+cBZRosk0X2I6k8O34dMKuj3rqQteh0pHxvxfnvtlCv2F/TYvz6mcw9JTllJeUE5tWy1b27ZS21ZLeUE5t518mw1dMsaYLLDOWqNEPB7nrD+c1SvNn9iXyeEf46WUbs8b1AduQiWcMf9FR1xEc1fzLpuX51TOYfnC5dS01NDS3UJpXimzSmdZTdgYY7IkazViEblXROpFJJSSVi4iz4vI++7fMjddROR2EflARN4UkSNS8ix2t39fRBanpB8pIuvcPLeLGyn6O8ZoFqoP4bul928mf2I/JodvxUspXZ5/9huEAwT4xtxv7FbzsohQVVbF3KlzqSqrsiBsjDFZlM2m6RXA6X3SrgJeVNUDgBfd+wCfAQ5w/18ELAcnqAI3AEcB84EbUgLrcuAbKflO38UxRg1Vpbq5mtc+eo0n330ybbKOQOIANwiX0OlZQ33g5n5rwqcecKo1LxtjTA7LWtO0qv5NRGb1Sf4CcLx7+37gJeAHbvoD6vQQ+oeIlIrIVHfb51W1CUBEngdOF5GXgAmq+g83/QHgDODpAY4xKoTqQyxbs4xNrZt4Z/s7bGzd2OvxYPwgKiM34qGQTs//sj2wFCSWcV8blmygNdxqzcvGGJPDhvsa8WRV7VlxYBvQ0313GrA5ZbtaN22g9NoM6QMdI+eF6kNc+dyVtEXbeGPrG7TF2no9HozPpjLyIzzk0+H9Gw3+n4PE0/bjw8dr33yN/cr3G66iG2OM2UMj1llLVVVEsjpx8a6OISIX4TSFM3PmzGwWZZdUlRv/eiPr6texrX0bMe1dy82LH0ZF5Do85NHu/QuN/l+BJNL2MyVvCs//+/PWBG2MMaPEcA9fqnObnHH/1rvpW4AZKdtNd9MGSp+eIX2gY6RR1d+q6jxVnVdRUbHHT2ooPLPhGV6qeYntndszBOEjqIhc7wbh5/sNwgeXHszWK7daEDbGmFFkuAPxE0BPz+fFwOMp6Re6vaePBlrd5uVngVNFpMztpHUq8Kz72A4ROdrtLX1hn31lOkbOUlV+8T+/oC3cRjjeu9NVfnw+lZHr8BCkzfs0jf7bMwbhqvwq3vr2WwDJjl7VzdW2WpIxxuS4rDVNi8hDOJ2mJolILU7v59uAP4jI14APgXPczZ8CPgt8AHQC/w6gqk0icjOw1t3upp6OW8C3cHpm5+N00nraTe/vGDlJVbnv9ft4efPLGYLwMVREfoDgY4f3CZr9v4V++ltVX1md7Oi1uXUzHvEQ1zgzS2Zy2fzLrJZsjDE5SqzG5Jg3b56+8sorw3rMUH2IO1bfwcPrH6Y13NrrsYLYcUyKXo7gpdX3CC2++/oNwnqDEqoP8YPnf5CcOatn6cKW7hY6Y502dMkYY3aTiLyqqvOyfRyb4nKErKtbx5KnlrBq46q0IFwYOyElCD/cbxB+8d9eRG9QVJU71txBob+Qsvyy5DAlEaEsv4wCXwHL1iyzZmpjjMlBNsXlCFhXt45zVp7DO43vpD1WGDuFidElCB5afL+n1fffGYPwitNXcOKcEwHY2LKR2tZaphVPS98QKM0rZVPrJmpaaqgqqxrS52KMMWbvWCAeZqH6EF994qsZg3BR7DNMjF4KQLNvBTv8f8y4j6AnyOKjkrN90trdikc8/U7YISJ4xdvvEofGGGNGjgXiYdQzVviVrenXootjn6c8ehEATf7f0ebL3Nnbi5fu67p7pZXklRDXOKqaMRirKnGN97vqkjHGmJFj14iHUXVzNX98K72WOyF6VjIIN/qX9xuE55TOIXZD+nSWVaVVzCiZ0W+Nt6W7ZZerLhljjBkZFoiHiapywn0npKWXRL9IWeyrKAka/XfQ7nsyY/4KfwXrvr2u14IQPeOERYQl85fQEe2guas52SlLVXdr1SVjjDHDz5qmh0GoPsQpD5zCto5tOxMVSmLnUxo7zw3Cv6bD92K/+1h53spdjhNeesrS5IIRXvEmH79+/vU2dMkYY3KUBeIsC9WH+PQ9n6Yp0rQzUaE09hVKYotQ4jT4f0Gn76/97qOqtIqy/LLkOOFpxdOS44SbOpu46oWrkuOEly9cTk1LDS3dLbbqkjHGjAI2oYcrGxN6qCpFtxbRGetMSYSy6DeYEP8CSoyGwM/o9L6cMb8XLxPyJnD3v97Ns9XP0tzZTFl+Wdp2zV3NlBeUs3zhcgu6e0hV2diykdbuVkrySqgqrbLX0phxbrgm9LAacRadcM8JfYKwUB69hOL4QpQo2wO30eVdnTFvob+QGRNmcOtJt3LYlMO457V7bJxwltjUoMaYkWSBOEsW3r+Qv25JaW5WoTx6GcXx01Ai1AdupdubuQa+ZN4SFs1exIKZC/B4PLz20Ws2TjhLUqcGHajJ3xhjssV6TWfB/r/en6dqntqZoB4mRr9Dcfw0EnRTH7ip3yB8+dGXc/vC2zlu1nF4PM7bkzpOOBMbJ7xnbGpQY0wusEA8hFSV+XfNZ0PLhpREL5Oil1MUP4kEXdQHbqTb+3rG/BX5FXxl7lfS0nNxnHCmYVSjTc/UoKV5pagqO8I7aOhsYEd4B6raq8nfGGOyxZqmh0ioPsQ3H/sma7et3ZmoPiZFvk9h4lgSdFIfuIGw9+2M+auKqpg3Yx7L1ixL63TVM074B8//ACDj6krXz79+2DoXjZVrqj1TgzZ3N7O+fj3t0XYEQVGK/EXMrpxtTf7GmKyzGvEQWFe3juPvPZ5V21btTFQfFZGr3SDcTl3w2gGD8CkHnjJgDaxnnHB5QTm1bbVsbdtKbVst5QXlw3ods+eaalNnE9OKp7FP8T5ML56evKYaqg8NSzmGQkleCS3dLazesprueDcF/gIKAgUU+Avojnezesvq5DAwY4zJFqsR76V1des44s4jiLFz6knRABWRH5KfmEecHdQHryPi2ZAxf4m/hFMOPMXJt4tOVyM9TrjvNdUePddU6SJjjX5vj5mtYUWzSmbR0NWAqhL0BZPpIkLQFyQajtLY1ci+JfsOyfGMMSYTC8R7IVQfyhCEg1REriM/cThxWqkLXkvUszFj/hJvCV/8xBeT9wfT6UpEhnyI0mCD3XAvt5jtJvCa1hoqCipoD7cTiUUIeAPOkpMKkXgEQZhYMJEPWz+0YWHGmKyxQLyHVJVjfndMnyCcT2XkevISnyBOM3XBa4h6NmXMP61gGgsPWtgrbSQ6Xe1OsBvO5RaHY1hRa3crJcESjp5xtHONOJJyjThQxBH7HEF3tNuuERtjssoC8R466q6jaI+1J++LFlAZuZG8xMHEaKQu+ENini0Z8+aTz7/s+y/JBRtGstPV7gS7XsOoBNoibU5N0hegOFAMypAMoxquJvCe51MWLGPBzAW0R9oJx8IEfUGKAkWgUBuptWvExpisskC8B7688susrdvZO9qjhVSGbyaoBxKTeuoC1xDzfNRv/n9c/A/+85X/HNHFGfYk2PUMo6ppqWFz6+a0GuSMkhlUlVbtdY1+uJrAe55Pz9ShxYFi5weFq7m72ZaPNMZknQXi3fS533+OJzfsXKrQoxOoDN9EUPcnKtuoC/yQuKe+3/yPnvMoh045dMQXZ9iTYCcinP6x07n4zxcT9AYp9BciHkETSlu4jdc+eo1Ljrxkr5/HQE3gitIWbaM90k6oPrRXr1uuDQszZnfZHOljgwXiQVJVTn3wVF7Y+EIyzaMlTA7fQkCriMoW6gLXEPc0ZMw/QSaw4uwVnHnwmcDQdbra0w/inlzvVVWe2fAMcyfPZfOOzbSEW0hoAo94KA2WcsiEQ3h2w7OccdAZQ9Jk3NN036Opu4n19etpC7cRjof5+f/+nCfff3KvOm/Z8pFmtBor4/mNBeJBCdWH+M7T3+HFmp3rBXu1jMrwjwnoTKKymbrgD4lLc8b8Fx92MVd86graIm1UN1cP2a/Wvfkg9hfsemTqwd1Tiy4OFidn0hIkuX1xsDgrTcbgBOHVtavxe/z4PX6Kg8UcUHbAkHTeGulhYbnCalejh82RPrZYIN6FUH2I81eez5sNbybTvDqRyeFb8es0IlJDXfBaEpK5Z+0ZB54BPvj2M98e0l+tofoQVz53JQB5vjyng5G/aNAfxEzBLlWmHtyt3a20R9pZV78On8fHhOCE5BdAOB5m7da1zCqdtde9jPs2GZfklRCqD+ETH4rzA2F2xWw8Hs+Qdd7KxrCw0cRqV6PHSIznN9llM2sNQFVZcO+C3kE4UcHk8G1uEN5AXfCH/Qbh7x/zfSKJyJDPQqWq3PjXG3m38V1C20O8+tGrvLz5ZV7e/DKKDmqxgp5g1xHtoLmrObmtqtLc1UxnrJPL5l/W64M8ITiB6pZqfOIj6Av2WiQh6AviFS8bWzZSEizZo+eVKnUmsfeb3qexs5FYIkaeL4/50+ZTnl+e3NbmhN47Y2m2tPEgdY70TOzzMPpYIB7AQbcfRGu4NXnfl5jClMhS/DqVsLxHXfAaErIjPV/ZQUSvidIaac3Kyj7PbHiGv9b8FVVNm5ZxzZY1JDQxqA/inkyb2dMUPRx6moyvOOYKDpp4EMfOPJYFMxb0CsJgy0DuDVuBavQZzvH8ZnhY03Q/1n64lvda3kve9yWmMTn8Y3xMotvzNvWBG1DpTMt3wSEX8ODZD1LdXJ2VITiqyt2v3u3USv3p0zKGY2HeaniL/Ur3G9QHcXeuj+4I76CqrIqNzRuRmKTNRBXXOFVlVb1+vOwtEeGQykMoChZRHCge9PXs8W6g672pj7WGW9ncupnpxdMz7meoZ0sze29P+neY3GaBOIOVoZWc88g5yfv+xAwqwz/GRzndnhD1gRtR6UrLt/BjC3nw7AeB7P1q3diykaauJrweLyj0raAGvAHaw+20R9sH/UEc7PXRkrwSCv2FzJ82n7e2v5U2jnhuxVw6o51D/gWwJ9ezx7OBrvcCvR5r6m6idkcthYFCyvPK0/ZltavcY5+HsccCcR+LH1vMA28+kLzvT8xicvgWvJTS5XmD7YGbUAmn5fvCgV/gT+f9KXk/W79aW7tbKQwUUhQsSs5qlUpEiCViTCqYNOQfxNQvgEwzUbV0ZecLwMb79jZQbTe1N+0+xfvQHm0nHA2zqXUT33ryW6AwpWhKsqdtob+Q6qZqVm9ezVEzjkoLxla7yj32eRh7LBCnOGHFCbz04UvJ+4HEx6gM34yXCXR5XmV74MeoRNLyPXzmw5xz6Dm90rL1q7Ukr4SEJphdMZs1W9ZAjF5NxOFYmJjG+PoRXx/yD2KmL4DigDOUqaUru18ANt7XMVBtd3bF7OT1XhXl5c0v92q1aOluoSRYwkGTDkq+RxOCEyjNK01OkHL45MOJxHdOW2q1q9xkn4exRawThmPSxyZp44WNyfuBxIFUhm/CSxGdnjVsD/wEJJqW79pjruXmU2/OuM/U2kmmX617MtZPVbnkyUto7mxGRdMWK/B7/By5z5E8vOjhrP0i7gkGfb8AhmOoi6qO2/G+uzqfLp1/KctWLyPfn8+aLWvwe/zJH2mReIStO7aiKCfOOpEZJTOS+23qamLVplW0hp1FMALeAAlNEPAGmD5hOr9Z+Bv7Ys9R4/nzMBxE5FVVnZf141ggdsg+olzs3A7GD6YyciMeCujwvExD4GcgsbQ8fvHTfW03Hk//nc+zEbRSv5BL8kroiHbQHe0mHHeazJeestQC4hiT+gMsUwtLc1czCRJ0RbuobqlOu2zRHeumoaOBuMaZUjSFk6tOTr5fTV1N/H3T39kR3sGEwASCviCqit/rt0BsxjULxMOsJxAH43OojNyAh3w6vH+jwf9zkHj69giPnPNIcsrKgWQjaI1krdQMv+rmapY8tSR5bbcvVeW9pvfoinaxtW2rs3pUymbReJSP2pyFSErySvj0vp9mQnACqsrfN/2dcCxMNBFl7tS5yZp0T9N0eUG5TQ5hxqXhCsR2jThFXvwwKiLX4SGPdu9faPT/CiSRtt2Mwhn8euGvBxWEITuzNtm0jOPLYHrhFwWKnB9liXhab3q/1+/0tAd84iMSd/o6tEXa6Ih24BMfxcFiphRN6TVW3IYvGZN9Y3ZCDxE5XUTeFZEPROSqXW5PgVsTzqPd+1y/QfiGT91AzfdqBh2Es6knwM+dOpeqMpsXeCzrtRZ0BqpKQhNccNgFRDVKOBruNVtaOBamMFBIga+AaCKK3+MH3M598ZgzbWjl7LQJW2z4kjHZNyYDsYh4gd8AnwEOAc4TkUMGyuPXqQgB2rxP0ui/I2MQvvDQC/nRiT8a8JqwMdnQ0wu/v4DY07t58aGLOX7W8YgIndFOOiOddEY7yfPlsWDGAg6behhl+WW0hlvZ2raVpu4mfF4fn5z2yYzjiG34kjHZN1abpucDH6hqNYCI/DfwBeCt/rMIO7yP0+z/XVqzHsDx+x7P/Wfen5XCGrMrgx076vF4uOHTN3Dlc1ciOLOt9SwI0hpuxe/x8/Cih51x3+5wpqUvL6W5K/PKYTZ8yZjsG5OdtURkEXC6qn7dvf9l4ChVvazPdhcBFwHg5UgqM81VBXTTQDMfZrvcu2ESkHnh49w0msqb22X1k0chlXgJ0E2APCLEidBBPVG6M27XI9N2PdtOYDpKggQ7eyZ68CJ42EFtWp49k9uvbW+jqawwuso7msr6cVUtzvZBxmqNeFBU9bfAbwFE5BXdmv3ecUNBRF4Zjp58Q2U0lXfUlbV9dJQVRuFrO0rKCqOrvKOtrMNxnLF6sXMLMCPl/nQ3zRhjjMkpYzUQrwUOEJEqEQkA5wJPjHCZjDHGmDRjsmlaVWMichnwLOAF7lXV9bvI9tvsl2zIjKaywugqr5U1e0ZTeUdTWWF0ldfK2seY7KxljDHGjBZjtWnaGGOMGRUsEBtjjDEjSVXH9X/gdOBd4APgqmE43r1APRBKSSsHngfed/+WuekC3O6W7U3giJQ8i93t3wcWp6QfCaxz89zOzssPGY+xi7LOAP4fzkQo64Fv52p5gTxgDfCGW9Yb3fQqYLW7/4eBgJsedO9/4D4+K2VfV7vp7wKn7epc6e8Yg3h9vcBrwJ9HQVlr3PfpdeCVXD0P3DylwB+Bd4C3gWNyuKwfd1/Tnv87gO/kcHm/i/P5CgEP4XzucvK8Bb7tlnM98J2cPmcH8yEcq/9xvgg3APsBAZwv8UOyfMzjgCPoHYh/2nPSAVcBS93bnwWedk+So4HVKW90tfu3zL3dc0KtcbcVN+9nBjrGLso6teeEBIqB93CmDM258rr5i9zbfvdDezTwB+BcN/1O4Jvu7W8Bd7q3zwUedm8f4p4HQZwP/wb3POn3XOnvGIN4fb8H/F92BuJcLmsNMKlPWs6dB+529wNfd28HcAJzTpY1w/fRNmDfXCwvMA3YCOSnnEtf6e+cYgTPW2AOThAuwOmU/AKwfy6+rqoWiI8Bnk25fzVw9TAcdxa9A/G7wFT39lTgXff2XcB5fbcDzgPuSkm/y02bCryTkp7crr9j7Ga5HwdOyfXyuh++fwJH4czg4+v7fuP0qD/Gve1zt5O+50DPdv2dK26ejMfYRRmnAy8CJwJ/Hmg/I11Wd9sa0gNxzp0HQAlOsJBcL2uGsp8KvJyr5cUJxJtxgpIP57w9rb9zihE8b4GzgXtS7l8HXJmLr6uqjvtrxD0nVo9aN224TVbVj9zb24DJ7u3+yjdQem2G9IGOMSgiMguYi1PTzMnyiohXRF7Hafp/HufXdYuqxjLsP1km9/FWYOIePIeJAxxjIL/C+WLoWV1koP2MdFkBFHhORF51p4aF3DwPqoDtwH0i8pqI3C0ihTla1r7OxWnuHWhfI1ZeVd0C/AewCfgI5zx8ldw8b0PAp0RkoogU4NR4ZwzwnEf0PBjvgTjnqPMzSnPpGCJSBDyCc51lx97sa08M9hiqGlfVw3Fqm/OBg7JZrj0lIp8D6lX11ZEuy25YoKpH4KxodqmIHJf6YA6dBz6cSz/LVXUu0IHTPLi7+9kre/AZCwCfB1bu7b72xGCOISJlOIvnVAH7AIU413Rzjqq+DSwFngOewbn+Hu+zTU68rmCBOFemwqwTkakA7t96N72/8g2UPj1D+kDHGJCI+HGC8H+p6qO5Xl4AVW3B6WR2DFAqIj0T16TuP1km9/ESoHEPnkPjAMfoz7HA50WkBvhvnObpX+doWYFkbQhVrQcew/mhk4vnQS1Qq6qr3ft/xAnMuVjWVJ8B/qmqdbvY10iW92Rgo6puV9Uo8CjOuZyT562q3qOqR6rqcUAzTh+XXHxdx30gzpWpMJ/A6ZmH+/fxlPQLxXE00Oo2eTwLnCoiZe6v1FNxrpl8BOwQkaNFRIAL++wr0zH65e7jHuBtVf1FLpdXRCpEpNS9nY9zLfttnIC8qJ+y9ux/EfAX99frE8C5IhIUkSrgAJxOGRnPFTdPf8fISFWvVtXpqjrL3c9fVPX8XCwrgIgUikhxz22c9y9EDp4HqroN2CwiH3eTTsLp9Z9zZe3jPHY2Sw+0r5Es7ybgaBEpcPfV89rm6nlb6f6dCZyF0zEyF1/X8d1Zy3l/+SzOL6UNwDXDcLyHcK6vRHF+vX8N5xrIizjd3V8Ayt1tBfiNW7Z1wLyU/XwVp9v8B8C/p6TPw/mS3AAsY2eX+ozH2EVZF+A0q7zJzuEVn83F8gKH4gwFetPd3/Vu+n44H/IPcJr9gm56nnv/A/fx/VL2dY1bnndxe0IOdK70d4xBng/Hs7PXdE6W1c3zBjuHhl0z0Hs0kueBm+dw4BX3XPgTTm/XnCyrm68Qp9ZXkpKWk+UFbsQZFhYCHsTp+Zyr5+3fcX4ovAGclMuvq01xaYwxxoyg8d40bYwxxowoC8TGGGPMCLJAbIwxxowgC8TGGGPMCLJAbIwxxowgC8TG5DBxpuh73f2/TUS2pNwPDMH+bxCRn/RJO1xE3h4gz49E5Iq9PbYxxuHb9SbGmJGiqo0442IRkR8B7ar6Hz2Pi4hPd87BuycewpkC8OqUtNQ5j40xWWY1YmNGGRFZISJ3ishq4Kd9a6giEhJnkQ5E5AIRWePWoO8SEW/qvlT1PaBZRI5KST4HeEhEviEia0XkDRF5RJzJ8/uW5SURmefeniTOtJ09C3D8zM3/pohc7KZPFZG/ueUJicinhvTFMWYUskBszOg0HfgXVf1efxuIyMHAF4Fj1VkMIw6cn2HTh3BqwbjT+zWp6vvAo6r6SVU9DGe60K/tRvm+hjNN4CeBTwLfcKcz/BLvWWBCAAABjklEQVTOFIGHA4fhzNZmzLhmTdPGjE4rVTW+i21OAo4E1jrT4ZJP5gnoHwb+R0Qup3ez9BwRuQUoBYpw5t0drFOBQ0WkZ37gEpw5hdcC94qzmMifVNUCsRn3LBAbMzp1pNyO0bt1K8/9K8D9qpp6/TeNqm4WkY3Ap4F/w1m1CmAFcIaqviEiX8GZF7uv1GPnpaQLsERV04K3OEsoLgRWiMgvVPWBgcpnzFhnTdPGjH41OEv9ISJH4KwXC87E84tSVqEpF5F9+9nHQ8AvgWpV7VnwvBj4yK29ZmrS7jn2ke7tRSnpzwLfdPMiIge6qzjtC9Sp6u+Au3vKbcx4ZoHYmNHvEaBcRNYDl+GsXoOqvgVcCzwnIm8CzwNT+9nHSmA2vXtLXwesBl7GWXEnk//ACbivAZNS0u/GWfnmnyISAu7CaYE7HnjD3f6LOOswGzOu2epLxhhjzAiyGrExxhgzgiwQG2OMMSPIArExxhgzgiwQG2OMMSPIArExxhgzgiwQG2OMMSPIArExxhgzgv4/GHBwZppAQx0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_error(features, label):\n",
        "  y_pred = SalaryPrediction.m.predict(features).flatten()\n",
        "  error = np.absolute(y_pred - label)\n",
        "  error = pd.DataFrame({\n",
        "      'true values' : label,\n",
        "      'prediction values': y_pred,\n",
        "      'error' : error\n",
        "  })\n",
        "  return error"
      ],
      "metadata": {
        "id": "KYKyz5LGmu8A"
      },
      "execution_count": 549,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_error(SalaryPrediction.x_test, SalaryPrediction.y_test).head(n=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "6OzXoWjfnMjw",
        "outputId": "ad6ebd4a-9189-4fb4-a9c5-bb76646630e1"
      },
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     true values  prediction values          error\n",
              "508       120000      116452.695312    3547.304688\n",
              "433        70000       67498.109375    2501.890625\n",
              "121       200000      202988.609375    2988.609375\n",
              "120        60000       54343.191406    5656.808594\n",
              "242       110000      109605.093750     394.906250\n",
              "497       165000      164873.500000     126.500000\n",
              "501        30000       35935.851562    5935.851562\n",
              "192        18000       30854.583984   12854.583984\n",
              "339       109280      109279.960938       0.039062\n",
              "157       423000      284594.500000  138405.500000\n",
              "443        60000       64061.988281    4061.988281\n",
              "502        40000       39458.503906     541.496094\n",
              "270        72500       72597.312500      97.312500\n",
              "307       106260      106129.093750     130.906250\n",
              "54         60000       60022.914062      22.914062\n",
              "386        28500       28574.328125      74.328125\n",
              "494       100000      105920.250000    5920.250000\n",
              "449        20000       25862.007812    5862.007812\n",
              "412        60000       57869.949219    2130.050781\n",
              "19         56000       56042.343750      42.343750\n",
              "306       116000      115825.539062     174.460938\n",
              "597       170000      169570.437500     429.562500\n",
              "39        138000      138411.328125     411.328125\n",
              "542       206699      207475.093750     776.093750\n",
              "555       160000      160040.921875      40.921875\n",
              "532       214000      213268.500000     731.500000\n",
              "206       200000      200668.031250     668.031250\n",
              "422       159000      158794.687500     205.312500\n",
              "328       170000      170682.312500     682.312500\n",
              "563       140250      140283.625000      33.625000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40271f7e-8c78-47e3-a740-a27509dd87bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true values</th>\n",
              "      <th>prediction values</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>120000</td>\n",
              "      <td>116452.695312</td>\n",
              "      <td>3547.304688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>70000</td>\n",
              "      <td>67498.109375</td>\n",
              "      <td>2501.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>200000</td>\n",
              "      <td>202988.609375</td>\n",
              "      <td>2988.609375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>60000</td>\n",
              "      <td>54343.191406</td>\n",
              "      <td>5656.808594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>110000</td>\n",
              "      <td>109605.093750</td>\n",
              "      <td>394.906250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>165000</td>\n",
              "      <td>164873.500000</td>\n",
              "      <td>126.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>30000</td>\n",
              "      <td>35935.851562</td>\n",
              "      <td>5935.851562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>18000</td>\n",
              "      <td>30854.583984</td>\n",
              "      <td>12854.583984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>109280</td>\n",
              "      <td>109279.960938</td>\n",
              "      <td>0.039062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>423000</td>\n",
              "      <td>284594.500000</td>\n",
              "      <td>138405.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>60000</td>\n",
              "      <td>64061.988281</td>\n",
              "      <td>4061.988281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>40000</td>\n",
              "      <td>39458.503906</td>\n",
              "      <td>541.496094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>72500</td>\n",
              "      <td>72597.312500</td>\n",
              "      <td>97.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>106260</td>\n",
              "      <td>106129.093750</td>\n",
              "      <td>130.906250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>60000</td>\n",
              "      <td>60022.914062</td>\n",
              "      <td>22.914062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>28500</td>\n",
              "      <td>28574.328125</td>\n",
              "      <td>74.328125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>100000</td>\n",
              "      <td>105920.250000</td>\n",
              "      <td>5920.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>20000</td>\n",
              "      <td>25862.007812</td>\n",
              "      <td>5862.007812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>60000</td>\n",
              "      <td>57869.949219</td>\n",
              "      <td>2130.050781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>56000</td>\n",
              "      <td>56042.343750</td>\n",
              "      <td>42.343750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>116000</td>\n",
              "      <td>115825.539062</td>\n",
              "      <td>174.460938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>170000</td>\n",
              "      <td>169570.437500</td>\n",
              "      <td>429.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>138000</td>\n",
              "      <td>138411.328125</td>\n",
              "      <td>411.328125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>206699</td>\n",
              "      <td>207475.093750</td>\n",
              "      <td>776.093750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>160000</td>\n",
              "      <td>160040.921875</td>\n",
              "      <td>40.921875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>214000</td>\n",
              "      <td>213268.500000</td>\n",
              "      <td>731.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>200000</td>\n",
              "      <td>200668.031250</td>\n",
              "      <td>668.031250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>159000</td>\n",
              "      <td>158794.687500</td>\n",
              "      <td>205.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>170000</td>\n",
              "      <td>170682.312500</td>\n",
              "      <td>682.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>140250</td>\n",
              "      <td>140283.625000</td>\n",
              "      <td>33.625000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40271f7e-8c78-47e3-a740-a27509dd87bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40271f7e-8c78-47e3-a740-a27509dd87bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40271f7e-8c78-47e3-a740-a27509dd87bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 553
        }
      ]
    }
  ]
}